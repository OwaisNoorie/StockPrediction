{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f3fa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>987.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>979.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>962.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>986.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>988.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Close\n",
       "0  987.95\n",
       "1  979.00\n",
       "2  962.65\n",
       "3  986.75\n",
       "4  988.10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ğŸ“Œ Step 1: Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ğŸ“Œ Step 2: Load Data\n",
    "file_path = 'D:/stock_prediction/data/TCS.csv'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(\"TCS.csv not found in /data folder!\")\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df = df[['Close']]  # Keep only 'Close' column\n",
    "df.dropna(inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09abee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ Step 3: Normalize Data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# Save scaler max for inverse transform\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)  # Ensure the directory exists\n",
    "\n",
    "np.save('../models/TCS_scaler_max.npy', scaler.data_max_)\n",
    "\n",
    "\n",
    "# ğŸ“Œ Step 4: Create sequences\n",
    "sequence_length = 60\n",
    "X, y = [], []\n",
    "\n",
    "for i in range(sequence_length, len(scaled_data)):\n",
    "    X.append(scaled_data[i-sequence_length:i, 0])\n",
    "    y.append(scaled_data[i, 0])\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))  # (samples, timesteps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b485d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ Step 5: Split Data\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "583fb1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         â”‚        \u001b[38;5;34m10,400\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             â”‚        \u001b[38;5;34m20,200\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m51\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,651</span> (119.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,651\u001b[0m (119.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,651</span> (119.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,651\u001b[0m (119.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ğŸ“Œ Step 6: Build LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))  # Output layer\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1197c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0277 - val_loss: 0.0039\n",
      "Epoch 2/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 3/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 4/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0017 - val_loss: 0.0039\n",
      "Epoch 5/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 6/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 7/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 8/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 9/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 10/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 11/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 12/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 13/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 14/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 15/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 16/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 17/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 8.8406e-04 - val_loss: 0.0017\n",
      "Epoch 18/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 8.9949e-04 - val_loss: 0.0019\n",
      "Epoch 19/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 9.0658e-04 - val_loss: 0.0016\n",
      "Epoch 20/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 9.2713e-04 - val_loss: 0.0020\n",
      "Epoch 21/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 9.6134e-04 - val_loss: 0.0018\n",
      "Epoch 22/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 9.2575e-04 - val_loss: 0.0015\n",
      "Epoch 23/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 7.0796e-04 - val_loss: 0.0015\n",
      "Epoch 24/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 7.9376e-04 - val_loss: 0.0014\n",
      "Epoch 25/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 8.1699e-04 - val_loss: 0.0014\n",
      "Epoch 26/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 7.6444e-04 - val_loss: 0.0013\n",
      "Epoch 27/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 7.3295e-04 - val_loss: 0.0015\n",
      "Epoch 28/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 6.4986e-04 - val_loss: 0.0017\n",
      "Epoch 29/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 6.8845e-04 - val_loss: 0.0013\n",
      "Epoch 30/30\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 6.2906e-04 - val_loss: 0.0015\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ Step 7: Train Model\n",
    "es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[es]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2940ea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved to D:/stock_prediction/models/TCS_lstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Œ Step 8: Save Model\n",
    "model.save(r'D:\\stock_prediction\\models\\TCS_lstm_model.h5')\n",
    "print(\"âœ… Model saved to D:/stock_prediction/models/TCS_lstm_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e925c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'D:\\stock_prediction\\models\\TCS_scaler_max.npy', scaler.data_max_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d70bb04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539ms/step\n",
      "ğŸ“ˆ Predicted next closing price for TCS: â‚¹2989.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owais\\AppData\\Local\\Temp\\ipykernel_20120\\1015568963.py:29: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predicted_price = float(scaled_prediction.flatten()[0] * scaler_max)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ğŸ“Œ Paths\n",
    "csv_path = r'D:\\stock_prediction\\data\\TCS.csv'\n",
    "model_path = r'D:\\stock_prediction\\models\\TCS_lstm_model.h5'\n",
    "scaler_max_path = r'D:\\stock_prediction\\models\\TCS_scaler_max.npy'\n",
    "\n",
    "# ğŸ“Œ Load data\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df[['Close']]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# ğŸ“Œ Use last 60 days for prediction\n",
    "last_60_days = df[-60:].values\n",
    "scaler_max = np.load(scaler_max_path)\n",
    "scaled_last_60 = last_60_days / scaler_max  # Manual scaling\n",
    "\n",
    "# ğŸ“Œ Reshape to (1, 60, 1)\n",
    "X_pred = np.reshape(scaled_last_60, (1, 60, 1))\n",
    "\n",
    "# ğŸ“Œ Load model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# ğŸ“Œ Predict\n",
    "scaled_prediction = model.predict(X_pred)\n",
    "predicted_price = float(scaled_prediction.flatten()[0] * scaler_max)\n",
    "\n",
    "print(f\"ğŸ“ˆ Predicted next closing price for TCS: â‚¹{float(predicted_price):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ad409c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29bda266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40d46aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r'D:/stock_prediction/data'\n",
    "MODEL_DIR = r'D:/stock_prediction/models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "SEQUENCE_LENGTH = 60\n",
    "invalid_files = ['stock_metadata.csv', 'NIFTY50_all.csv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "071ac359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 0.0080 - val_loss: 0.0011\n",
      "Epoch 2/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0014 - val_loss: 7.7866e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0011 - val_loss: 5.4106e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 6.8624e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 8.7221e-04 - val_loss: 3.7139e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 8.0820e-04 - val_loss: 4.7431e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0010 - val_loss: 4.7672e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 7.1505e-04 - val_loss: 5.1391e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 9.1639e-04 - val_loss: 3.1522e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 5.8256e-04 - val_loss: 3.4045e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 8.0645e-04 - val_loss: 4.4083e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 7.5501e-04 - val_loss: 2.5583e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 7.4014e-04 - val_loss: 2.4779e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.3048e-04 - val_loss: 2.5863e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 5.9362e-04 - val_loss: 2.3649e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 6.4226e-04 - val_loss: 2.4051e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 5.0306e-04 - val_loss: 2.7695e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 5.7338e-04 - val_loss: 1.9224e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 5.4023e-04 - val_loss: 1.8883e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 4.4345e-04 - val_loss: 1.7886e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 5.4930e-04 - val_loss: 1.7720e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 4.2915e-04 - val_loss: 2.4969e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 4.8289e-04 - val_loss: 1.8126e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 4.1559e-04 - val_loss: 2.0149e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 4.3956e-04 - val_loss: 1.6712e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 4.0707e-04 - val_loss: 2.2926e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.8648e-04 - val_loss: 2.2447e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 3.3466e-04 - val_loss: 3.0878e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 3.9941e-04 - val_loss: 2.0780e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m92/92\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 6.2121e-04 - val_loss: 1.7991e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADANIPORTS model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - loss: 0.0159 - val_loss: 2.5764e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0021 - val_loss: 2.4502e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 0.0017 - val_loss: 2.0380e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0012 - val_loss: 2.0306e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0013 - val_loss: 2.1816e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 0.0016 - val_loss: 2.9026e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 1.7157e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 8.9507e-04 - val_loss: 1.2183e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 9.6498e-04 - val_loss: 1.9010e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 9.6876e-04 - val_loss: 2.2703e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 6.3992e-04 - val_loss: 5.1010e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 0.0011 - val_loss: 1.1850e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 9.1272e-04 - val_loss: 2.4148e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 5.6285e-04 - val_loss: 1.5192e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 8.9255e-04 - val_loss: 9.5552e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 5.8540e-04 - val_loss: 2.0075e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 2.3598e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 7.1265e-04 - val_loss: 8.8335e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 7.5541e-04 - val_loss: 8.7859e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 6.9634e-04 - val_loss: 1.3999e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 5.4200e-04 - val_loss: 8.8094e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 6.6212e-04 - val_loss: 1.2205e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0015 - val_loss: 1.9251e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 6.8991e-04 - val_loss: 1.0980e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ASIANPAINT model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - loss: 0.0134 - val_loss: 7.1462e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 0.0024 - val_loss: 6.6981e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0020 - val_loss: 4.0005e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 0.0020 - val_loss: 3.4209e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - loss: 0.0015 - val_loss: 3.4585e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 0.0017 - val_loss: 2.1297e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 0.0015 - val_loss: 2.2004e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.0011 - val_loss: 1.9699e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - loss: 0.0010 - val_loss: 2.1730e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - loss: 9.9090e-04 - val_loss: 1.9409e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 0.0016 - val_loss: 1.6924e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 1.8615e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 7.7281e-04 - val_loss: 4.8557e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 0.0011 - val_loss: 2.0406e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 9.8901e-04 - val_loss: 1.4192e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 9.5634e-04 - val_loss: 1.4135e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 8.7820e-04 - val_loss: 1.4432e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 7.9114e-04 - val_loss: 1.3461e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 8.1228e-04 - val_loss: 1.5793e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 7.5105e-04 - val_loss: 1.3194e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 6.4871e-04 - val_loss: 2.8120e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 8.6362e-04 - val_loss: 1.3541e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 6.2846e-04 - val_loss: 1.1342e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 7.3505e-04 - val_loss: 1.2941e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 8.8360e-04 - val_loss: 2.1790e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 6.8010e-04 - val_loss: 1.4048e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 7.8200e-04 - val_loss: 1.2809e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 5.6319e-04 - val_loss: 2.7868e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AXISBANK model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 0.0455 - val_loss: 0.0022\n",
      "Epoch 2/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 3/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 4/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 5/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 6/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 7/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 8/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 9/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 10/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 11/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 12/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 13/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 14/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0015 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BAJAJ-AUTO model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 0.0138 - val_loss: 0.0038\n",
      "Epoch 2/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 8.7995e-04 - val_loss: 0.0034\n",
      "Epoch 3/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0010 - val_loss: 0.0032\n",
      "Epoch 4/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 8.5831e-04 - val_loss: 0.0034\n",
      "Epoch 5/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 9.0545e-04 - val_loss: 0.0029\n",
      "Epoch 6/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 9.0226e-04 - val_loss: 0.0033\n",
      "Epoch 7/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 8/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 8.6444e-04 - val_loss: 0.0034\n",
      "Epoch 9/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 7.2655e-04 - val_loss: 0.0022\n",
      "Epoch 10/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 6.6912e-04 - val_loss: 0.0022\n",
      "Epoch 11/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 6.1868e-04 - val_loss: 0.0021\n",
      "Epoch 12/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 6.2141e-04 - val_loss: 0.0038\n",
      "Epoch 13/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 7.5253e-04 - val_loss: 0.0030\n",
      "Epoch 14/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 7.5524e-04 - val_loss: 0.0019\n",
      "Epoch 15/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 5.8106e-04 - val_loss: 0.0020\n",
      "Epoch 16/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 6.5034e-04 - val_loss: 0.0018\n",
      "Epoch 17/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 4.9987e-04 - val_loss: 0.0018\n",
      "Epoch 18/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 5.6946e-04 - val_loss: 0.0017\n",
      "Epoch 19/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 5.3118e-04 - val_loss: 0.0019\n",
      "Epoch 20/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 5.6708e-04 - val_loss: 0.0020\n",
      "Epoch 21/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 5.6688e-04 - val_loss: 0.0017\n",
      "Epoch 22/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 5.1468e-04 - val_loss: 0.0020\n",
      "Epoch 23/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 5.8225e-04 - val_loss: 0.0024\n",
      "Epoch 24/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 6.2914e-04 - val_loss: 0.0015\n",
      "Epoch 25/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 4.8133e-04 - val_loss: 0.0015\n",
      "Epoch 26/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 4.7529e-04 - val_loss: 0.0015\n",
      "Epoch 27/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - loss: 5.0245e-04 - val_loss: 0.0016\n",
      "Epoch 28/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 5.2261e-04 - val_loss: 0.0021\n",
      "Epoch 29/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.9790e-04 - val_loss: 0.0014\n",
      "Epoch 30/30\n",
      "\u001b[1m89/89\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 4.8908e-04 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BAJAJFINSV model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 0.0071 - val_loss: 8.4982e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0015 - val_loss: 5.2802e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 9.2566e-04 - val_loss: 3.6405e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 7.6134e-04 - val_loss: 4.5275e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 7.0923e-04 - val_loss: 9.1161e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 7.1908e-04 - val_loss: 3.0202e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 4.3641e-04 - val_loss: 3.0286e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 7.5952e-04 - val_loss: 2.6666e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 8.6413e-04 - val_loss: 2.3200e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 0.0010 - val_loss: 6.4451e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 5.5439e-04 - val_loss: 2.1859e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 6.5039e-04 - val_loss: 2.5701e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 5.4168e-04 - val_loss: 1.7577e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 7.0650e-04 - val_loss: 1.7594e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 5.3797e-04 - val_loss: 2.8877e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 4.7078e-04 - val_loss: 1.6448e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 5.7696e-04 - val_loss: 2.3265e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 3.0897e-04 - val_loss: 4.1251e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 7.5076e-04 - val_loss: 1.5511e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.7048e-04 - val_loss: 1.6728e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 5.1578e-04 - val_loss: 1.5570e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 5.1763e-04 - val_loss: 2.1320e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 5.8304e-04 - val_loss: 1.4113e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 4.3163e-04 - val_loss: 2.3031e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 4.3277e-04 - val_loss: 3.6639e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 3.9940e-04 - val_loss: 1.3496e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 3.3403e-04 - val_loss: 3.7577e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 5.3414e-04 - val_loss: 3.1509e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 5.2510e-04 - val_loss: 6.2449e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 71ms/step - loss: 3.2335e-04 - val_loss: 2.8266e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BAJFINANCE model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - loss: 0.0235 - val_loss: 5.8636e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - loss: 0.0018 - val_loss: 6.4308e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 90ms/step - loss: 0.0017 - val_loss: 5.3202e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 88ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 5/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 90ms/step - loss: 0.0014 - val_loss: 3.8740e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 85ms/step - loss: 0.0013 - val_loss: 4.3393e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - loss: 0.0011 - val_loss: 7.6686e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 7.4931e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - loss: 0.0013 - val_loss: 4.1252e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - loss: 0.0011 - val_loss: 3.4009e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 9.1026e-04 - val_loss: 2.6768e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 0.0011 - val_loss: 6.1081e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 42ms/step - loss: 9.3423e-04 - val_loss: 3.9305e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - loss: 8.3682e-04 - val_loss: 3.1720e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - loss: 8.6186e-04 - val_loss: 3.2832e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - loss: 7.9241e-04 - val_loss: 2.6557e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - loss: 8.0485e-04 - val_loss: 2.4684e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - loss: 6.6316e-04 - val_loss: 2.1187e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 6.8237e-04 - val_loss: 2.1903e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 7.4377e-04 - val_loss: 2.0599e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 6.5486e-04 - val_loss: 2.0082e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 6.8891e-04 - val_loss: 1.9884e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 6.4412e-04 - val_loss: 2.2367e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 7.3461e-04 - val_loss: 2.1548e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 6.3918e-04 - val_loss: 2.1732e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 5.8543e-04 - val_loss: 1.9865e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 5.8564e-04 - val_loss: 1.8002e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - loss: 5.1838e-04 - val_loss: 2.1598e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - loss: 4.9114e-04 - val_loss: 1.9751e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - loss: 4.9486e-04 - val_loss: 2.1281e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BHARTIARTL model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - loss: 0.0151 - val_loss: 6.1329e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 0.0025 - val_loss: 5.7322e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0020 - val_loss: 7.9729e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0018 - val_loss: 4.4393e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0015 - val_loss: 4.4084e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0014 - val_loss: 4.8620e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0013 - val_loss: 3.4077e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 5.6096e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 5.6401e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 3.4347e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 2.7315e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 7.5716e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 9.4467e-04 - val_loss: 3.7506e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 7.9095e-04 - val_loss: 3.2971e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 8.7336e-04 - val_loss: 2.5024e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 8.6440e-04 - val_loss: 2.3112e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 8.4191e-04 - val_loss: 2.1145e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 7.8812e-04 - val_loss: 3.3939e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0011 - val_loss: 2.2850e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 7.2056e-04 - val_loss: 2.0808e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 8.4422e-04 - val_loss: 2.4836e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 8.4284e-04 - val_loss: 2.4808e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 7.2341e-04 - val_loss: 2.0660e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 85ms/step - loss: 7.1408e-04 - val_loss: 1.9172e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 81ms/step - loss: 7.9116e-04 - val_loss: 1.7529e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 81ms/step - loss: 6.7498e-04 - val_loss: 2.1492e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 82ms/step - loss: 7.0078e-04 - val_loss: 1.7064e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 83ms/step - loss: 6.9096e-04 - val_loss: 1.6576e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 82ms/step - loss: 6.0237e-04 - val_loss: 1.6329e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 81ms/step - loss: 5.4129e-04 - val_loss: 2.2693e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BPCL model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 79ms/step - loss: 0.0123 - val_loss: 4.2548e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - loss: 0.0011 - val_loss: 5.6297e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step - loss: 8.8166e-04 - val_loss: 3.0376e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 77ms/step - loss: 8.5881e-04 - val_loss: 2.9060e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 75ms/step - loss: 8.4770e-04 - val_loss: 3.0989e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 77ms/step - loss: 8.6002e-04 - val_loss: 5.6605e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 77ms/step - loss: 7.9009e-04 - val_loss: 2.5310e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 76ms/step - loss: 8.7248e-04 - val_loss: 3.1279e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 77ms/step - loss: 6.0188e-04 - val_loss: 7.5785e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 76ms/step - loss: 7.8333e-04 - val_loss: 2.1354e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 80ms/step - loss: 6.0434e-04 - val_loss: 3.1460e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 79ms/step - loss: 5.8264e-04 - val_loss: 2.6029e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - loss: 5.2432e-04 - val_loss: 3.0581e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 79ms/step - loss: 5.9729e-04 - val_loss: 1.9252e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 80ms/step - loss: 5.4259e-04 - val_loss: 4.3340e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - loss: 5.1686e-04 - val_loss: 3.9146e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 83ms/step - loss: 4.4109e-04 - val_loss: 0.0017\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 80ms/step - loss: 6.3465e-04 - val_loss: 3.0884e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 82ms/step - loss: 4.9246e-04 - val_loss: 5.0800e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BRITANNIA model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 87ms/step - loss: 0.0139 - val_loss: 4.8264e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 80ms/step - loss: 0.0023 - val_loss: 8.4946e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 82ms/step - loss: 0.0020 - val_loss: 3.4223e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 81ms/step - loss: 0.0017 - val_loss: 3.4323e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 81ms/step - loss: 0.0017 - val_loss: 3.1418e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 82ms/step - loss: 0.0017 - val_loss: 7.1622e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 80ms/step - loss: 0.0017 - val_loss: 2.7442e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 87ms/step - loss: 0.0011 - val_loss: 2.0775e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 84ms/step - loss: 0.0012 - val_loss: 1.9221e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 64ms/step - loss: 9.5491e-04 - val_loss: 3.1198e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - loss: 9.4597e-04 - val_loss: 1.9602e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 2.7833e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0010 - val_loss: 1.6875e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.0010 - val_loss: 2.7131e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 8.5004e-04 - val_loss: 2.1345e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 8.4082e-04 - val_loss: 1.5024e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 1.6196e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 7.5118e-04 - val_loss: 1.5219e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 7.8815e-04 - val_loss: 2.4006e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 6.8827e-04 - val_loss: 1.4004e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 7.0341e-04 - val_loss: 1.4315e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 8.4546e-04 - val_loss: 1.3202e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 6.1122e-04 - val_loss: 3.5726e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 7.8429e-04 - val_loss: 1.3125e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 1.2828e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 5.8234e-04 - val_loss: 1.2695e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 6.8078e-04 - val_loss: 1.8429e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 8.5581e-04 - val_loss: 1.2033e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 6.8027e-04 - val_loss: 1.2117e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 6.2992e-04 - val_loss: 1.2242e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CIPLA model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0779 - val_loss: 0.0067\n",
      "Epoch 2/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.0047 - val_loss: 0.0011\n",
      "Epoch 3/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0043 - val_loss: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0047 - val_loss: 8.6235e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0040 - val_loss: 8.8959e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0038 - val_loss: 4.0686e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0038 - val_loss: 3.8017e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0032 - val_loss: 3.7527e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0034 - val_loss: 3.8997e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0037 - val_loss: 3.3603e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0029 - val_loss: 4.2943e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 0.0034 - val_loss: 3.6238e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0028 - val_loss: 3.3425e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.0033 - val_loss: 3.3661e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - loss: 0.0027 - val_loss: 3.1345e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.0027 - val_loss: 3.2160e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0028 - val_loss: 3.5388e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0027 - val_loss: 3.5496e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0026 - val_loss: 3.0700e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0025 - val_loss: 3.9168e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0021 - val_loss: 4.6816e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0025 - val_loss: 2.8742e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0022 - val_loss: 3.0211e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0023 - val_loss: 2.8478e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0021 - val_loss: 2.6207e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0021 - val_loss: 3.0513e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0020 - val_loss: 2.6732e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0022 - val_loss: 3.4697e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0019 - val_loss: 2.6465e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m72/72\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0018 - val_loss: 4.9454e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… COALINDIA model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 0.0095 - val_loss: 0.0023\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 9.0788e-04 - val_loss: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 8.8421e-04 - val_loss: 0.0020\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 8.1892e-04 - val_loss: 9.1371e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 8.5417e-04 - val_loss: 0.0014\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.7235e-04 - val_loss: 0.0020\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 7.4356e-04 - val_loss: 0.0015\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.5835e-04 - val_loss: 0.0015\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.0530e-04 - val_loss: 6.5160e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 5.9102e-04 - val_loss: 5.8727e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 4.9472e-04 - val_loss: 6.5352e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 5.1566e-04 - val_loss: 6.1220e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 4.9526e-04 - val_loss: 0.0015\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 4.7616e-04 - val_loss: 7.0233e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 4.8780e-04 - val_loss: 8.2335e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DRREDDY model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - loss: 0.0143 - val_loss: 0.0047\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 9.0942e-04 - val_loss: 0.0031\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 9.5957e-04 - val_loss: 0.0033\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 7.8080e-04 - val_loss: 0.0034\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 8.9347e-04 - val_loss: 0.0036\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 8.9508e-04 - val_loss: 0.0029\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 9.6098e-04 - val_loss: 0.0028\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 8.0434e-04 - val_loss: 0.0029\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.7544e-04 - val_loss: 0.0040\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.7083e-04 - val_loss: 0.0026\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 7.3587e-04 - val_loss: 0.0025\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.2690e-04 - val_loss: 0.0024\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 7.5906e-04 - val_loss: 0.0024\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 8.1674e-04 - val_loss: 0.0023\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.0768e-04 - val_loss: 0.0024\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.7333e-04 - val_loss: 0.0022\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 8.4542e-04 - val_loss: 0.0021\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 6.8605e-04 - val_loss: 0.0021\n",
      "Epoch 27/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 8.1379e-04 - val_loss: 0.0021\n",
      "Epoch 28/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 7.2163e-04 - val_loss: 0.0033\n",
      "Epoch 29/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.9064e-04 - val_loss: 0.0020\n",
      "Epoch 30/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 6.5318e-04 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… EICHERMOT model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - loss: 0.0383 - val_loss: 0.0017\n",
      "Epoch 2/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 3/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 4/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 5/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 6/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 7/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 8/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 9/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0024 - val_loss: 9.8297e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0023 - val_loss: 8.5960e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 12/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0022 - val_loss: 7.9396e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0020 - val_loss: 8.0944e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0022 - val_loss: 7.7321e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0018 - val_loss: 8.2180e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0018 - val_loss: 7.1663e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0016 - val_loss: 6.8391e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0016 - val_loss: 6.5034e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 7.0149e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0015 - val_loss: 7.1405e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 6.3974e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0014 - val_loss: 5.9855e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 5.8183e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0014 - val_loss: 6.6916e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 5.9482e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 6.9164e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 5.7627e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 9.7698e-04 - val_loss: 5.8741e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0010 - val_loss: 5.6114e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.5011e-04 - val_loss: 5.5720e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GAIL model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.0260 - val_loss: 8.2165e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0024 - val_loss: 1.7810e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0023 - val_loss: 5.7262e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0017 - val_loss: 5.8724e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0015 - val_loss: 7.9454e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 2.7246e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0017 - val_loss: 2.0857e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0017 - val_loss: 6.5043e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GRASIM model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 0.0075 - val_loss: 5.8181e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 8.7865e-04 - val_loss: 5.8974e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - loss: 7.7568e-04 - val_loss: 6.0312e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 6.8574e-04 - val_loss: 5.6829e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 6.9643e-04 - val_loss: 8.4969e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - loss: 5.8453e-04 - val_loss: 4.7775e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 5.5601e-04 - val_loss: 4.1170e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.0589e-04 - val_loss: 3.2300e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.2998e-04 - val_loss: 3.1776e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 5.8575e-04 - val_loss: 2.9389e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 5.0250e-04 - val_loss: 2.7617e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 3.5075e-04 - val_loss: 4.3015e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.7313e-04 - val_loss: 2.7691e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 4.0255e-04 - val_loss: 3.1156e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.9331e-04 - val_loss: 4.6854e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 4.3898e-04 - val_loss: 2.4466e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.2094e-04 - val_loss: 2.1527e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.6278e-04 - val_loss: 2.1008e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.7793e-04 - val_loss: 2.0023e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.5210e-04 - val_loss: 1.9019e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.9845e-04 - val_loss: 2.2979e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.2509e-04 - val_loss: 2.1709e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.4535e-04 - val_loss: 1.8237e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.8816e-04 - val_loss: 1.8861e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.9582e-04 - val_loss: 1.7445e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.5273e-04 - val_loss: 1.7109e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.5565e-04 - val_loss: 1.5903e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.5601e-04 - val_loss: 1.5988e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.8302e-04 - val_loss: 1.9821e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.4612e-04 - val_loss: 1.6175e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HCLTECH model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 0.0244 - val_loss: 0.0012\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0019 - val_loss: 7.1577e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0018 - val_loss: 8.9658e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 0.0016 - val_loss: 6.5465e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0015 - val_loss: 7.1609e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 5.7751e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 8.2507e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 5.2005e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 4.9545e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 8.8828e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 8.3448e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 6.2293e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.8267e-04 - val_loss: 5.2331e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.9360e-04 - val_loss: 4.7098e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.3292e-04 - val_loss: 0.0021\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 9.5471e-04 - val_loss: 5.9551e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 8.4590e-04 - val_loss: 0.0013\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 0.0011 - val_loss: 5.0873e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 7.4566e-04 - val_loss: 7.0304e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HDFC model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 0.0191 - val_loss: 0.0025\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0016 - val_loss: 9.5627e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 9.2586e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 8.9019e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.8474e-04 - val_loss: 9.9374e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.4650e-04 - val_loss: 9.7520e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.8474e-04 - val_loss: 0.0013\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 8.0380e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.0185e-04 - val_loss: 7.9804e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 8.4687e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0015 - val_loss: 8.7915e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.4325e-04 - val_loss: 7.9544e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 8.4062e-04 - val_loss: 0.0011\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 7.6170e-04 - val_loss: 7.6723e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.9609e-04 - val_loss: 6.9738e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.4206e-04 - val_loss: 7.1512e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.8506e-04 - val_loss: 6.7276e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.9447e-04 - val_loss: 6.5709e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HDFCBANK model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 0.0284 - val_loss: 0.0011\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 8.7274e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 7.6487e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 7.9561e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 8.6982e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 6.6263e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 6.3408e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 6.3205e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0010 - val_loss: 6.0530e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 6.1050e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.8269e-04 - val_loss: 6.5610e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.8561e-04 - val_loss: 9.0671e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.4078e-04 - val_loss: 6.2939e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 9.0045e-04 - val_loss: 5.5099e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.4356e-04 - val_loss: 6.4987e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.0894e-04 - val_loss: 8.7929e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.4710e-04 - val_loss: 5.6007e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.5224e-04 - val_loss: 8.3000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.3837e-04 - val_loss: 5.3021e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.6149e-04 - val_loss: 4.7831e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.0639e-04 - val_loss: 4.6193e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.2245e-04 - val_loss: 4.5196e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 6.8006e-04 - val_loss: 8.4839e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.7669e-04 - val_loss: 4.6539e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HEROMOTOCO model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0213 - val_loss: 4.5057e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0029 - val_loss: 9.9291e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0018 - val_loss: 1.5489e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0018 - val_loss: 7.2280e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0016 - val_loss: 5.2856e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0019 - val_loss: 5.6810e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 5.6008e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0018 - val_loss: 1.2054e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 9.7196e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 1.1410e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HINDALCO model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - loss: 0.0075 - val_loss: 7.2047e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.1258e-04 - val_loss: 5.9200e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.8384e-04 - val_loss: 8.1481e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.1121e-04 - val_loss: 0.0052\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.9269e-04 - val_loss: 5.5259e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.7611e-04 - val_loss: 4.7991e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 6.0015e-04 - val_loss: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 6.3569e-04 - val_loss: 4.7171e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 6.0391e-04 - val_loss: 2.6723e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.8626e-04 - val_loss: 7.3770e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 6.2670e-04 - val_loss: 3.1740e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.2638e-04 - val_loss: 0.0013\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.4258e-04 - val_loss: 0.0014\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.2419e-04 - val_loss: 1.9585e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.7868e-04 - val_loss: 2.8418e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.9617e-04 - val_loss: 9.7163e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 5.4902e-04 - val_loss: 5.6970e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 4.3290e-04 - val_loss: 0.0018\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.7491e-04 - val_loss: 2.9729e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HINDUNILVR model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 0.0189 - val_loss: 2.5172e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0025 - val_loss: 2.0047e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0020 - val_loss: 2.2019e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 3.2668e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0016 - val_loss: 2.0039e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 3.2536e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 1.9464e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 1.6759e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 1.4998e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 1.0687e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 1.6987e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 1.1377e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.6168e-04 - val_loss: 1.2067e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 1.3435e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 9.2499e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.1400e-04 - val_loss: 1.1329e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.5394e-04 - val_loss: 8.6651e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.5251e-04 - val_loss: 9.9017e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.1087e-04 - val_loss: 1.2989e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.7350e-04 - val_loss: 7.8903e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.3612e-04 - val_loss: 8.4736e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.2161e-04 - val_loss: 8.8760e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.5311e-04 - val_loss: 8.5237e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.4222e-04 - val_loss: 1.4098e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.7672e-04 - val_loss: 1.1172e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ICICIBANK model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 0.0208 - val_loss: 0.0027\n",
      "Epoch 2/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 3/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 0.0035\n",
      "Epoch 4/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 5/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 6/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 7/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 8/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.0735e-04 - val_loss: 0.0017\n",
      "Epoch 9/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 8.8437e-04 - val_loss: 0.0017\n",
      "Epoch 10/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.5468e-04 - val_loss: 0.0018\n",
      "Epoch 11/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.8653e-04 - val_loss: 0.0034\n",
      "Epoch 12/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 8.4075e-04 - val_loss: 0.0019\n",
      "Epoch 13/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 7.8060e-04 - val_loss: 0.0016\n",
      "Epoch 14/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.2742e-04 - val_loss: 0.0016\n",
      "Epoch 15/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.9566e-04 - val_loss: 0.0022\n",
      "Epoch 16/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.2179e-04 - val_loss: 0.0023\n",
      "Epoch 17/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.2946e-04 - val_loss: 0.0019\n",
      "Epoch 18/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.4381e-04 - val_loss: 0.0014\n",
      "Epoch 19/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.4633e-04 - val_loss: 0.0018\n",
      "Epoch 20/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 6.9508e-04 - val_loss: 0.0013\n",
      "Epoch 21/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.8120e-04 - val_loss: 0.0014\n",
      "Epoch 22/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 5.9958e-04 - val_loss: 0.0018\n",
      "Epoch 23/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6.2309e-04 - val_loss: 0.0013\n",
      "Epoch 24/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.2840e-04 - val_loss: 0.0012\n",
      "Epoch 25/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 7.0046e-04 - val_loss: 0.0014\n",
      "Epoch 26/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 5.9561e-04 - val_loss: 0.0012\n",
      "Epoch 27/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 5.7069e-04 - val_loss: 0.0016\n",
      "Epoch 28/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6.1793e-04 - val_loss: 0.0012\n",
      "Epoch 29/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.4488e-04 - val_loss: 0.0011\n",
      "Epoch 30/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.0106e-04 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… INDUSINDBK model saved!\n",
      "âŒ Error training INFRATEL: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0034 - val_loss: 3.6437e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 5.0205e-04 - val_loss: 1.8334e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.7417e-04 - val_loss: 5.2245e-06\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.4455e-04 - val_loss: 4.3625e-06\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.4774e-04 - val_loss: 1.6049e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.2445e-04 - val_loss: 5.6046e-06\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 2.5883e-04 - val_loss: 9.6741e-06\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.7475e-04 - val_loss: 1.2204e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.5841e-04 - val_loss: 3.0793e-06\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 2.5783e-04 - val_loss: 3.5124e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.3941e-04 - val_loss: 2.7328e-06\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.0981e-04 - val_loss: 1.4910e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 1.9610e-04 - val_loss: 3.3331e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 1.8027e-04 - val_loss: 2.4971e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 1.8622e-04 - val_loss: 5.9080e-06\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 1.9561e-04 - val_loss: 8.6895e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… INFY model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0165 - val_loss: 3.2496e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0029 - val_loss: 1.5448e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0023 - val_loss: 1.1315e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0022 - val_loss: 6.0955e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0019 - val_loss: 4.6278e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0019 - val_loss: 4.0712e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0016 - val_loss: 5.3465e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0016 - val_loss: 1.2994e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 4.7339e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0014 - val_loss: 3.2997e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 3.6756e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0010 - val_loss: 2.9848e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 3.1245e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0010 - val_loss: 1.0621e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.0625e-04 - val_loss: 2.5011e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 1.2080e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.4577e-04 - val_loss: 2.8773e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 8.7239e-04 - val_loss: 2.2971e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.1493e-04 - val_loss: 1.3938e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.0876e-04 - val_loss: 2.2915e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.9466e-04 - val_loss: 2.7171e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.0236e-04 - val_loss: 5.8218e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.1697e-04 - val_loss: 1.2197e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 6.0399e-04 - val_loss: 4.4280e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.1780e-04 - val_loss: 1.1075e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… IOC model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - loss: 0.0072 - val_loss: 9.4301e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0022 - val_loss: 5.1577e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 3.6307e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 2.9849e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.7558e-04 - val_loss: 1.9587e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.9016e-04 - val_loss: 4.1883e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0010 - val_loss: 5.5525e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 1.3486e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0015 - val_loss: 3.2032e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.5686e-04 - val_loss: 4.7442e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 5.7701e-04 - val_loss: 1.0354e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.7752e-04 - val_loss: 1.5505e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.4243e-04 - val_loss: 3.5055e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ITC model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 0.0266 - val_loss: 2.4614e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0035 - val_loss: 5.4525e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0025 - val_loss: 1.7023e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0032 - val_loss: 1.5338e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0023 - val_loss: 1.1244e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0023 - val_loss: 1.0877e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0019 - val_loss: 1.1930e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0023 - val_loss: 1.0752e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0020 - val_loss: 1.0286e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0022 - val_loss: 1.2879e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0021 - val_loss: 9.4029e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0019 - val_loss: 1.2254e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 7.8126e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 1.1347e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 7.8194e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0016 - val_loss: 2.8508e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 6.2835e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0015 - val_loss: 7.5349e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0023 - val_loss: 7.8006e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 8.6626e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 5.7549e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 8.9615e-04 - val_loss: 5.7714e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 9.4298e-04 - val_loss: 1.3130e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0014 - val_loss: 5.7111e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 7.1514e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 9.1882e-04 - val_loss: 7.6784e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 9.5668e-04 - val_loss: 6.4888e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0010 - val_loss: 1.2636e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 6.8387e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… JSWSTEEL model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 0.0189 - val_loss: 0.0030\n",
      "Epoch 2/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 3/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 4/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 5/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 6/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 7/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 9.9324e-04 - val_loss: 0.0011\n",
      "Epoch 8/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 9.3357e-04 - val_loss: 0.0015\n",
      "Epoch 9/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 7.7925e-04 - val_loss: 7.9894e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 8.6099e-04 - val_loss: 9.3777e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 7.0877e-04 - val_loss: 0.0014\n",
      "Epoch 12/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 7.1266e-04 - val_loss: 8.0008e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.1186e-04 - val_loss: 7.3543e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 6.5817e-04 - val_loss: 6.7420e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.7103e-04 - val_loss: 6.2698e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.0965e-04 - val_loss: 0.0015\n",
      "Epoch 17/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 5.7945e-04 - val_loss: 7.1922e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 5.1803e-04 - val_loss: 8.3994e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 5.3920e-04 - val_loss: 0.0011\n",
      "Epoch 20/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 5.2987e-04 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… KOTAKBANK model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0158 - val_loss: 2.9019e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0019 - val_loss: 2.4463e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0017 - val_loss: 1.8729e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0015 - val_loss: 1.8058e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 1.9032e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0015 - val_loss: 1.7892e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 1.8446e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0010 - val_loss: 1.4435e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 1.2843e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 9.4140e-04 - val_loss: 1.3181e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 9.9830e-04 - val_loss: 1.2789e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 8.3547e-04 - val_loss: 1.5753e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 7.9306e-04 - val_loss: 1.4084e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 7.1251e-04 - val_loss: 1.5359e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 8.4818e-04 - val_loss: 1.1418e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 7.3563e-04 - val_loss: 1.9380e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.4657e-04 - val_loss: 1.0661e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 7.7193e-04 - val_loss: 1.3630e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 6.1926e-04 - val_loss: 1.5743e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 7.2184e-04 - val_loss: 1.3205e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 5.1871e-04 - val_loss: 1.4683e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 6.0079e-04 - val_loss: 8.0529e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6.7637e-04 - val_loss: 1.0679e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 5.6466e-04 - val_loss: 1.3489e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 5.0521e-04 - val_loss: 8.1160e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.8262e-04 - val_loss: 9.4228e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m116/116\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 4.5160e-04 - val_loss: 8.0595e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LT model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 0.0236 - val_loss: 0.0021\n",
      "Epoch 2/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 3/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 4/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 5/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 6/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 7/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 9.9082e-04 - val_loss: 0.0024\n",
      "Epoch 8/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 9/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 9.7415e-04 - val_loss: 9.1865e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 8.9766e-04 - val_loss: 0.0013\n",
      "Epoch 11/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 8.7583e-04 - val_loss: 0.0027\n",
      "Epoch 12/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 8.4832e-04 - val_loss: 8.4625e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 8.3718e-04 - val_loss: 8.6089e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 7.0802e-04 - val_loss: 8.3644e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 8.1329e-04 - val_loss: 0.0014\n",
      "Epoch 16/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 8.6385e-04 - val_loss: 9.2236e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 8.9188e-04 - val_loss: 7.9745e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 6.6779e-04 - val_loss: 9.4497e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.6544e-04 - val_loss: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.4099e-04 - val_loss: 9.5199e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.8854e-04 - val_loss: 9.6146e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.7286e-04 - val_loss: 8.1050e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MARUTI model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 0.0445 - val_loss: 5.8211e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0030 - val_loss: 5.2392e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0028 - val_loss: 6.9956e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0028 - val_loss: 4.2472e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0026 - val_loss: 4.0562e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0021 - val_loss: 3.7470e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0021 - val_loss: 4.1028e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0021 - val_loss: 3.2527e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0017 - val_loss: 3.3270e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0021 - val_loss: 5.2902e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0017 - val_loss: 2.7737e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 2.5944e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 2.5346e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 3.3799e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 2.3352e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 2.3002e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 2.4424e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 2.2986e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 2.7133e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 1.9305e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 3.0138e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0010 - val_loss: 1.9226e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 1.8510e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 9.2696e-04 - val_loss: 1.8202e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0010 - val_loss: 1.7072e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.7302e-04 - val_loss: 1.7279e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0010 - val_loss: 1.6011e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.2640e-04 - val_loss: 1.5745e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.4720e-04 - val_loss: 2.6970e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.6193e-04 - val_loss: 1.5604e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MM model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 0.0130 - val_loss: 0.0041\n",
      "Epoch 2/30\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 3/30\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 4/30\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 9.3042e-04 - val_loss: 0.0022\n",
      "Epoch 5/30\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 8.5372e-04 - val_loss: 0.0020\n",
      "Epoch 6/30\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 8.1874e-04 - val_loss: 0.0040\n",
      "Epoch 7/30\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 9.2392e-04 - val_loss: 0.0016\n",
      "Epoch 8/30\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 7.6726e-04 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… NESTLEIND model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0180 - val_loss: 0.0011\n",
      "Epoch 2/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0022 - val_loss: 9.0289e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - loss: 0.0020 - val_loss: 6.0064e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.0019 - val_loss: 5.0900e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.0016 - val_loss: 3.9542e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0018 - val_loss: 6.6226e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0016 - val_loss: 4.2051e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0015 - val_loss: 3.4137e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 3.1930e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 3.0150e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 3.2947e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 3.3464e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 2.7676e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 2.6104e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 5.0405e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 3.2872e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 9.9811e-04 - val_loss: 2.5556e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 8.8608e-04 - val_loss: 2.4074e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 8.0850e-04 - val_loss: 2.5712e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 8.1837e-04 - val_loss: 2.3671e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 7.9056e-04 - val_loss: 2.3347e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 8.7905e-04 - val_loss: 2.4990e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 7.6914e-04 - val_loss: 2.1829e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 7.1855e-04 - val_loss: 2.0711e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 6.5176e-04 - val_loss: 2.4311e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 6.9432e-04 - val_loss: 3.9179e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 6.5876e-04 - val_loss: 2.0889e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.0620e-04 - val_loss: 3.8009e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m114/114\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 6.0663e-04 - val_loss: 2.1382e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… NTPC model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 0.0273 - val_loss: 7.7707e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0024 - val_loss: 1.9284e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0023 - val_loss: 7.3526e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0024 - val_loss: 2.9045e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0022 - val_loss: 4.6939e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0021 - val_loss: 4.1065e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 1.4736e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0017 - val_loss: 1.8637e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0018 - val_loss: 4.1741e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0016 - val_loss: 1.9050e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0017 - val_loss: 1.2982e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 3.4125e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 1.0755e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0014 - val_loss: 2.1625e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 9.0836e-06\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 9.1694e-06\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 2.4082e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0015 - val_loss: 8.4670e-06\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0010 - val_loss: 8.3556e-06\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0010 - val_loss: 3.9707e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 7.4824e-06\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.8663e-04 - val_loss: 2.5004e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 2.9187e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.6518e-04 - val_loss: 5.0468e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.7449e-04 - val_loss: 1.9117e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 8.1556e-04 - val_loss: 1.2983e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ONGC model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0400 - val_loss: 0.0022\n",
      "Epoch 2/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 3/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 4/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 5/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 6/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 7/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 8/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 9/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 10/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 11/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 12/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 13/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 14/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 15/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 16/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 17/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 18/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 19/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 20/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 21/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 22/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 23/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 24/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 25/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 26/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 27/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 28/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 29/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 9.6575e-04 - val_loss: 0.0012\n",
      "Epoch 30/30\n",
      "\u001b[1m93/93\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… POWERGRID model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.0120 - val_loss: 8.6293e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 0.0017 - val_loss: 6.2500e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 5.6610e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 4.7167e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.3788e-04 - val_loss: 7.9808e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.8067e-04 - val_loss: 5.0813e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.8838e-04 - val_loss: 4.2415e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.0157e-04 - val_loss: 9.4757e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.4924e-04 - val_loss: 5.4754e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.3970e-04 - val_loss: 5.2127e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.9444e-04 - val_loss: 6.6864e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.0343e-04 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RELIANCE model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 0.0142 - val_loss: 4.3664e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0025 - val_loss: 3.5126e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0020 - val_loss: 2.9659e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0020 - val_loss: 1.5984e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 5.1336e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 2.0347e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 2.8313e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 1.8547e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 1.7321e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0010 - val_loss: 1.6305e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 6.7938e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 1.4593e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 3.5441e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0010 - val_loss: 5.8981e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.5156e-04 - val_loss: 1.7324e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 2.1198e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.1169e-04 - val_loss: 1.5468e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SBIN model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0141 - val_loss: 0.0014\n",
      "Epoch 2/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.8214e-04 - val_loss: 0.0029\n",
      "Epoch 3/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 6.0213e-04 - val_loss: 0.0016\n",
      "Epoch 4/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 5.3852e-04 - val_loss: 0.0012\n",
      "Epoch 5/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.1894e-04 - val_loss: 0.0013\n",
      "Epoch 6/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 4.4861e-04 - val_loss: 0.0022\n",
      "Epoch 7/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.9948e-04 - val_loss: 0.0016\n",
      "Epoch 8/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.5919e-04 - val_loss: 0.0022\n",
      "Epoch 9/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 4.2720e-04 - val_loss: 9.7920e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.1477e-04 - val_loss: 9.1517e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.7775e-04 - val_loss: 0.0012\n",
      "Epoch 12/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.5713e-04 - val_loss: 0.0024\n",
      "Epoch 13/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 4.0649e-04 - val_loss: 0.0013\n",
      "Epoch 14/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.7843e-04 - val_loss: 8.1698e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.0107e-04 - val_loss: 8.0592e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.2989e-04 - val_loss: 0.0023\n",
      "Epoch 17/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.2228e-04 - val_loss: 7.7592e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 3.3511e-04 - val_loss: 7.6042e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.4411e-04 - val_loss: 7.0800e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.4995e-04 - val_loss: 7.6569e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.5548e-04 - val_loss: 0.0033\n",
      "Epoch 22/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.6971e-04 - val_loss: 0.0048\n",
      "Epoch 23/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.6611e-04 - val_loss: 7.5785e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.2051e-04 - val_loss: 6.5119e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.3429e-04 - val_loss: 6.8752e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.2945e-04 - val_loss: 0.0015\n",
      "Epoch 27/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.1781e-04 - val_loss: 0.0024\n",
      "Epoch 28/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.5552e-04 - val_loss: 9.0044e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m139/139\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 2.8666e-04 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SHREECEM model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - loss: 0.0071 - val_loss: 8.1741e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0015 - val_loss: 5.4164e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 7.5822e-04 - val_loss: 3.4993e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 9.9281e-04 - val_loss: 5.8404e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 7.1322e-04 - val_loss: 1.6668e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 7.2178e-04 - val_loss: 4.9674e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 7.3812e-04 - val_loss: 3.6978e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 5.4276e-04 - val_loss: 3.3399e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 6.9030e-04 - val_loss: 1.0637e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 6.7030e-04 - val_loss: 5.3594e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.7025e-04 - val_loss: 3.0534e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 4.0821e-04 - val_loss: 2.7152e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 5.2986e-04 - val_loss: 1.2488e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 5.6423e-04 - val_loss: 7.7352e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 8.8031e-04 - val_loss: 2.6150e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.9865e-04 - val_loss: 2.6045e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 8.2055e-04 - val_loss: 3.4317e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.6150e-04 - val_loss: 2.0243e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.8626e-04 - val_loss: 1.3076e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 4.2386e-04 - val_loss: 3.0646e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 4.0713e-04 - val_loss: 2.1571e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.8717e-04 - val_loss: 2.1634e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.9958e-04 - val_loss: 5.0098e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 4.0210e-04 - val_loss: 2.0944e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.3975e-04 - val_loss: 4.5614e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.8475e-04 - val_loss: 1.2746e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.8594e-04 - val_loss: 3.1453e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.6566e-04 - val_loss: 1.9595e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.3308e-04 - val_loss: 2.1220e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SUNPHARMA model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 0.0166 - val_loss: 2.2876e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0020 - val_loss: 1.6288e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0017 - val_loss: 2.7110e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0015 - val_loss: 1.1317e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0015 - val_loss: 1.1157e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 1.0919e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 2.0365e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 1.2692e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 1.0919e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.7179e-04 - val_loss: 7.5633e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 9.1246e-04 - val_loss: 1.5527e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.0432e-04 - val_loss: 7.8865e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.3958e-04 - val_loss: 6.5861e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.5946e-04 - val_loss: 8.7036e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 8.3269e-04 - val_loss: 1.0609e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 7.8268e-04 - val_loss: 1.3594e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.0633e-04 - val_loss: 5.6708e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.5205e-04 - val_loss: 6.0751e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 8.0268e-04 - val_loss: 6.7869e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 8.9485e-04 - val_loss: 5.3490e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.0266e-04 - val_loss: 7.2650e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.4723e-04 - val_loss: 6.6522e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.7842e-04 - val_loss: 6.0651e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.1876e-04 - val_loss: 4.7617e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.9541e-04 - val_loss: 5.0031e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.9832e-04 - val_loss: 2.3452e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 7.7442e-04 - val_loss: 5.2461e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.7397e-04 - val_loss: 7.8495e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.9347e-04 - val_loss: 8.3124e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TATAMOTORS model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0261 - val_loss: 0.0019\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0018 - val_loss: 9.2562e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 8.6943e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0015 - val_loss: 8.6907e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0015 - val_loss: 7.8648e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 8.7996e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 7.6104e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 6.2820e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 5.7351e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 7.2074e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.9638e-04 - val_loss: 5.1416e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.8231e-04 - val_loss: 9.7613e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.6172e-04 - val_loss: 5.4984e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.6041e-04 - val_loss: 4.4196e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.5447e-04 - val_loss: 5.3448e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.9456e-04 - val_loss: 4.7003e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.7615e-04 - val_loss: 4.4990e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.7133e-04 - val_loss: 4.9378e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.6531e-04 - val_loss: 3.8539e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.8264e-04 - val_loss: 3.9992e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.3309e-04 - val_loss: 3.3631e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.3456e-04 - val_loss: 5.0859e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.0591e-04 - val_loss: 4.1857e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.8661e-04 - val_loss: 3.0173e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.7718e-04 - val_loss: 3.6303e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.7774e-04 - val_loss: 3.0357e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.7332e-04 - val_loss: 3.4680e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.6212e-04 - val_loss: 3.2549e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TATASTEEL model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 0.0185 - val_loss: 0.0018\n",
      "Epoch 2/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 3/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0024 - val_loss: 8.9019e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 5/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 6/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 7/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0016 - val_loss: 8.1277e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 7.9077e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0019 - val_loss: 4.9423e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 7.9898e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0015 - val_loss: 4.7168e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 4.8580e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 8.0890e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 15/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 3.9107e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 3.9084e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 18/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 3.5086e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.2744e-04 - val_loss: 4.4491e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 3.2093e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.1757e-04 - val_loss: 3.1843e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.9130e-04 - val_loss: 3.2472e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.6548e-04 - val_loss: 3.5611e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.9648e-04 - val_loss: 3.0018e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.8544e-04 - val_loss: 3.0268e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.8999e-04 - val_loss: 4.1599e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.0236e-04 - val_loss: 5.1837e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.1042e-04 - val_loss: 3.8150e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.7764e-04 - val_loss: 4.4178e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TCS model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0151 - val_loss: 6.4876e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0033 - val_loss: 2.2081e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0028 - val_loss: 1.5819e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 1.5933e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0019 - val_loss: 1.3354e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0023 - val_loss: 1.2761e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0016 - val_loss: 4.8490e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 1.1241e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 1.7538e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0010 - val_loss: 1.3657e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 9.8804e-04 - val_loss: 1.6837e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0015 - val_loss: 9.5825e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 9.1913e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 9.3983e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 8.1835e-04 - val_loss: 9.3476e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 1.2509e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 8.3681e-04 - val_loss: 2.2999e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m101/101\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 1.2450e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TECHM model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 0.0055 - val_loss: 1.6922e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 9.4894e-04 - val_loss: 0.0017\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0017 - val_loss: 1.1062e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0010 - val_loss: 1.0517e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.8675e-04 - val_loss: 8.8777e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.4279e-04 - val_loss: 3.2955e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.2550e-04 - val_loss: 8.0911e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 6.4141e-04 - val_loss: 6.4834e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0016 - val_loss: 6.4617e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0015 - val_loss: 1.8317e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.8397e-04 - val_loss: 6.0331e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.7334e-04 - val_loss: 1.0730e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 6.9438e-04 - val_loss: 6.4917e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.5786e-04 - val_loss: 6.6073e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 5.2396e-04 - val_loss: 6.0232e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.4978e-04 - val_loss: 6.4697e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.1389e-04 - val_loss: 6.5053e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 8.6975e-04 - val_loss: 5.5100e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.7059e-04 - val_loss: 8.0304e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.1140e-04 - val_loss: 1.7644e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.0772e-04 - val_loss: 5.9307e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.6670e-04 - val_loss: 1.9626e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0010 - val_loss: 4.6346e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 4.4127e-04 - val_loss: 8.5529e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.5633e-04 - val_loss: 4.7705e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 6.8559e-04 - val_loss: 4.9270e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.6284e-04 - val_loss: 6.3025e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.7935e-04 - val_loss: 4.2374e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.5192e-04 - val_loss: 4.2228e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… TITAN model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0198 - val_loss: 0.0014\n",
      "Epoch 2/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 3/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 4/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 8.3975e-04 - val_loss: 0.0025\n",
      "Epoch 5/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 7.8474e-04 - val_loss: 0.0013\n",
      "Epoch 6/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.3630e-04 - val_loss: 0.0030\n",
      "Epoch 7/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 7.0160e-04 - val_loss: 0.0012\n",
      "Epoch 8/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 7.0486e-04 - val_loss: 0.0012\n",
      "Epoch 9/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6.4765e-04 - val_loss: 9.1292e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6.2237e-04 - val_loss: 0.0021\n",
      "Epoch 11/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6.1254e-04 - val_loss: 0.0012\n",
      "Epoch 12/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6.1168e-04 - val_loss: 0.0019\n",
      "Epoch 13/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 5.3382e-04 - val_loss: 0.0017\n",
      "Epoch 14/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 6.7654e-04 - val_loss: 8.8981e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 5.8370e-04 - val_loss: 0.0014\n",
      "Epoch 16/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 5.5850e-04 - val_loss: 7.6854e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 4.9162e-04 - val_loss: 7.3585e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 4.9057e-04 - val_loss: 0.0011\n",
      "Epoch 19/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 4.4945e-04 - val_loss: 6.8519e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 4.5485e-04 - val_loss: 7.0448e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 4.5536e-04 - val_loss: 6.5816e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 4.7389e-04 - val_loss: 0.0012\n",
      "Epoch 23/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 4.2585e-04 - val_loss: 0.0011\n",
      "Epoch 24/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 3.8720e-04 - val_loss: 6.0394e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 3.9568e-04 - val_loss: 0.0020\n",
      "Epoch 26/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 4.4214e-04 - val_loss: 7.3642e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 4.1769e-04 - val_loss: 5.7455e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 4.3300e-04 - val_loss: 0.0014\n",
      "Epoch 29/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 3.6540e-04 - val_loss: 0.0012\n",
      "Epoch 30/30\n",
      "\u001b[1m115/115\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 4.1906e-04 - val_loss: 9.4073e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ULTRACEMCO model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0359 - val_loss: 0.0016\n",
      "Epoch 2/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 3/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0022 - val_loss: 9.5742e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0020 - val_loss: 9.3781e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0024 - val_loss: 8.9703e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0018 - val_loss: 8.7055e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0018 - val_loss: 7.2664e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0019 - val_loss: 9.3620e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0015 - val_loss: 6.5049e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0018 - val_loss: 6.1720e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0023 - val_loss: 6.3409e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0016 - val_loss: 6.3240e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0016 - val_loss: 5.9662e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0015 - val_loss: 5.2917e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 5.2535e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0016 - val_loss: 6.1350e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 6.2419e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 4.7836e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0014 - val_loss: 4.5343e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 4.4681e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 5.0548e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 4.2343e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0010 - val_loss: 4.7897e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 9.7372e-04 - val_loss: 7.1367e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 4.6047e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0015 - val_loss: 4.0475e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 9.0116e-04 - val_loss: 3.9365e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 3.7694e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 7.2955e-04 - val_loss: 3.7398e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 3.7106e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… UPL model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 0.0056 - val_loss: 1.3912e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 8.2436e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 2.1004e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 3.6431e-06\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.7387e-04 - val_loss: 5.7210e-06\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.6110e-04 - val_loss: 9.3369e-06\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 8.0541e-04 - val_loss: 8.8205e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 7.4092e-04 - val_loss: 9.0191e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 7.3640e-04 - val_loss: 1.7981e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… VEDL model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 0.0017 - val_loss: 1.7572e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 2.9209e-04 - val_loss: 2.0792e-06\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.6835e-04 - val_loss: 4.6164e-06\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.5647e-04 - val_loss: 1.2528e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.2993e-04 - val_loss: 7.6919e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.4366e-04 - val_loss: 8.9104e-06\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.1001e-04 - val_loss: 2.2271e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… WIPRO model saved!\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\stock_prediction\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 0.0026 - val_loss: 2.3074e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.9575e-04 - val_loss: 2.5581e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.1830e-04 - val_loss: 1.6491e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.2500e-04 - val_loss: 1.7737e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.9890e-04 - val_loss: 1.4189e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 2.7130e-04 - val_loss: 1.4280e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.7338e-04 - val_loss: 1.8167e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 2.2432e-04 - val_loss: 1.2311e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 2.3867e-04 - val_loss: 1.3243e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 2.0318e-04 - val_loss: 1.4076e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 2.3796e-04 - val_loss: 1.6313e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.9600e-04 - val_loss: 1.0734e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.7605e-04 - val_loss: 1.5004e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.9632e-04 - val_loss: 1.1867e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 2.0653e-04 - val_loss: 1.0418e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 2.0007e-04 - val_loss: 1.2549e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.7782e-04 - val_loss: 8.7683e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.8450e-04 - val_loss: 8.2753e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.8322e-04 - val_loss: 8.1113e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.8151e-04 - val_loss: 9.4297e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.5305e-04 - val_loss: 1.0740e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.7155e-04 - val_loss: 1.0635e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.7662e-04 - val_loss: 8.8836e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.4798e-04 - val_loss: 7.0944e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.6320e-04 - val_loss: 7.8228e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 1.4351e-04 - val_loss: 6.7698e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 1.3366e-04 - val_loss: 1.0260e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.7346e-04 - val_loss: 6.9597e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.4751e-04 - val_loss: 6.4035e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m148/148\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 1.6304e-04 - val_loss: 8.0885e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ZEEL model saved!\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(DATA_DIR):\n",
    "    if not file.endswith('.csv') or file in invalid_files:\n",
    "        continue\n",
    "\n",
    "    company_name = file.replace('.csv', '')\n",
    "    csv_path = os.path.join(DATA_DIR, file)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'Close' not in df.columns:\n",
    "            print(f\"âš ï¸ Skipping {company_name}: 'Close' column missing.\")\n",
    "            continue\n",
    "\n",
    "        df = df[['Close']].dropna()\n",
    "\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "        # Save scaler max\n",
    "        np.save(os.path.join(MODEL_DIR, f'{company_name}_scaler_max.npy'), scaler.data_max_)\n",
    "\n",
    "        # Create sequences\n",
    "        X, y = [], []\n",
    "        for i in range(SEQUENCE_LENGTH, len(scaled_data)):\n",
    "            X.append(scaled_data[i - SEQUENCE_LENGTH:i, 0])\n",
    "            y.append(scaled_data[i, 0])\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        # Train\n",
    "        model = build_model((X.shape[1], 1))\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.1,\n",
    "                  callbacks=[early_stop], verbose=1)\n",
    "\n",
    "        # Save model\n",
    "        model_path = os.path.join(MODEL_DIR, f'{company_name}_lstm_model.h5')\n",
    "        model.save(model_path)\n",
    "        print(f\"âœ… {company_name} model saved!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error training {company_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d6c4a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\Owais\\AppData\\Local\\Temp\\ipykernel_20120\\2496631880.py:23: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  scaler_max = float(np.load(SCALER_MAX_PATH))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzsnQV4FOfXxc/GPSFAcHe3ClSAUigtVKi7u351V/qvC3V3d6GFlkJboC3QAsUdiruTEE/2e+7MvDuys5tNSDay5/c86czOzM7Ozswufc+ee67H6/V6QQghhBBCCCGEEEJIGIkK54sRQgghhBBCCCGEECJQlCKEEEIIIYQQQgghYYeiFCGEEEIIIYQQQggJOxSlCCGEEEIIIYQQQkjYoShFCCGEEEIIIYQQQsIORSlCCCGEEEIIIYQQEnYoShFCCCGEEEIIIYSQsENRihBCCCGEEEIIIYSEHYpShBBCCCGEEEIIISTsUJQihBBCSI1j8ODB6N69e7W9fuvWrXHRRRchklizZg08Hg/ee+8937IHH3xQW1ZZTJ48WdufTEnNobKvMyGEEBIqFKUIIYSQMCIDv1D+1KB93759eOihh9CrVy+kpKQgMTFRE2vuuOMObNq0ybbvH374AYMGDUJWVhaSkpLQtm1bnHHGGfj555/LPK7CwkI8//zz6NOnD9LS0pCRkYFu3brhiiuuwNKlS33bTZs2TRvA7tmzBzUVEZOs51Lej5y/Z555BgUFBaip1NbjduOVV16xiVuRRElJCZo2bapdw59++qnC+/nkk0/w3HPPVeqxEUIIITWNmOo+AEIIISSS+PDDD22PP/jgA0ycONFveZcuXfDff/9h6NChWLduHU4//XRNIIqLi8P8+fPx9ttv49tvv8Xy5cu17Z9++mncdtttmih11113aaLUypUrMWnSJHz22Wc49thjgx7Xqaeeqg2gzz77bFx++eUoKirSxKgff/wRhx12GDp37uwTpUQkEwFFhKuaSnx8PN566y1tXgS0r7/+GrfeeitmzpypnY+yWLZsGaKiomrdcVc29957L+68884KiVINGjTwc5sNHDgQeXl52n1cV/ntt9+wefNmzW338ccf47jjjquwKLVw4ULceOONlX6MhBBCSE2BohQhhBASRs477zzb4xkzZmiilHN5cXExhg8fjq1bt2quqSOOOMK2/pFHHsETTzzh2/bhhx/GsGHD8Msvv/i95rZt24IekwgeIj7JPu+++27bupdeeqlGu6ICERMTYzun11xzDQ499FB8/vnnePbZZzUnixOv14v8/HzNjSbiUG087qo4HvmrLEToS0hIQF3mo48+Qt++fXHhhRdqn6f9+/cjOTm5ug+LEEIIqZGwfI8QQgipgYhDZt68ebjnnnv8BClBSrtERBJ27NihlfkdfvjhrvuScr5grFq1Spu6PT86Ohr169fX5qVsT9xYQps2bXxlZpJFZBXH2rVrp4k64hSRQblb6Zm4ssTVlZqaqr2Xgw8+WHOGBEMEN3GAiZtLXqu8YojkVAnqeOX4jj/+eEyYMAEHHXSQJuq8/vrrvnVOl4+IczfddJO2Tt5f8+bNccEFF2jnXyHv9YEHHkD79u21bVq0aIHbb7+9wuV35T1uOUZx1sjryuvLcYh4WVpa6vde5P2lp6drjjcRUNzEx0BZQyK8HHLIIdr1qFevnuaAUoKoHN+iRYswZcoU3z2i3kOgTKkvv/wS/fr1096LOKxEmNu4caNtGzleKWGV5aNGjdLmGzZsqDnJpGQuGHK+pJzVjQEDBmjnUSEisXzm5LzIa3Tq1MlPrA2EuMDEwXjWWWdppbPy+Pvvv3fdNthnQM7XuHHjsHbtWt85lPMqSFmk9XOncDu3f/zxh+aybNmype9+lHtYjosQQgipCdApRQghhNRAxo4dq03PP//8MrcV0UkG85Ipdf311yMzM7Ncr9WqVSttKqVGIkwFcsaccsopWrngp59+ijFjxmjigSDCgHDZZZfh/fffx2mnnYZbbrkFf//9Nx577DEsWbJEG6grZFB9ySWXaJlVUmoog/85c+Zo2VfnnHOO62uLk0v2e+aZZ+Kdd97RxLLyosQ3JbKpMj0Rua688kqtbFEECDdycnJw5JFHau9Fjl2cMCJGyXXasGGDdi5E+DnxxBPx559/aqWWUoK5YMEC7VzJefvuu+/KfczlOe7c3FxN5BDRRpaLECHllnKOpZxM5ROJs+qkk07SjvOqq67SjlOujwhToSDlmyJWSVnn6NGjtVI8udZStnbMMcdoryP3oQg6IqoKjRo1Crg/uR8uvvhiTZSR+0XcgZJv9tdff2n3hbVMVMQncRCKe0xKVqU8VTK3RAi9+uqrA76G3DciIIorUF5HIaKPuBWfeuop7bGIaSJg9ezZU3tvIuRIGawcSyjI/SD3iohSjRs31sQl+Vw57+uyPgNy3vbu3avdW3L/CHI+y4uIfXJfyLmR++eff/7Biy++qO1X1hFCCCHVjpcQQggh1ca1117rdfvnuE+fPt709PSQ93P//fdr+0lOTvYed9xx3kceecQ7e/bskJ5bWlrqHTRokPb8Ro0aec8++2zvyy+/7F27dq3ftk899ZS23erVq23L586dqy2/7LLLbMtvvfVWbflvv/2mPd6zZ483NTXVe+ihh3rz8vL8jkMhx9OtWzdt/uuvv/bGxsZ6L7/8cm9JSUmZ7+fCCy/UzsP27du1v5UrV3offfRRr8fj8fbs2dO3XatWrbRj+/nnn/32IetkP87z+80337ieP+HDDz/0RkVFef/44w/b+tdee0177l9//VWlx/3www9rz1++fLlt+Z133umNjo72rlu3Tnv83Xffac9/8sknfdsUFxd7jzzySG35u+++61v+wAMP2O7PFStWaO/x5JNP9rsW1usn106uoZPff/9d259MhcLCQm9WVpa3e/futvvhxx9/1LaT8249P7Js9OjRfp+Vfv36BT23e/fu9cbHx3tvueUW23I5B3J+1b0+ZswY7TXk/FeE448/3nv44Yf7Hr/xxhvemJgY77Zt23zLQv0MjBw5UrvWTuT6uH0GnedWyM3N9Xv+Y489ZnvPbteZEEIICRcs3yOEEEJqIFKOJ2U9oSLuFSn9ke55UtYlTgsphxJHj7h7giElP/Kc//3vf1opljihrr32Ws1BJQ6TUDKlxo8fr01vvvlm23JxTAlSiqRKo7Kzs7XwbGe2kFuZmByLHIM4f6RELdTwccnxEQeX/EkJm5RfSZmW1bGlyhDFeRNKOaV0wjv55JP91qnjFueJuI4kFF5cVOpvyJAh2vrff/+9So9bXl/cXHINra8vYfniMJo6darvWokbzuosEueZuJvKQtxe4gi7//77/a6F2/Uri1mzZmmZZ5KdZb0fRo4cqZ1Hdd9YEXeXFXnP0hQgGFIeJ4HjX3zxheYUU0hWV//+/TVXmaBcWVJy5yx5LIudO3dqnyNxsFkbCMh5kddVlPczcCBYc8bk3pL7QRxucg7EmUUIIYRUNxSlCCGEkBqIDKJl4FoeZDAsGTK7d+/W8n2kDEgGnieccIIWhB0MKVMSIUsErE2bNmlikAzWZTB93XXXlfnaUgYlIoUIKVakhEkG+rLeWorWvXv3Mve5evVqLVtIBvZSclSeAbsM9mXwL38ixqxfv14rwXLmCom4Ewpy3GUd84oVK7TyLyUqqb+OHTuGFDh/oMctry/lX87XF1HK+vpyLZo0aeJXDhaodNF5HuQ6d+3aFZWBui/cXltEKbXeen5UuahCRDi558tCxE05n9OnT/e9l9mzZ2vLrdtICauUokrJoZThyWcgFIFKBC7pWinCsJT8yd+uXbu0UkMp4VOU5zNwoEjnTsnikpJelcElJZ6ClAcSQggh1Q0zpQghhJAaiAzIRVCSQbSEE5dX0JJOfPIXGxur5TxJ5o8ajJaFCBYyGBcxSDJvZFAuGTihdGGrTKeHHIf8ibNHHDXWMOqyEOePEmOCUZkd60S46NGjh9Ylz41QruOBHLe8vlxzCVZ3Q4ljtZmKZIkpRJyVYHa5n8UtJFMR2CQI3HpeRQwUV5u4tETkE7FJ3G4i9AZ7fSU8BWo4IG6uQGHr5SHQZ8wZ9i6P5X4QYeyOO+7QvlOkC6BkjolQVV4nGCGEEFIVUJQihBBCaiAygBa3knQ5kyDkiiJCjohSEnRdXkTQksBnceBI2Y+4ngINiKXUTwa5sq2UsCkktFrK/1SYugRSCwsXLvRzVTkRV4wEnIsgcOyxx2rd3EQkqw7kuOWYy9pGOiYeffTRlV6GFQry+hKyXZaoJdfi119/1ba1uqUkPD2U15DrvHjxYvTu3TvgdqG+f3VfyGurMkfr8aj1lYEIMhJiLmWOIhyK2CSlf02bNrVtJ0KVXEP5k+0effRRzUUoQlWgcyuuPgmVF1ehU/yV8yUNC6S89t577w35MxDoHIozTHCW1TpdZRKyLwH78vmXkHeFuPAIIYSQmgLL9wghhJAaiHSaE9fNI4884is3siKlfaqzmXTXcttGtZ0vqzRLhCQp83Eig17ZrwyCVcmUDOzVOisjRozQpqrDm0K5hiQjSJDubJKVJV3WnCWF1qwfRXp6upbTIx0GxfWhSp/CjbjGRHByZjtZj/uMM87QXChvvvmm3zZ5eXlapk9VIq8v10vOlxO5XsXFxb5rJfOvvvqqzVUjJZJlMWrUKE20kc50TqeN9frJfRJKFpmIpnJtX3vtNRQUFNjuWyklVfdNZSHleVKe+tZbb2nX01q6J4iryIkS36zHF8glJS41+exa/+S6iFCltgn1MyDn0K3ETolaKiNMXb833njDtp1ydVn3KfPS2ZAQQgipKdApRQghhNRAxKX0zTffaM6MgQMHagNbKQuS5ZJbJK4LEYtEtBJRSsqRJANKHEVSJiaCgIRSS8aUCAmScxMIGZxL/pQEQYtzRPJnRFwRh4UM4EVoUgNcCU8XRBCTEj85HnF1SQj4hRdeqA2M5bVlEC7t52Uf8vpHHXWUr7RQWtxLZs/BBx+sva68DzkGeR+yvZMGDRpo7o4jjjhCOx9//vknmjVrhnBy22234auvvtJKvS655BLtPIiAMXbsWE1QkfcvbhgpCZMgbnHVyPUSsWDp0qXachGLylOCWJFjlOMRN5CUZ8kxihAmjhk59jVr1mjnUq6XHJsEbcsyyYeSey2UjCFx9si1f/jhh7V75ZRTTtHyyGbOnKk5jkRoEeS1RfSS8Hx5jghPTieUIPfPE088gYsvvli7ZyQXTdx1Ipy0bt0aN910U6WeIxHkRBC69dZbtXtaxEYrIraJ2CNimLi0JIfrlVdeQfPmzbX7LxAiOIl4FahE88QTT9SC5P/991+t+UAonwE5h+LmkuYBsp242uTaiVtQPuvioJR7UD6vn332mU90VEi5nghY8l7l8yyfPQnsDyV/ixBCCAkbYevzRwghhBA/rr322qCt2Hfv3u29//77vT169PAmJSV5ExISvN27d/fedddd3s2bN2vbFBUVed98803vqFGjtBby8fHx2rZ9+vTxPvXUU96CgoKgx7B161bv448/7h00aJC3SZMmWgv7evXqeYcMGeL96quv/LZ/+OGHvc2aNfNGRUXZWtPLcTz00EPeNm3aeGNjY70tWrTQjjM/P99vH2PHjvUedthh3sTERG9aWpr3kEMO8X766ae+9XIs3bp1sz1n5cqV2vF16dLFu3379oDv58ILL/QmJyd7y0LO1ciRIwOuk/1Y2blzp/e6667T3ntcXJy3efPm2jY7duzwbVNYWOh94okntGOX6yDnsV+/ftp52bt3b9DjqYzjzs7O1s55+/bttWNs0KCBdp6ffvpp7dis7+X888/Xzn16ero2P2fOHO16vvvuu77tHnjgAdf785133tHuL/Ue5XpNnDjRt37Lli3aMaampmrPl/XC77//rj2WqZXPP//ct7/MzEzvueee692wYUNI5yfQMQZC9i3bDx061G/dr7/+6j3ppJO8TZs21c6fTM8++2zv8uXLA+5v9uzZ2v7uu+++gNusWbNG2+amm24K+TOQk5PjPeecc7wZGRnac+W6K1atWqUdv5yvRo0aee+++27t/DvP7eLFi7XtUlJStHvh8ssv986bNy/k60wIIYRUNR75T/gkMEIIIYQQQgghhBBCmClFCCGEEEIIIYQQQqoBilKEEEIIIYQQQgghJOxQlCKEEEIIIYQQQgghYYeiFCGEEEIIIYQQQggJOxSlCCGEEEIIIYQQQkjYoShFCCGEEEIIIYQQQsJOTPhfsvZRWlqKTZs2ITU1FR6Pp7oPhxBCCCGEEEIIIaTG4vV6kZ2djaZNmyIqKrAfiqJUCIgg1aJFi+o+DEIIIYQQQgghhJBaw/r169G8efOA6ylKhYA4pNTJTEtLQ22mqKgIv/zyC4455hjExsZW9+GQKoTXOnLgtY4ceK0jC17vyIHXOnLgtY4ceK0jC15vf/bt26eZe5SeEgiKUiGgSvZEkKoLolRSUpL2PvhhqdvwWkcOvNaRA691ZMHrHTnwWkcOvNaRA691ZMHrHZiyIpAYdE4IIYQQQgghhBBCwg5FKUIIIYQQQgghhBASdihKEUIIIYQQQgghhJCww0wpQgghhBBCCCGkjlJSUqJlHpGqQ85vTEwM8vPztfMdCcTGxiI6OvqA90NRihBCCCGEEEIIqWN4vV5s2bIFe/bsqe5DiYhz3bhxY6xfv77MYO+6REZGhva+D+Q9U5QihBBCCCGEEELqGEqQysrK0jrDRZJYEm5KS0uRk5ODlJQUREVFRYQIl5ubi23btmmPmzRpUuF9UZQihBBCCCGEEELqEFJCpgSp+vXrV/fhRIQoVVhYiISEhIgQpYTExERtKsKU3GcVLeWLjLNFCCGEEEIIIYRECCpDShxShFQV6v46kMwyilKEEEIIIYQQQkgdhCV7pKbfXxSlCCGEEEIIIYQQQkjYoShFCCGEEEIIIYQQEqI76Lvvvqv0/bZu3RrPPfccIg2KUoQQQgghhBBCCKlRTJ8+XQvPHjlyZK0SeC666CJNuJK/uLg4tG/fHqNHj0ZxcXHQ582cORNXXHEFIg2KUoQQQgghhBBCCKlRvP3227j++usxdepUbNq0CbWJY489Fps3b8aKFStwyy234MEHH8RTTz3lum1hYaE2bdiwYUQG01OUIoQQQgghhBBCSI0hJycHn3/+Oa6++mrNKfXee+/5bfPDDz/g4IMPRkJCAho0aICTTz5ZWz548GCsXbsWN910k8+xJIgw1Lt3b9s+xE0lriqrW2nYsGHa/tLT0zFo0CD8+++/5T7++Ph4NG7cGK1atdLew9ChQzF27Fifk2rUqFF45JFH0LRpU3Tq1MnV3bVnzx5ceeWVaNSokfYeu3fvjh9//NG3/s8//8SRRx6JxMREtGjRAjfccAP279+P2gZFKUIIIYQQQgghpI7j9QKiWVTHn7x2efjiiy/QuXNnTbA577zz8M4778Br2cm4ceM0EWrEiBGYM2cOfv31VxxyyCHaum+++QbNmzfXSubErSR/oZKdnY0LL7xQE3xmzJiBDh06aK8hyw8EEY6UI0qQ4122bBkmTpxoE5oUpaWlOO644/DXX3/ho48+wuLFi/H4449r5YzCqlWrNDfWqaeeivnz52sCnhzzddddh9pGTHUfACGEEEIIIYQQQqqW3FwgJaV6XjsnB0hOLl/pnohRgogve/fuxZQpUzQXlCAuo7POOgsPPfSQ7zm9evXSppmZmZp4k5qaqrmVysOQIUNsj9944w1kZGRor3388cejvIiQJgLUhAkTtFJERXJyMt566y0tc8qNSZMm4Z9//sGSJUvQsWNHbVnbtm196x977DGce+65uPHGG7XHIp698MILmrPr1Vdf1ZxVtQU6pQghhBBCCCGEEFIjEAeRCDJnn3229jgmJgZnnnmmJlQp5s6di6OPPrrSX3vr1q24/PLLNZFHyvfS0tK0UsJ169aVaz/ifkpJSdHEIXE8yfFL+aCiR48eAQUp9f7E7aUEKSfz5s3TShrlNdTf8OHDNYfV6tWrUZugU4oQQgghhBBCCKnjSIa2OJaq67VDRcQn6VQneUtWx5HkNL300kuaWCTlcOUlKirKVgIoFBUV2R5L6d7OnTvx/PPPa3lQ8poDBgywld6FwlFHHaU5lkR4kvchwpoVcUoFI7GM9ydCmeRNSY6Uk5YtW6I2QVGKEEIIIYQQQgip40jed3lK6KoDEaM++OADPPPMMzjmmGNs6yQc/NNPP8VVV12Fnj17amVxF198set+RAwqKSmxLZPudlu2bNGEKRV+Lo4kK5Lh9Morr2g5UsL69euxY8eOcr8PEZ3at2+PitKzZ09s2LABy5cvd3VL9e3bV8uZOpDXqCmwfI8QQgghhBBCSK3msceAm24qf6A2qVlI2dvu3btx6aWXat3mrH8S6q1K+B544AFNoJKp5C4tWLAATzzxhG8/0slu6tSp2Lhxo09Ukjyq7du348knn9SCwl9++WX89NNPtteXsr0PP/xQ2+fff/+t5TZVxJV1oAwaNAgDBw7U3rOEoUtJnhzrzz//rK2/4447MG3aNC3YXIS1FStW4Pvvv6+VQecUpQghhBBCCCGE1Gruvht47jlxvlT3kZADQUSnoUOHaiV6TkSgmTVrltZtTgSmL7/8EmPHjkXv3r21gHLJoVJI5701a9agXbt2mkNK6NKli+aCEjFKQtFl+1tvvdXv9UUUEyfS+eefr5XHZWVloTr4+uuvcfDBB2vZWl27dsXtt9/uc3+Jk0rC18VJdeSRR6JPnz64//77bSWPtQWW7xFCCCGEEEIIqbWUlprza9cCffpU59GQA+GHH34IuO6QQw6xZUKdcsop2p8b/fv318LAnUjpn/xZuVsUTQMRd2bOnGlbf9ppp9keO3OpnEgAeUXWr1mzxvZYugi+8847AfcjgtUvv/yC2g6dUoQQQgghhBBCai3WrOoKxP8QQqoRilKEEEIIIYQQQuqEKFVcXJ1HQggpLxSlCCGEEEIIIYTUWqxClLWUjxBS86EoRQghhBBCCCGk1vL99+Y8u+8RUrugKEUIIYQQQgghpNZy0UXmPMv3CKldUJQihBBCCCGEEFJr+O8/YMwYYP9+/3WFhdVxRISQihJT4WcSQgghhBBCCCFhplcvICcHeOEFYPVq+zqKUoTULqrVKfXqq6+iZ8+eSEtL0/4GDBiAn376ybd+8ODB8Hg8tr+rrrrKto9169Zh5MiRSEpKQlZWFm677TYUOzybkydPRt++fREfH4/27dvjvffeC9t7JIQQQgghhBBSeYggJaxZ479u2rSwHw4hpLY6pZo3b47HH38cHTp0gNfrxfvvv4+TTjoJc+bMQbdu3bRtLr/8cowePdr3HBGfFCUlJZog1bhxY0ybNg2bN2/GBRdcgNjYWDz66KPaNqtXr9a2ETHr448/xq+//orLLrsMTZo0wfDhw6vhXRNCCCGEEEIIqQyc3fbGj6+uIyGE1Dqn1AknnIARI0ZoolTHjh3xyCOPICUlBTNmzLCJUCI6qT9xVCl++eUXLF68GB999BF69+6N4447Dg8//DBefvllFBq+zddeew1t2rTBM888gy5duuC6667DaaedhjFShEwIIYQQQgghpNayZ4//suzs6jgSUhu56KKLMGrUKFu11o033hj245g8ebJWGbbH7YY+ANasWaPtd+7cuaip1Jigc3E9ffbZZ9i/f79WxqcQd1ODBg3QvXt33HXXXcjNzfWtmz59Onr06IFGjRr5lon7ad++fVi0aJFvm6FDh9peS7aR5YQQQgghhBBCai87dvgvy8urjiMhlSkUqfieuLg4LYJHqqecMT1VwTfffKMZXapTSApE69atfeclOTlZiyj68ssvEYwWLVpoFWWip9RUqj3ofMGCBZoIlZ+fr7mkvv32W3Tt2lVbd84556BVq1Zo2rQp5s+fjzvuuAPLli3TbhRhy5YtNkFKUI9lXbBtRLjKy8tDYmKi3zEVFBRofwrZVigqKtL+ajPq+Gv7+yBlw2sdOfBaRw681pEFr3fkwGsdOfBaVxaxvrmvvy4BEG1bq4/bquGwHMdgnVbH60tETmlpqfZXm5DjFiPJO++8o43Lx48fj+uvvx4xMTG48847/baXKikRryr6Wuo8CRkZGdo0lHOmtpGp7EPtryLnu9Syr2DPf+ihh7Q4ItEonn32WZx55plaNNFhhx0W8LxI9nao76kixy3vWe636Gj/z2GtEKU6deqkWcn27t2Lr776ChdeeCGmTJmiCVNXXHGFbztxRMnJPvroo7Fq1Sq0a9euyo7pscce0y62EykXtGZa1WYmTpxY3YdAwgSvdeTAax058FpHFrzekQOvdeTAa32gnOSbu/tu+0BYmDRpEjIyCiP6WouAI/E3OTk5vmib2oISOGTsLX/nnnsuvv76a3z33Xe45pprtD/RD/r06YO3335bE17mzZuHDRs24L777sNvv/2GqKgozfwiGdYtW7b0VWfdf//9WvyP7P+8887Tzo04sJQR5fjjj9e0B9EEBBHFJK9atIodO3agWbNmuOmmmzBo0CBNmxDq16+vTc8++2y88sormlDz3HPPaZnZ27Zt07QLacgm+dlWbeHuu+/Gxo0bcdBBB2nPFbKzs7Vjd0P2K/nZ6rzIcUllmZwbcUJJE7nzzz9f00tEyJP3IiJer169MHXqVO19CUuWLMGDDz6oVY+JoCTPleOW2CPhgw8+0CKR1q5dq5070WVECHNDzp+YfWT/TiebtcqtRotSyo4n9OvXDzNnzsTzzz+P119/3W/bQw89VJuuXLlSu7DyIfvnn39s22zdulWbyjo1Vcus20g2lZtLSpAywZtvvtn3WG5Qsb0dc8wxtkyr2oh8wOWLcdiwYdoNTeouvNaRA6915MBrHVnwekcOvNaRA6911TFoUCmmTNEH80cfPRSOYpmIu9ZSibR+/XqtGikhIUFfKG6ektCEgkonOgnweELaVM6XiGrWsbe8DxGiZJmsFxEkMzNTE3cEGdufccYZ6N+/v7ZOni+Z1bJMTDCiOzz11FP49NNPNSFL8qbFaTRu3DgcddRRvteS58m26vFZZ52lZV6/8MILmrgjjdREnJLnS+nc6aefrok8qampmigjUxG0ZJ3kW0t+thzPlVdeqQk8ImbJdZEGbSKuXX755Zg1a5YmWgny/ECag4hVci2t6+VcSDmfLJP1L730kibMqRJE5V6Scj/ZRkQwEavkOES8lWV//fWXb78icomQJ+9XRD9pQifHLsKbGIjc7jM59wMHDjTvMwMl9NV4UcpN/bOWzllR4VzimBJE+ZQbTdRHZUmTD76cTFUCKNuISmhFtrHmVjmJj4/X/pzIBa8r/3jUpfdCgsNrHTnwWkcOvNaRBa935MBrHTnwWlc+V10VhalTdd1FP7+I6GstriARK0So8DlvivcDX1WTyeKMHCA6OaRNVW6SHLc4eX799VdNfJISPlmmMpWUS0oQ95NoCbJM1gvvvfeeVo4nopAYTMT8IgYUaXwmiBFG9qtey/r68nj58uWauCT6gcqpVoYaQbKvBdWQTUQYcQ6JKCWCj9Ic5DnTpk3Dm2++qQlg8rpishFRTBCBSzKxn3jiCfv1ckEdm7yONHMToU4cW+o5Q4YMwa233moLOhfUfl999VWkp6fj888/992XnTt39m0vFWOyX3WO5DiXLl2qHfvFF1/sdzzqerjd56He99UqSskNIR3zRDEUm9onn3yihYVNmDBBs5zJY+nOJ6qcZEqJTU4UOLGlCXJjifgkFrUnn3xSy4+69957ce211/pEpauuukpTC2+//XZccsklmpXviy++0BRRQgghhBBCCCG1nzqSskIMfvzxR80dJY4zEZskb1pKzhRSimbNkZLyPamoEqeR08kj2oKINxL4raqvlCtKSudUHpSbKUacRuIqChU5BilbE4ecFRGRxHkkiLPKehxCMNOMFcnZFs1DZXKLq2nkyJG+9fJ+giHv6cgjj3QVjKTpnJyrSy+9VHNwKcQBJkJWVVGtopQ4nMS2JjeHvEkRm0SQkgsoljZRF6UWU06OlM+deuqp2gVQyA0iN+vVV1+tXURRS8VSJsn8CqmLFAFKBC1RRps3b4633npLC04jhBBCCCGEEFK3RKkAGgOREjpxLFXXa5cDcRSJq0eEJ2l8JgKSFRn7W5HsLIkDkvIzJw0bNqzQIQeK+wmGHIcgGoTkT1lxq8YqL1LmJ90JRZCSBm7KFRbovJTnPaljF1eUUzRzhpjXGVFKrHWBEBFKAs/LQrrzOcvznAwePFirhSSEEEIIIYQQUjdFKRmfU5AKgpygmNBK6KobEVespXJl0bdvX60kTWJ9AmUySQzQ33//rVVfKQfQ7Nmztee6IW4scWmJLqHK96wop5aUSiqkkkvEp3Xr1gV0WEm53tixY23LZsyYEdL7lJLB8pwXJ2IEkgB2caA53VIicokA+N9//2nh8uEicLEiIYQQQgghhBBSC6gEEwqpxYiIIoKNdLj7448/tEByiQa64YYbtK58wv/93/9p5W7SxU9ykiRofM+ePQH32bp1a60SS2KA5DlqnxIHpAwy4lSS6q3t27drTiMpH5RMJ6nUEvFHyuH+/fdfvPjii9pjFTG0YsUKzfW0bNkyLbZI8q/CwXXXXadlX0mAuwSsy3F8+OGH2nGoTCnJxJKgc8nUWrBgAd59911f/lVVQFGKEEIIIYQQQkitIJATKkCvLBIhJCUlaYHmkld9yimnaG4kyUaS7CXlnLrlllu0PGoRmiT+RwSkk08+Oeh+pYRQQr9FwJJAcMlaknghQcrzRMS58847NReW5FgL0vlOOuCJuCPHceyxx2rlfBItJMgxfv3115rQ1atXL61L36OPPopwIHndkrMtApo4uaTkUcr1lGvqsssu0+KORIgSp5hsI4KZOvaqwOMNlOpFfIiSKJlXqgVlbUZselLuKAHy7PhRt+G1jhx4rSMHXuvIgtc7cuC1jhx4rQ+cwkJ/V1SHDsDChZKXI93cgU2bpFQLEX2tRYwRZ4+ICQkJCWF//UhDyvxENxC9IFj3vLpGfpD7LFQdpVozpQghhBBCCCGEkPKIUk6k8kjikhyZz4SQWgBFKUIIIYQQQgghtYIVK8z5Bx+UgGuKUYTUZihKEUIIIYQQQgipFQwfbs4/8EB1HgkhpDKInGJHQgghhBBCCCG1mu3by96GqcmE1B4oShFCCCGEEEIIqd0U7MSDp9yPHi3mV/eREELKAUUpQgghhBBCCCG1gkGDAqxY8SruHfUw5j/eCygtDvNR1eyucITU5PuLmVKEEEIIIYQQQmoFGRn69OWXHSuyzQT0mOx/ARyCSCYuLg5RUVHYtGkTGjZsqD32MBG+SsWZwsJC5Ofna+e9ruP1erX3u337du39yv1VUShKEUIIIYQQQgipFShjRny8Y0X+Vt9sTP6aiBelRCho06YNNm/erAlTpOpFmry8PCQmJkaU+JeUlISWLVsekBBHUYoQQgghhBBCSK2gpESf+o2BczdaHjDpXBD3iggGxcXFKFEnjlQJRUVFmDp1KgYOHIjY2FhEAtHR0YiJiTlgEY6iFCGEEEIIIYSQWuWUio62LiwGclZaFlCUUohgICJJpAgl1SnQiPiXkJDAc11O6n6xIyGEEEIIIYSQOiVK2ZxSO6YBJfm+h14vw70JqS1QlCKEEEIIIYQQUitQVWhJUVuAf28B9iwAsq0uKU2VqpZjI4SUH4pShBBCCCGEEEJqlVOqn+dmYOmzwIxLgf0SbG7iAZ1SpPawZAkwYgQwaxYiEmZKEUIIIYQQQgipVaJUE+94fWbXTCCto18nNEKqi/x8ICEh9O27dtWnu3YBM2Yg4qBTihBCCCGEEEJIrSrfs7mhtv/l2IpOKVI9fPihB4mJwEMPlf+5y5cjIqEoRQghhBBCCCGk1jilojwliEW2udAo31u5tb029dApRaqJSy/Vi9EefBAoLCzfc+PiEJFQlCKEEEIIIYQQUmtEqXrJu/1XRCdg5dYOaqtwHxYhfqx05O+XRUyEhitRlCKEEEIIIYQQUmvK9zJTdvmvSO+GopJYbZaZUqQmsHZt+baP1W/fiIOiFCGEEEIIIYSQWuOUSkvc578ipZ2WNGVsFe7DIsSPvXvLt30MnVKEEEIIIYQQQkjNFqWS4nP1B2mdgN5PAkktgO73orRUH94yU4rUBPbsKXubggJznqIUIYQQQgghhBBSw8v3kuP36w+ik4GutwGj1gEZPeClU4pUM927m4LobpfoMyf//mvO16uHiISiFCGEEEIIIYSQ2uOUijOcUjFJ9nVefXjLTClSHWzenIyFC5UwCuw3tNNgbNlizhcVISKhKEUIIYQQQgghpNaIUj6nVEyybZ3XqwsCHjqlSDXwzDP9ApbmBWLnzvJtXxehKEUIIYQQQgghpNaU7/kypaLdnVKgU4pUA6tXp9seFxaWT5QqLkZEQlGKEEIIIYQQQkidcUp5vXRKkfBTv36e7XEozqdcQ19VgmskQlGKEEIIIYQQQkitz5TyGsNbD+iUIuEnLa3QT5Qqy7RXYBGuli+PzBI+ilKEEEIIIYQQQmpn9z0XpxS775HqoHFje7L5++8DUVFAt26Bn1PgEKEefxwRB0UpQgghhBBCCCFhpyLlSppTSmVKOcr3mClFqhMlinbooB7r08WLgY0b3Z9T6Mid+usvRBwUpQghhBBCCCGEhJU9e4AWLYALLzyQTKkkd6cUM6VINVBSot9/GRn+6xYsCM0ptWsXIg6KUoQQQgghhBBCwspnnwGbNwMffBD6c5YsATZssGZKBXBKMVOKVAPFxfr9l2y/LTVWrw5NlNpp6cYXKVCUIoQQQgghhBASVmJiyv+cww/Xp2amlDPonJlSpPrYsSNRm6akuK1zf878+fbHdEoRQgghhBBCCCFVjIRAK0KNgNq9W5+a5XsOp1QpM6VI9bB0KbBmTXpAp1ROjv8yuU3nO0SpffsQcVCUIoQQQgghhBASVv78M3AJU1mYQed2pxTolCLVxNKl6t4DsrNDE6WUyBrpUJQihBBCCCGEEFJtBOpMFoiATil23yPVhLWLnoT4hyJKSaYaoShFCCGEEEIIIaQaad8+tO1UV7OUhFz3TCnVfY9OKVKNotTVVx+YU2q/oblGChSlCCGEEEIIIYTUaIqLzYF9y2buTilf0DmdUqSaRKmjjy5Fp07m8iOPdBel8vKAwYP1+YYN7eu2bUNEQVGKEEIIIYQQQkiNZtMmXZiKiwOiEcgppYa3dEqR8FJQoAui6elAfLy5vG9fd1FKgv5LSvT5RL1pn4/33kNEQVGKEEIIIYQQQkiNJj9fnyYleeEpLsMpBTqlSHhRYf0iSIlwqmje3F2UWr/enI+PB5plbkCL+uu0x6NHA1u3ImKgKEUIIYQQQgghpFopLcPcJC4pITG+CPCWuHbfKy3Vh7ceL51SpPpEqWTvKjxz7s1o12glWrZ0F6WiLEpMSUEeNrzYAouf7IqE2Dxt2d9/I2KgKEUIIYQQQgghJGzMnBnYCSVs3x5YlEpNtKRAB3BKeZkpRapJlIqL8yJt/aO4ecQY/HT7cWjRwl+UWrUK+N//zMfdmugfiJSE/Whab5M2P2sWIgaKUoQQQgghhBBCwsbOnf7Lco2YqOefB7KygDFjAolSxoaeGCAq1rZNqZEp5WGmFKlGp1Ta7k+1+Q6NV6JxY315dra57cMP25/bIMVUYeun7PTbvq5DUYoQQgghhBBCSNiQMGgn0o1MuPFGfXrzzWU4pRwuKcHrZaYUqZ7S05de0qUVyZPylJi2v7RUr+/+Vvew1RUoZCTvhqJ+6k5bN79IgKIUIYQQQgghhJCwobqOCUlGLJQasAdCrU9RTilHnpS1+56XmVIkjHz2mYhOHjPzzCKKpiYZaqvF/VQkm1hISzBFqbbNdtqcV5EARSlCCCGEEEIIIWEXpTp3BmJjzYH6rl2hiFKGUyraxSllZEp56JQiYWTOHHM+K1nvoKeI8+xDQoI+v29f2aLUqcfTKUUIIYQQQgghhFQZSmCKjgZiYsxlffuW/ZyU+MBOKZUpBTqlSBixdtLLSlplX1m0z1eu9/HHeqnfDz8EFqVSYiNPlDK+AgghhBBCCCGEkPA5pUSUsjql1q4NQZRKYKYUqVnIfaxokLDavrLIsEcBuOceoEkT/+dnJJmiVHLM9ogTpeiUIoQQQgghhBBS7aKUk717/UWppATDKRVNpxSpeaJUZpy/U8rKJZf4P39gf4tTKnqzNqUoRQghhBBCCCGEVLEopcr33Abhhx3mVr4X2CklaVI6dEqR6hGlUj3+TqlDDw383HvuAbLSLaJU1EZtyqBzQgghhBBCCCGkCkUpEaSUU2rePP/tFi92cUrFKVEqiFMKdEqR8OFRWqiU33nX2FcW7cN9N69GXIy7ytS0qSiypiiV5NmkTemUIoQQQgghhBBCwlS+t2ZNaM9J8gWdB8mU8tIpRcKHCjIXkqN0UQmpHfTpqjcwsrgtnjv/RtfndukiwpUpSiVgC6I8JRSlwsWrr76Knj17Ii0tTfsbMGAAfvrpJ9/6/Px8XHvttahfvz5SUlJw6qmnYuvWrbZ9rFu3DiNHjkRSUhKysrJw2223oVjJ6AaTJ09G3759ER8fj/bt2+O9994L23skhBBCCCGEEBK8fC/X0JoC4eeUcsmU8vqGt3RKkfCh7k0Rk1Lj9KBypHbSp9v/0iZXD33N73n/93/A4EFeoHCPb5kHpejXbSsaNULEUK2iVPPmzfH4449j9uzZmDVrFoYMGYKTTjoJixYt0tbfdNNN+OGHH/Dll19iypQp2LRpE0455RTf80tKSjRBqrCwENOmTcP777+vCU7333+/b5vVq1dr2xx11FGYO3cubrzxRlx22WWYMGFCtbxnQgghhBBCCIlk1CDe6pTKywvtOYlxZTulPHRKkTCi7s2Ths/RRCV4ooCMHn7bRUeZ5pnrrweeew7wlGQDXkOljaunTf6ZvAnffYeIoVpFqRNOOAEjRoxAhw4d0LFjRzzyyCOaI2rGjBnYu3cv3n77bTz77LOaWNWvXz+8++67mvgk64VffvkFixcvxkcffYTevXvjuOOOw8MPP4yXX35ZE6qE1157DW3atMEzzzyDLl264LrrrsNpp52GMWPGVOdbJ4QQQgghhJCIxK18TzmlBg1yf47qzpcUG9gpxUwpUh2oe7NDi/X6THwWkNrOb7sGqTt88z7dtNAo3YuKB1La6/N5eth5pGCYJasfcT2JI2r//v1aGZ+4p4qKijB06FDfNp07d0bLli0xffp09O/fX5v26NEDjSzetuHDh+Pqq6/W3FZ9+vTRtrHuQ20jjqlAFBQUaH+Kffv0No5yPPJXm1HHX9vfBykbXuvIgdc6cuC1jix4vSMHXuvIgddap6BAHE0xiI4uNTqXRSEnR4SkKMTE6FOFOld5ebIsGolxOdrjkqgElDrOoxrol5aUVPs55rWOHAoL9XszM3Gb9tib0AjF9QfB0Ft9ZKVtw9a9jbX5rl2LUVTkBXK3adt54+rBm9BYu/NLctb73du1kVDv/WoXpRYsWKCJUJIfJS6pb7/9Fl27dtVK7eLi4pCRkWHbXgSoLVu2aPMytQpSar1aF2wbEZry8vKQmJjod0yPPfYYHnroIb/l4syS7Kq6wMSJE6v7EEiY4LWOHHitIwde68iC1zty4LWOHCL9Ws+d2xJAH+zcuQ0FBaJKNcS6deIiycLu3dvRv38JZsxoitTUQowfr2cOz53bFkAPJEfrbpS5SzZiw8rxtv0WGw6sLVs24Y/x9nXVRaRf60jgv/96A2iF9ATd9bR9HzB9yiI0jH8AWSVzkJU/HWkx2zVRSqhfPw+Zmb9i/PgSNChZgMMB5BTEYMe2IrQBsHLBVCxd1gK1ndyyguJqiijVqVMnTYCScr2vvvoKF154oZYfVZ3cdddduPnmm32PRcBq0aIFjjnmGC2QvbarlfLFOGzYMMQqryypk/BaRw681pEDr3VkwesdOfBaRw681jqbN+vZT8f3nYkr+/4fbvngYawoOltb1qxZQ9x2WykGDgQaNIjV4l6EpUt191TTDD1IuteA49Ezy17rN/9TPZu4ceNG6DBUf151wWsdOXz1lWb3Q1q8HljeoFknjOgv959+D+7/YTiQ/zuy0nVR6r774nDKKcO1ec+GAmA6kJzZAklNBgALf0aHZkloe3D13r+Vgao4q/GilLihpCOeILlRM2fOxPPPP48zzzxTy4Xas2ePzS0l3fcaN9YtbzL9559/bPtT3fms2zg79sljEZfcXFKCdOmTPyfyZVJXvlDq0nshweG1jhx4rSMHXuvIgtc7cuC1jhx4rXXO73k/GqeuxsfXnoemN44CkIz4+CjtTygp8fjOkwqTTo3Tc3liUpqagVQGpV5dHIjy6Oe4JsBrHTkZaanxulMqKqEhoizXvDS2EZCvl+8JycnRiI3V71WUZuvPic8EknV3VFT+Ztvzayuh3vfVGnTuRmlpqZbnJAKVvIlff/3Vt27ZsmVYt26dVu4nyFTK/7Zt0y+uIGq0CE5SAqi2se5DbaP2QQghhBBCCCEk/IP4BBVaLsVP6fO1qYxj9ZwpczvB6GOFhBh9EI+Y1IDd9wB23yPhwxRMdacU4uvb1pfG6o/rp+zUV1v9L4W7zc57Sc30+bxNiCRiqrtMTjrmSXh5dnY2PvnkE0yePBkTJkxAeno6Lr30Uq2MLjMzUxOarr/+ek1MkpBzQcrpRHw6//zz8eSTT2r5Uffeey+uvfZan9PpqquuwksvvYTbb78dl1xyCX777Td88cUXGDduXHW+dUIIIYQQQgiJ6EF8erxpLmjXaBVmrBwQUJSaNQuIjS5EbJShTsW6iFLKc+Fl9z1Sc0SpAuiPM1N2+YtSeZv1aUIWkNjUWMbue2FDHE4XXHABNm/erIlQPXv21AQpqbsVxowZg6ioKJx66qmae0q65r3yyiu+50dHR+PHH3/Uuu2JWJWcnKxlUo0ePdq3TZs2bTQB6qabbtLKAps3b4633npL2xchhBBCCCGEkPAP4j2eUiTH7vUtS0vU82fcRCkpfJHc8nrJeuc9jZiUgE4pD51SJIyoJnPJsYYoFedwSsVkBnZK7V9rPLmV6ZQS99SyF4FO1yMSqFZR6u233w66PiEhAS+//LL2F4hWrVphfBmdFQYPHow5c+ZU+DgJIYQQQgghhFQOOTlAcrxZuiekJmQHFKU+/dTYJtEo3YtOAKL8h7KlXpVOQ6cUCb9TyieySimeheZt6wPbTFEqIUE9MRfY/LM+n9RSf1693sDuucDqDylKEUIIIYQQQgghlU12tilCKZTgJC4SpyjV1KhqSonPCZgnpWNkSnnplCLhd0olRhv3Z5zZqE3wSIi5W/ne7BuA4v2mU0o4/HNg+UtAot64LRKgKEUIIYQQQgghJGxIp3if68lAiVTp6f6ilGri5XuOS+meQKcUCTe//66XlwoJMYbAFJtu38jImPIr31tlqRxLaatP0zoCB72ASKLGdd8jhBBCCCGEEFLHRSmnU8p4LI3VnaJUfr7DKeUSci6w+x4JN0OGqDkvEqLU/Zlm3yjO7pTSyvcWP2mur38oEOcQsiIIOqUIIYQQQgghhIS1fC8pPte2TLmgrrzSX5Rat66cTil23yNhJj62ADFRRrhUnLtTKi0xW+sgmZToAf69w1w/dCoiGTqlCCGEEEIIIYSE1SmVGJvn6pTq3dsuShUWAh99pD8++7TsoE4pX6YUnVIkDGzfbs6nJ+oh5165B52iaVyGvtxwSzVIWGOuS+0IRMchkqEoRQghhBBCCCEkrE6pxDi7KNWhdTYWL9bnU7a+gzP7f6aJUps2mdscdWROSE4pDzOlSBiYM8ecT0/aa4bwexwyiycKxZ56PlEqPWq5uW7IREQ6FKUIIYQQQgghhITXKeUQpdq1ykaXLhIq9QfSl16Kz64/Gy3qr0OuUeVXrx7QMCO4U0q5Udh9j4SD/UauuZCWuM895NygMMoMO4/JWagvbHk6kNwSkQ5FKUIIIYQQQggh1SNKxTfUp0XGoH6Z2XlsUJcpmDcPZjh0kXJKBQo6Z/c9Uj2ilM8pFUAwTUzXw84vPmenJrxqNBhQ9QdZC6AoRQghhBBCCCGkesr3Ehrp08K9QEkhsGmcb7s+reZgxgyLKFUcPOjc132PTikSZlGqXvJubeqNzXDdNipBd0pdcu4uYM98fWHmQWE4ypoPRSlCCCGEEEIIIWGhoEAPL/cFnSc21qfF+4CclUCJWdY36qDv8NprXotTKnj5nq/7Hp1SJMyiVIPUHfpMfAP3jeN0pxRy/gNy1+vzGd2r+hBrBRSlCCGEEEIIIYSErXRPMJ1ShijlLQX2LDBWNtUmbbNWIz5aF6ISE0W4Ch507suUYvc9EgZuucWcb5i63V6O6iRed0ph62/6NKk5EKeHn0c6FKUIIYQQQgghhIStdE9IS84zHSSeGNNFIqR3R3FpnDabkbQnZKeUypTysHyPVDHi9rPSr7suSnmV+BTIKbVjuj6tf0iVHl9tgqIUIYQQQgghhJCwkJPjEKViEoE4o2NZzmp9Gp+JAm+GTZRKTbU6pcrovsfyPVLF7DCq9YSTTwZOHL49ePmeU6yiKOWDohQhhBBCCCGEkLA6TJLjDVEqOhGITbc7peIyUYgMW1ez3r3LDjo3M6XolCJVy7ZtjgUFO7WJN64Mp5QipW0VHVntg6IUIYQQQgghhJCwUFSkT5N8olSSKUrtV06p+igoTbc5pTp2DKV8T3Xfo1OKlA+p+Bw2DGjVCtiwoeztt2+3PxeFu9zFp0BOKdV1klCUIoQQQgghhBASHoqLHUHn4pSKy/BzSpVEG+V7yboolZERStA5nVKkYvz0EzBpErBunT3APFRRylNkJPgrgdUJRamAUJQihBBCCCGEEBJWp5RPlJJMqYQm9o3iMtG4pT1Tql690J1SHmZKkXIydaq74OTG2rXAk0+aj0eNMktLvQHuTb+sKdV1ksBoc0AIIYQQQgghhFRtntTRR7s4pZKa2jeMz0R0vC5KnTFqD7akAf0PLQG+yw0adO7LlGL3PVJO2loinkpKgm/bpw+we7c+36IFcMEFAL7cF/Te9BOhYtMO6HjrEhSlCCGEEEIIIYRUOX/+ac4nxFhEqcRm9g0lLNroyHfkoXtx5NXiktpvro91L98Tj5QOnVKkfMTFmfMFBcG3VYKUcOqpUn5WApTkBhebouPtjz3qXiUs3yOEEEIIIYQQUuWkWLSkaFhFKadTqj4QYwzuVVaPKt3zxABRjgG+AbvvkQMtKw1FlLIiGVS+rpDBnFIkIHRKEUIIIYQQUgvRwnX5YzupRVir6qI9FlHKmcMjolSsQ5Tav8YMiA5w4zNTihxIaakiPz/wds7K0Oho8x4tEXnF6YgiZUKnFCGEEEIIIZXIxo1AmzbAY49V3Wu8+iqQmQnMnFl1r0FIVQ78E2MDOaU8QGyGvyi1c5Y+zewXcP9ewynlZaYUqSKnlHOdlj9luPiKkRj8RbrepU8PebPiB1oHoShFCCGEEEJIJdK8ObBmDXD33VX3GtdcA+zZA5xzTtW9BiFVOfC3dd+ziVJeICralymFYkOU2jW7bFHKcFDRKUUORDBdvTrwdk4XlXZPG8JpsScp+Iv0HA2ctAZof9kBHWtdg6IUIYQQQgghtZRsS5QJIdV5Hw4dCrz2WgVEKXFKScmTuKOsKKdU4V59uvvfskWpUmZKkYphvTeF338PTZRKF+20SL9Hiz1lOKWiYoDkVgd0nHURilKEEEIIIYTUUnJyqvsICAFeeAH49Vfg6quNcqZQRClr+Z7Q63/6tON1+tQZdL5/rT5N7RBw/17Vfc9LpxSpuFNK+Ocf9+3ee8+cHzAAePxxUWWX6/tAgM57JCgUpQghhBBCCKml7N8fvgHbmDHA/PmICCSSaOXK4AILMZFSUsXtt5ctSkVHFSM2ptguSnW4Ghi5GOj3gv5Yle+JKFWUAxQbCmxik4D79/qGt3RKkQNzSgWKJbvLiIUSpk0DmjUpAmb/n/a4xBNblYdYZ6EoRQghhBBCCAnKl18CN98M9OqFiOD994EOHYDLL6/uI6kdPP20Of/ss2UP/H2le1ZRyhMFpHcxO+up8j3JlMrbbGybBMSkBNw/u++RynJKWcWnoD8C7Jrjm831NK6CI6v7UJQihBBCCCGkkig2zB+K0joyNl6/PvB7rIvcd58+fffd6j6Smk+eRV8qCyVKDT/aKkoluG+sRCkpxctZZbqklGjlQqnRfS+gzYWQcubzffQRcMMNetc96XrqR85/vtnlsadV3QHWYWKq+wAIIYQQQgipC8iAu0cP+7KpU4HBg1HrSU4253NzgbQ6Hp1SHqEl0tmxo/xulJRElSeVEFhkEleUJxrwlgD7lpVZumd1SoFOKVJOtm1zX37++fp0717ggw/M5Ykq0zxvozYpbXEmCnbVq+rDrJPQKUUIIYQQQkglMGsWsMwYOyuOOqpuOIusxhO3EpaffgKGDwc2bECtZt8+YNw4djWsKlFq9Gh9OnOGI+TcDRGrlFtq35LQRClmSpEKsmWL/zLrd/eUKfZ1WVnGTK4uSnkTm1Xl4dVpKEoRQgghhBBShYPzQL/AVwRpR14dzquPP7Y7pZyMGAH88gtw7rmo1Vx6KXD88f75MiQwu3aFtt0PPwBr1ujzcdEhiFKCEqX2LtanSS2Cbs5MKVIRpKGBauKQlOT+3d20qf05Z5xhd0oh0bEBCRmKUoQQQgghhFQCkjnixubN7ttKePjOneV7DXmO8xf7cGBtjx6s499ff6FW89VXqDOIu+2ii4BHH63a18kxmuJZkVInKytWACeeaD6+7cZsu+gUiLhMfbp7TkiiFDOlSEWQ7zQltv/8sz5t0sTunnJ24lSuPyVKeSlKVRiKUoQQQgghhFShKLVpk/+y//1P/6X9mGPK9xrKaVKdBBOlnAM3Un2IQChdBO+5Jzz3w5AhQIyRWHzaafYSyNWr7c/p0XlvaKJUckt9WmwoX0nNg27uBTOlSPmxfm+pvDz5MeHll92FeSEhwV6+B5bvVRiKUoQQQgghhIRZlPr0U33677/le43770etyhAiNVM8rIrXkTB8lcEzaRLwwgvmNtHR9uekJe4LTZRK7WB/XKYoxUwpcmCilLWpwzvvlPFEceTl6V/wdEpVHIpShBBCCCGEVKEotXWr/zLfr+yVQGkVm0KcGVKLjXif2oyU5dSFAPpQqcpqNqsoZWXdOnM+yjHqTE1QTqn04Dtvcmy5RCmoTCkvnVKkYt+h1kypQPgcrgU7gNLCkEL4SWAoShFCCCGEEFIFopQSntzEj/j4yg0/V3z9tZ7dE2r4dCg895x/h7razJw5el7M2We7N3yri1SlAGcVpc46y1y+fbuefyb3olOUSo4L0SnV8Ej744TGoWVK0SlFKuCUkvu0UaPg20ojhG++cYScJ2QBUXFVe5B1GIpShBBCCCGEVALOjm2XXebuZPrss/KX7SlUZk8gJ5Nk+UiXs4MOQqWxfr39cVERajV9+wYONY+rQ+NKq8BWld0EraLUBx8AY8boj7/9Vu8UefDB/q8fhxAzpaLjgLYX6/NNjweiXD4ANpgpRSouSkmZqfy9915wl5TPFZhjhKUlGdlnpEJQlCKEEEIIIaQSyqOcTimVo+MUpZwOnVBLq2Rg7+Z4cZbXuQVLHwhOoaY2ilLPPgt07GgvKXMj02j2Vtvfbzjfg1WUio0FevWyr//vP+DOO+3LPMX7QivfE/q9ABz2CXDYB2VuSqcUORBRKiamFPjjNIzIvCjgPVSvnuXBviX6NLVjGI6y7kJRihBCCCGEkAPgt9+ArCzgo4/sy1XJUlmZTzlGY7GysIpPM2aYZSbLlqFKcZa0lSVwVHXGVUW45RZgxQq966EVp8jXoIH/c/capp7ahlXsDJdTSmjY0H8bP2dgUYhOKW2bFKD12UCcVQ0I3n2PmVKkPKjvrC5NlwLrv0bD7PfRtJ5Lhwrn/b1jhj7N7BeGo6y7UJQihBBCCCHkALj0Ur0j3fLl5jIpoQtVlPryS0+5RClxYB1yCDBggP54yRL31ylvuLUINlJy6HxeKKKUdRvJEqpJvPKKOS/lZRkZ5uO8PPu2Sryx5mg9+SRqJVbBLZyilJuw50fhntCdUuWATilyIE6p9o1X+pb1aLHA9h3vKkplr9Cn9Rz2QFIuKEoRQgghhBBSieVtDzygh+GG7pQqnygl3aFEBFKDIxU87hRYlFgQCiJE3Xcf8PbbwN9/29dJKHgwUUren1XImjoVNYprrzXnpcRyj6GHuIk16vGhh5rLfvwRtQ4RGF99terL96SzpGSkWYP9ywqKvuIKuRCGcpngYqs6IJgpRSouStVPNTtEtGlo1kB36mRu266dMSNuvP1r9PnkVuE50DoKRSlCCCGEEEIOAGcL8ZQUfeomSt17r//zQ3U0KZFJvZ5yJ4mYdOGFwPTpwbvkSSc0yUOR5z3xROASQmfnPqdw4xQ4nFlamzej1mA9dplXWVySjaTo0we1CinnlHti3Liqd0pJp0fFJqPaSe6vsWMDP+fFF6VlpCFKxTesEqeUh04pUg7Ud3R6olmr26K+2eFh6FD9R4BBg4B0Ze5b+TpQIq1PPUBym3Afcp2CohQhhBBCCCFlIMKR5OLkyxjEwdy59seqjMkqSn34ITBhAvDII/4Derd9BnNKqf1/9529LG3kyOBOKemEplxCEjw9c6a7ELV7t/15zuMTUWrRIlPQca53imE1GatYs9Ks3NFC0U85JTTnT00jO9t/WVWJUv/84+5IO+EE9+1FONWchT6nVFblHpDXUGqZKUUq4JRKTzK/vI47yqxDbt0aWLtWzw/0sfxls3QvyuhqQSoERSlCCCGEEELK4OOPgX79gKuuCjwoVygnkxKlVq0CLrgAOPZY+3bNmrk7jUIp3xN69gwuPJRVvie5VHPm+ItSyvGiUMenXvfzz4Hu3c0ugk5RSgSr2oL13KvzJdclNVW/3sKYMahVqK6P4e4gWJZ4d9hhQP/+EnaVBxTnVIlTyusb3tIpRSoiSplOqdZNTFFK3FGJieZ3uuaQ2mt80R36VliPtS5CUYoQQgghhJAyuOMOffr++3Yhw1ky5+aUcjqPFDLIqYhTSolDL78c2vaKmBj/bfr21UUXmQYSpVRpn60VOoBvv9Wnv/9uX64yhmoDViFPvU8VhK7KMAWrq6y2DLCr0iklLr1jjjEf+0qaLJxzToAyV+WSiooNrfteOfAqpxQzpUgFPjNpiaZTKiNhu1a2JxloPjFKkWPU+cakAvUsX56kQlCUIoQQQgghpAysOUl//RV8MO4UpQIJAioYuqJOKV/gbgCcTqlhw/SpuICs3Hyz/bEzU0qV/AXqqnbuuai1WM+9EqWUGKWuj7BxI2oNbvdTZTulTj4ZmDjRfDxpkv82EpqvhFehZUtjJmeVPk1s6t/a8QBhphQ5kEyptATTKeUp3K7d46+/7vKEbKPWN7V9pd/DkQhFKUIIIYQQQsqgfn13gUIJUMFEKWuIuBUlelidUhIC3bu33tXMytKlwCef2EUptzKtYKKUEius7c3dENFNSteU0LBhg0sr9HJ0I6xt5XvOoHo311lNxs15V1WZUsHEWbm/Bw40H/s6Gu42QtgyD6r04/Cq7nvMlCIVcEqlWpxSvjB+N3IsohQ5YChKEUIIIYQQUgZWp8nOne7LFZpolL8NzRJmhShKmb+033ADMG8e8L//2bft0sXsaGZ1nwTDKUQosaJVGd3LJQNLQt3FWbViBfDnnw6niwNV7qaC192EuuoIpn/jDTP3KpRzpALarWV7NUWUks6J1iD28jqlAolSr72ml26Wp2NiXp7/Mqf7zq0UtI1qUFawQ58mNkFlw0wpckDlexanFIr2ACUBPjjKKZVCUaoyoChFCCGEEEJIOdwn1kG/mwCgiTK/D8elzQ9G//bT/UQpCRj/5ht3p5Sby0kEFivWsrJgFBe777NTJ4TMCy/Yg6rdUPtV4pTzdauDd94Brryy7Hwr6/Vbtsxepmg973stY9VwIyKldE7s0CG07d3up0Dle1dfrYfd33576MdjFWXLEqWsYpjk82gUGDuID1APWgmZUh5mSpEKlO8lxztaVyoBNVj5HjlgKEoRQgghhBASBBEnrOKFddC/bZsjxFl+PJeBjVGidOHA921lYSJ8/P23nsnjFKWWLzf3YS0dUyHr5RWllBDx2GN6pz4RN9Tzy+qUpoiPN+ePPBK47Tb7enF0qddJSwtfp7eyuPde/2WnnOK/7KmnzAGp6rInrd+d7AgwNg0HyqlWleV74o4Lle0uVU3a/b/oceATDzDvHt9y6+fGF72jRKk4S01sJeE1MqXolCIVcUolxDg+PCqU3wnL9yoVilKEEEIIIYQEwemGUoP+deuAO+/U53v0MNenRRudmQB0aLTCJwgcdRTQsWPgoPMvv4zyE6VEEBPhJJAoJSHk1s55VsSxJALR3XcDCxaYy9u3ByZPLutd+79W48a6wGXlvvv8c4WUU0rcRdOmoVpwyx4WIdDJb7/Jebcvcyvfk9But6524SDbYd4oC7dy0bJEqVA7QAqLF/sv05xJ8+7SHyx61JfH41rKqdwnVeCUkiPRYKYUKQfqsx0fm1e2KLX5FyDnP8ATDaR1Cc8B1nEoShFCCCGEEFKOAbsSkd5801zWubNeAiWZUOnRa8zlTZf65q1uKqsLSe3fGqYuzpUzzgDOPz+IULRzFtKzf8Ds2e7HLYLUe+/5L2/RAmjaFOUSdyS8PC25ANE7p8LjcR/wKwFCRClxHfXqBRx+OPD11wgbknckeVhuiCjoxqJF9scqz0vOv9Ud5NqFq4aJUuL6+vxz/+VluddiY0N/jfXrXRY6Q6G3TdEmF17okkdWqMr3Kt8ppbrv0SlFyoNyS8Yrp1RCVuCw86XP6dOO1wEJIXZ/IEGhKEUIIYQQQkg5RClVjrd7t7lMwsefeAJ4/nnZwKz/apa5CS0brHUNKHeW71kDpJWD5+OP/Y9He15JATDhYGDqicCehbb1RxxhChHStc+KEgecJYC//w788Yf/a6n3qJXtLRwNTBqER84wy7MCCRs332yWwT39NMIyqBQ30HXX6Z0D3YK7AwlxIrxZXVBZWabzy3r+v/oK1YK1E6MaPAdCjlfuHWHAAF0YDMUppa6d7P/TT4E1pq7qh7r/+/e3ZInlO9pF7pnvuw9EGJ061bLOlylVBeV7hlOKmVKkQk4pJUoltXR3SpUWA7v+0edbnRPOQ6zTVKso9dhjj+Hggw9GamoqsrKyMGrUKCxTCYMGgwcPhsfjsf1dddVVtm3WrVuHkSNHIikpSdvPbbfdhmJHwuLkyZPRt29fxMfHo3379njP7WcjQgghhBBCyhClpKub/K/mrl3mskGDLBvst4/oR/X7ztUp5ey+55Zl5Ib2vD2WerwdM3yzMTGm8CTHqErqFEoYczpjmjd37+q3caM+1fYjZVkA7jrxcbz0ki5cXHMNbK/tRlWWvUlIt2RxSWmevAcJOHcjOloXn6QMTwK3ra4pcf5YM6isJWdSsqiorvK9DRvM+VdeCb7tTz+Z8+KgU+Hobk4p6/v56y9d0Hv1VeCcc/xLQm+8ETjoIL0LoRKlBg4EZs40AuLzt7iKUnLexS3l6/ioBbRVXfkenVKkvDz3HPCo9tXmRXyM8ctAitEqMtfy4RPWfaGLqnGZQL3eYT/WukqAfzrCw5QpU3DttddqwpSISHfffTeOOeYYLF68GMmWfw0uv/xyjB492vdYxCdFSUmJJkg1btwY06ZNw+bNm3HBBRcgNjYWj+p3F1avXq1tI2LWxx9/jF9//RWXXXYZmjRpguHDh4f5XRNCCCGEkNqEW97O/Pl2UUq5k6yi1N6StkiP/g/De07ACxP+L6AoNX++B4sW1ccrr0SHdDwJCaXAhu/9Xk9lUSnBSYQIp0tJ/f7rzFxq1sy9k6DKonKKW9deq08lr0rOhTipAolSrrlCleQgCpSn5UQ5jC65RP876yxz3bvvmvNyXnzi3PKX0aNwBaI8z6DUG213+4QRJQwK11+vi0eBsJ7rIUPMElERk5w4l738sjlvdQEKmgMQeimmEqXktUSo0vjPEKWiYoHSImC3karvpHg/UFpYZU4plSlFpxQJ9bv9ppv0+ZjoYkRHGfdNuoQEfglkLwdKCoFZ1wJx9YAS4x+DVmcC0XHVd+B1jGoVpX7++WfbY3EvidNp9uzZGCjSu0WEEtHJjV9++UUTsSZNmoRGjRqhd+/eePjhh3HHHXfgwQcfRFxcHF577TW0adMGzzzzjPacLl264M8//8SYMWMoShFCCCGEkHKLUuKuUYN6cQuJS8dH9gptsrF4sCZKZSTt0R47nUiqW51wzz1WVSs4AzKeBhYZwUfC/jWQ/6WdMAE45hhTHBKnVKh5RHJsbl39VFe2jPRSwMUpJGKWKvsLlFsUaqh6eXEUWARFDDpWArmepBRNE+ykTGfWdZDEmON6D8W4Ocf7BCJ5z+FAjlFERgnUDxVr18bXXoPmaHMKW8EC0d2YMcPumDruOBexUZXvNR4ObBqnC6XbpwEND7PvTOVJRcUD0Q6VthJg9z1SHqRRhCIxzlI/Xc+oe923DFj7CbDqLf2xx/hyrReiGk5qvijlZK+06ACQmZlpWy7upo8++kgTpk444QTcd999PrfU9OnT0aNHD02QUojQdPXVV2PRokXo06ePts1Q8elakG1ulG9VFwoKCrQ/xb59+7RpUVGR9lebUcdf298HKRte68iB1zpy4LWOLHi9aw45OaJSxKBNGy/q1/di1qwojBplrh82rBhFRcYguHAXYvYs1Pwam4qOQNf4d3yDnfj4EhQVmQ6Orl3lv+VImFbPi7dYe0Q/yd2M0aOL0Lt3FG68sRQPPCAD82jc4xL99Pzz1mPQX/uyy/RlUmoV6Hi6tt8KWESgIgkpctitdDeS+/O3bCmyBblX5nUJRPv2XqxcaR6j9bNUUBDtmmTSo0cpiopKtJbv6p10abrEJ0rt2FHky5yqys/12297cNtt0Vr54L599vMc7LkNGujXXmjSpAhNm+qP160z3pffgDzw/Td1ajEOOcSLAQPMbcQdmJ0tFzoKCQnmvRSVu0l71ZKUjvA0BaI2/QjvX2ejeMQK233i2bdGu2LehMZ+cSuVgU+K8pZW+3cnv8NrNvJ91by53I36/ZkQa/76UJTSRftkeLNXwbv+e/Obwqvfs8XJHeB1XFdeb39CPRc1RpQqLS3VRKLDDz8c3bt39y0/55xz0KpVKzRt2hTz58/XHFCSO/XNN99o67ds2WITpAT1WNYF20bEpry8PCQ6fraSrKuHHnrI1ZVlLR2szUycOLG6D4GECV7ryIHXOnLgtY4seL2rj337YrFrVyKys6VM43AUFeUgNVXqmqytxKR87W94PHpOTuPiGTgUXmR7mmP+f6UY2tP8BX7z5vkYP95uexk5sgfGjWtbvgMr3q10B42c7Suxef94Ldj6778lg0hKT9z32bTpOIwfrw/d7703C3PmNMLgwUswfnyx9n6BEa7P27bO3kJvwvhvUeKxW6uSSzfixmML8Mqka1BYbNSNGXz33WQ0aeJSQ3YA/P23VFIcGnB9aan84C0p3Drjx4/3zW/eLM/zr8RIT1+Nv3/4DIflP+hb1rX5Et/8L79Mx5o1jtq2KvhcX331Sdp05Ur78ri4Ytv7cLJxY3sA3dChw2789NNUbNvWBMAhWLhwD8aPtyfZ//efWPUCtCTUctJicPbZ8t7tbe8XLZIf7DOwcuVcjB+vZ+70zf8XLQAsWbML62POwHH4EZ7cdZgy7m3sjzIT5lsW/Yo+0s0wPwPTg7yPipKzX1N64fWWBj1P4YTf4TWTRYsyUVJypO+xEqVKEIvxkxfieMQi2luEgk1T4DSRTvx7DQo9FpuVdR2vt49ct7rhmixKSbbUwoULtbI6K1dccYVvXhxRkgN19NFHY9WqVWjXrl2VHMtdd92Fm6VVhIGIVy1atNDyrtKsPutaqlbKB2XYsGFa7hapu/BaRw681pEDr3Vkwetd/dSrF4P9+z0YPVp3mDRsmIKuXZO0TnVWBg06FIcdpgs9UfP/1BxFSW2OQ6tsfYCsRKnBg3tgxAjzx1fsXYDC/+Zj3DgJ1XWEPGmRE1488UQJTjzR/r/sKfF6qE9p6wsRteZ9pMblYcQIU0z6/Xf3XkazZxehRw+j9krkJ99TRE4ws4LcGHhoF8BShjf8qEOAJGvNIhDzQ2sMPX8TPB4vxvxk/r+0cNBBg32d4CqLPXv8z5mVpk3T8N9/5mPrOXrjDff8rqOOao3DE76GJ9908Zx38nrc9Z0XW7d60KPHYTj6aG+1fa4LC2MwcOAIpKS4r587V7/2Awema+83K8uDxx8XV1k92/sX/vor+PkTPv3ULkgJq1bpQt9hh/XCiBE9tfnoKc8D24DOvQejU6uzUPrbK4jaOQODeyTB28p83agF04ClQP02AzCir7sAeiA88aDeLS3K4/V7v+GG3+E1G3G8WlHf01GxyRgx8nhETWgP7FuCBK+/CD10xNl+TlFeb39UxVmtEKWuu+46/Pjjj5g6dSqa2wry/Tn0UP3XkJUrV2qilJT0/fOP0ZbRYKvRN1XlUMlULbNuIwKT0yUlSIc++XMiN1dducHq0nshweG1jhx4rSMHXuvIgte7+lAizdixuoCRmOiB1+svZqSmxpjd7Ir09PPo1DbwxKTqz4vVBzuNG1u285YCU0fg9EZbcfXQl/HqJEsbO4PLL/egb1/7/65HeeR3fD0MKKrrbcCa9+Ep2IHYaA8QpW/r8r+xGn37Br+PUvXD1bj9duDJJ/X5Bg2AGHFnWYj15thb+BXlAPmbtNmRvcfh3ek34/33gZN0ww9yc+U+RqUhGVEffhh8m5gY+6DT+jkKdI6k/M2zZ479ecWb0K6dRwtWz821XMNq+lxPnRrrO69OVFZWQkIUYmOj0NQwKe3a5fG9npQt3XFH6HljgUhPt5yLgm3aJCalmX5fNDgU2DkDMXv+BdpfqG+z7U9gqX5TRad3RnQVfK9JIL2Ot8Z8b/I7vGaimh84nVKe6AT9eqV11EQpN2LjAoec83qbhHoe3H9GCRNer1cTpL799lv89ttvWhh5WcydO1ebimNKGDBgABYsWIBt2/QvQkEUShGcuuqF+to20nHPimwjywkhhBBCCAmGCoSWIPApU/zX2wLCVZBzXCa8UQm2X+BF3LGFoRvh0Mf1+sm32Pj91SecSKi2dIfr08cIR0+0/PKc0hbwyP/Oe4ECvXxQOLjBhxh32whkphjHEiJ6ppSOFCssWgSccgqg/W90vvn/2vr7dLgHLB0A6yXv1sLWTzjBvbNbZSDH5Pjfez8k3NvZZVChh8H7O56y0szziMbH6NO8Lb5Q+gMVciqD1asDr5OoL0GNmdVxS1j/rFlmBz3pyvj666G/pnRXdGIPOje67yUYJZH1D9GnO/82t1loiUdpbM/7rSy8vu57DDonwXHGHfkypaKNL/TUDvYNWp9rTM8Lx+FFFFHVXbInAeaffPIJUlNTtewn+ZOcJ0FK9KSTnnTjW7NmDcaOHYsLLrhA68zXs6duFZWSOhGfzj//fMybNw8TJkzAvffeq+1buZ2uuuoq/Pfff7j99tuxdOlSvPLKK/jiiy9wk+r/SAghhBBCSACUECH/a/nss/7rbcb7At0phfhMlEYl2gY7DaWVm2LnTN9s80w9l6dlSy9uucVf7LroIuDss/X59KS95sApJhGIb2DvfgbgtGYXYETvn3DfqIfL/V5/+EE6YgOSkiG/74qAof1vt1OUUu/T99gUc1o1WIu777YLQl984f560ndI9i8B2uVhhd7gMCBy7l58Ue+MKAwbZl9/Sb+78d+YtujQeLlteYMUQ1yR83qYYcUq3IX0tOJqFaWks6Iaurh10gskSlndbxcahqUN+u3m4+ijJb4EeOop/bF0cHTSr5+5Tz9RqrQIKNjpEKUMdXX3HKDQyN7Z9a8+7f0EkNENVT68dbZcJMSCM2ff130v2vhCT7OUrsY3BPq/q//J/Uvqjij16quvah33Bg8erDmf1N/nn3+urY+Li8OkSZM04alz58645ZZbcOqpp+IH+dfSIDo6Wiv9k6k4n8477zxNuBo9erRvG3FgjRs3TnNH9erVC8888wzeeustrQMfIYQQQgghwVCG/IwMfcA+f77dVWQd+IuAoRFXH15DlIqNKUZ0VLH2fB+bJ/hmm9bTy94kJ8ha7WAtMTP695hOqdh0fZrQyC5KSRmdQVa6KST9/HNo7/X4403xwkaBntXj9z5dnFP1U3fhxmt19SZIlYvG888DCxbozp3ysMNiaHJy772SZSLdtvX9fvmlIYpt+hmYcSmQtxnHtngMbbLWYMx59h+pM5INASWunnYNVdZXk0xddAkxIqVSkWsn951RKOK7F0IRpXRHGGzHHuUYAcp9+eijwK236oLXuHHASy/ZtxEx7uqr/Z+noQRLT7QmxvpcfOndgdJC4KfewP615j3T8VpUFV6vRQmVEllCQhSl/JxSrc4yVya3krApoO1FQJIZ3E8qh5jqLt8LhoSLT3HzSDuQ7nxldVcQ4WvOHHt9OCGEEEIIIaGWeWRl6dMePYAOHYClS/XH6YY+pKEcI/FSvmdaqJLi8xAdbahXpcXApvG2cjcpPGrRwou4OI+rKKWEMZ9TKjbNIkotMEUpVUZllDA98YReehWojC1k/Mr3AotS2mvnbwbiUvHJJ8Bpp7nv8s47zfnd5Wxot92hkTnFEiXuiWNKe31x80w8GyjaA3hL/N0RBmkJe0zRL8oQWQp2onE9ecFGYXFKGUUjPvr2td9nH32kZ37JfehECU9uQejikNq82f9eEDecQmVQnXyy5P6ay0eNMsv/hNatZQzmLN1rZJSTyg3gAZqPAvYu1AWp2f+nL09qAcRY6/4ql1KvVXGjU4ocgCgVkwT0HQPMvx/oaRpeSB1zShFCCCGEEFITcfvt1Fp+pxwpgiaAbBgL/HGqOUCXTCmPGTb10vMWpWHPPF3UEWeJbBpThKT4XG3/SUnuWVUqG8gUpQI4pfJMUUq2FfHAT5Ba9zXw762aYyhklFNKvZ6zfM+ZMVWkH6dqlm30H/Ih7igRzBQSil4RUcq6D4VNJFTsmKELUsJOs0lScamzs6FxfuMyzLIdLWtqu0/0kcFs5876e9prbF6Z/PWX/bESJ61OOyPJxI+dhiZaX0xeBoMHm/NSVunk4IP9l4k4JWLs7Nl6pprkoVl/32/Z0nJf7V+nTxMdDpIOV5rzG77Xp6kdUZWoTCn9AZ1SJPRMKb/yPaHzjcAZ+4CmZtdSUvlQlCKEEEIIIcSBM3fHKgwJIkrYFKyZVwHrvzGXxWWifgMP8gp1ZalVM6sotVCfNjwCXqNwQdxSAwZ4bcJDplEJJdx/PyAd7h+8u4zyPYtTKiNpD/z6COVvB6afByx9Bvj9WPu6omzg78uA/z4I7JRK62wPdA8oSu2zCSoFBfbV99zj7w4qTwSQEqWUs8eKrUxSIW4dhaWjVly0RV2U0xmlnFJ2USojYZtPjBT317Jl0s0buO8+vbRNsrGsjqPK7AqmzqFTbHvoIf9z5idKlRbh+MFmMrqU/jmdWHJvuSGlf+LSUtlR1uD63FzLhtnL3YOhk5oDA8fal0lHsyrES6cUqSynFAkbFKUIIYQQQgixIM4QcYI40ZxLhgrwwQfAoEG6MKCV7NlcRx6tREmcNHmF+q/uHdoaSoAIVzMu0uczeqAkpp5PlGrUyIt6+kM/t0ujRnrWz0G9lJNHiVKGBWnvEiB7pS3wXPKn2rZ1vImNY4ESY/C1Z75drFk4Glj1NjDjwsBOKSVKheiUCiRKOV0KzrwmOc0iXF1/vbtYpTKlxMHz2WchiFJ5em6XE5/zDMDDDwOeIsf5Ndw/6XEbfce9zjAGCSJOffedno0lZYKVkTlVYlYX2vKhnO/rwQf9XVXKueXbdtFjuKVDW5x3xIc+YdXq8rOWpZaFZE4prIH82DFdn9br7f8kyZayUsVOKZUBpkGnFDmQoHMSNihKEUIIIYQQEkJnt5aJfwFfpABLn9MEo8mTDZfJ/jWOLb1abVPHjkBRqf6re5OGecCyF/QSP0VGL5QaolRm8i5NfLCKUq5laIWOTKkUwwq1aRzwQwdg3Ze+TVs1228TtjT2LLA/3jbVnN8915y3BKZrGVgqK0t1pCrYFlyUKrSLUk4hxDkgFCTvSCFCj4RvS+C2W7c55dSR7KQzz7SLQdZwbx8BShW7ddynZSfJa0hAuq/ETzmlUlprk3qx+jVevFh3R1lLN8UxpTj8cBwwzzxjf6zK5Fq08N/2q6/sj/PzHR0hFzygTT68+gJtKgH9znPvlj/lhoiyct6lpE/OOfJ3ACteAzb9pG/Q0OXNG+cvXKIUM6VIqNApVXOgKEUIIYQQQojLwN7J4KgTgZJc4F97xzZ/UQo+QSarSaIZ/D3HYjXJ6AW0PB3e2EyfU0oEDnGyiCNFysGcOUwaysmjyvdS29vXbzObBKUm7vd//t5FdlFrx9/6tKTQnHc6i7TSPRHaooBMI3U7x/GeLWWD1uNUopQMAK1laRIU73dolnwmoxm3f6kY7M4rtX/pgHjXXcCQIcCAAaE7peI8+/Dii5YywELH+U3WRZWMWL0EbuZM+/NXr7Yf30KjMvNA+PVX9+Vu94NVELPeu9Y8MivSec/pUgtVlFJil5T0aUKZlKzOvFrvsCf5aPX6+D9BQs2NEshwlO/RKUUO3ClFUSrcUJQihBBCCCHEwi5HZZoiBi7qiJsoZRnUeKSDk7bTWXoHuJhU4Mx8YMRcrUTMG2uW76kyraeeAsaMCXBwRlaTTzRJMZLE3Sh2EaX2Gfk/7S7Tp6vf10vxxnUFirP9y/WE3PX6NLGZ6XTJ26ALWb5zYNS0pXe1Hae1g+Dxx5uOJrcuduefr3cZlHI9qyjlzECyilLqnAnirBJBx/qaZYlSvvPp7CoYZ1jWknUnWlq0u/AozqkHdDNSpeB8r9JpzyooTZrkniHlJ0rFlwCr3nXN4nKKUtYA/5CRi7TeEqKV3k3vVuZGhqVNoCHyVRV0SpFQcX4OTKcUy/fCDUUpQgghhBBCHJlSbpR4LK3sVS6T9gRDsGh2ItB4GDBsmrlODdT3Ltan9Q8Coi2qSZwpSklpVZn4nFKG0yk2FUjrFOCAc+1uEZlX4kyn/9ODqItzdHEhZ5V/ILoi1xCcklsCCVlAdJK+r39v1KdyLpQwl9HbdpxWx85PP+luJmH+fH16zDFAjx5m2aQ4xNYbGlgwUUqVA7oKUG6o953e3b5cXD4llsArlcmV2MhWfpYWtTpkkcPpXioPKsBdOTnOPde+/uij9fK5QKKUEusysz8D/r7Eb/9Ll9oH4+IQ85X6lYf9Zni6rYzUjR4P6GJUr0eAKLfaysqD3fdIqLB8r+ZAUYoQQgghhBALzvwjH+J0UuRYBuVKkGk2EhjyC5BpKWNSv7ort1G8PVU6Kt4UpVR2UFCkQ55VlBKOmgi0v9J9++Jcexmet1gvw5MAbyXQrHhFnzYYADQ93t8ppVxQSS30uq2oWON5rwJrv9BzqrwlepmWzymli1JSkmjln3+ATz81RanLLrN3GZTyN2eGVDCnVEiilLh6lCgl7zGYWypviz1APrmV/j48+1E/xaEABWC5YUYLhrynH3/0L01U70vKOAOJlFI+99tv/gKqvE3llErOdSSgiz4aXaQJZlZR6u23UTFy/jPn5X7qfHPgbbMGAietBrrdjaqG3fdIqDDovOZAUYoQQgghhNR43DqwVRVuneESYvO0/CEf1q51at6tNElcRYISReLsLdQ8CUbQecouXZSSkrjZN5vh0QHL9yyiVHILoPfjZZfw5RlqT0Ij3bGiOqOpgPPmJwMJRi3Xxh+BRY/qQpwS1JKMloT1Dzb3OedmYMqJ+rxkCqmyQpXNBH/R5fHH7WHu1mB5EWKcmV5KlJJB5NNP604ht/I9VxY8BPx5hulsa3BocFFKZWPJOdIOKAFIbKLNtm7oXsKnHEd9DC1yv0vVpJMbbojGCSfYO9qVxwGWnOzf1VDuW/U5iS3a4PecBqk7tO1fMTTI0aOBY49FxdByxqT27wjgpPW68FQjoFOKhAadUjUHilKEEEIIIaRGI26SLl10V004UMJAI0OXEL543xHkrYQoUQGUU8pNlIoJLkpFJZhB55ootfRpYNkYYPII94NTuU+STWVF9qtEI9v2FitN7kYzG0pQopRCBJv4Bvr8xrHAvHuAdV+ZTikp3xNEAGt4pPG+NptCjjjE4tLds5oMFiwwXVKClO5ZA9BloBhIlPr4Y+C224CDDgJKSkIQb/atABY8CKz/yuyo18ClQ5w6VnGhqfMlTjKFkSvVpuFqWxndBXpDO41Nm8zA8EDlnwq5Zd5/Xx+Gvfqq+71XltimyiKt58oqUEUX+dcQNsu0d0x0utgqJEpJCWiS5VxVM8yUIhV1xPqcUlEUpcINRSlCCCGEEFKjGTsWWLbsAEqNKuiUsmbtDD58t7soJcHYSshQoo2bU0qyi5QwYiHKcEqJKKWxdbK7PWz9d8C3TYFds80sKSeHvKGX1kkJnmQ/BXJKJQUQpVI72DulCTtmmJlSUr4nZPYDhk0Fjp5slvsJWUeZDi6VfQW7M8rK+PFAkyZ2cUTcRs5yPfXY6qhSBBWltv9hf5zYGEjvDPR7Huj3ApDWWV9euNsuHMp7iLW0pDPERqtT6ttv/V1Oyr1UllNqzhyzhLN1a1PUuv9+fRqKKKXet1WUWmXEgsn59BQYQuExM3zvs2WT3ZUvSjnKUasbZkqRUHF+Tn1OqRiW74Wbqk2aI4QQQggh5ACxZutIls6QIeERpaTbmSIpNsddlFLZOlLi5Vb24RzgOMv3LJlSLdp4gTnr7Q4e5Tz65wp7zpO1fE/RdDhwyjbdRfWjdMnbpotSpSXAvLuB5S8Zx9rUX5SKSdFzlFT5nkK6BqryPafo1miQ/rd5ou4Wa3IMsG2Kvk6ErCXPAq3ORG6uIYI5D7epv/gnA0WnU0o9tjrXFEHFm53/2B+rnKhON+jTTeOAfUuNazjEFKWsLilL2Hn7Rit9i5KSzIB2lQEVqii1YYMpePXsqU+7dwd27wZ69y6fU0q5o8RtpsoHBw/2wqMC26UMMU534zVM31V5olSBIUop8bPGYA1mo1OKuCOfm3//tS+jU6r6oFOKEEIIIYTUaKwD9GHDwlfWoQSCmBggutQom1Mo99DOme5d3ZxOKYXDKaW673VqvRFZmfuBbEtKtohB2SuBvUvtglQgp5S2vwwgKhqIMRQS1V1vyZN6Nz6r48naMU3EC6kf9HNKTbeUark4wYQmw4D2l+vPV5lSUtY35xbgu+a4ZsDtrk9LTTU78Cmk9C1Q+Z5VJKyQKCVOKSvKKbVviT7NDSBKZR6kTY7o9KdvkTOE/MILTVEqWPne2rXAtm1JNhegPFcEKWHu3ADva+WbwBdpwMxr/Mr3xFAnZZGKdi32AqUFfqJUSa5dlFIlkNjyK7BxPMqFuiecImY1I7dgaakhTNEpRQLw4IP+y8xMKTqlwg1FKUIIIYQQUqOxlmiJIySUIOnKcEo1aACtW9nOnZaud2rAopxS+5aZId9uqEypAE4pJRgkxeyDZ+8C+0D6t6OBHzoA47q47NfFKWUlWolS+3W3k4vIYg9LbxkgF8twm4jIZQhoQVHOLguNdj2FpXO3oKvRmM8pSj32mCkAZmcHFqWcneoE146FEs5euEfvCmjFKaqlGedV3FLaCwUQpbIGwev1oFvzxejQ2L21ngiXKlNqmz26yYeUoHboEIsff2xnW/7BB/7b+olSi5/Q88Sk42FJoe0zIa4Pdf6ERhlbzesrTr04R4mowWqJyCrYBfw2FJgyEtg9DyFTsKNGlu/Zc6XolCLuvPii/zIGnVcfFKUIIYQQQkit4i//bvdV4pSS8qasLL00yxcwrhxRks+kdaZTIeCtQnNK+YlSumAQixx4dv/r7kZxI5BTyrc+xRSlVHc9VcKWZYSUC4e8rpfx9XlKf5zeFWg6Qn8/VhFH3FWuClBoYlmntIlYuBA4/nh/UUrEnKeeMl1GTvEpmCjlR0kBML4X8FU9wOtoryVZWG5Oqb1LgotS8ZlYVzxcmz2j/xeuLyvOKeWUeuYZYLvD2Cb8+CNCxiZKWTsgase7yOeU0g7XYezo1VF1EDScYfG68HnJuXanlLYPlVEmbPhev1/cWl3KMcy9C/jvfYcoVR81DREQ9Rk6pQgCisgKJfCmJhlfNHRKhR2KUoQQQgghpFZ1SXK28q4qp5RNGFBOqdT2QFScPuCVbnbOznROnAOcAOV7USiFZ+tvgQ+qybGO/QZL+DacTap8T4lSh30KHDvT7gRofwVw4ipTsBHhafA44KQ1QKuz/AWc8jqlOlytT/cs1HZtvXZWt48SqMQptd6ivwjz5gFnnglMn25ffvLJDtFk+SvA+m/Ncjyh/iF6AHz3+4EWp9p3IAKcIHlYkt8VSJQSV1GeXjfas8V8HHGEuVyJbFdcYReHfvnFbxd+4lEwbPeeiGYqKF/YNVs7d27ljMIJwyx5UtrOdFGqc9tdmmB2883AGWfonQxtZaELHgC+SAU+jQLGttPPpWLh/4DFjwMzLgLyt1tEKaNbY00q36NTipRBq1b27xfppNmxHZ1S1QWDzgkhhBBCSI1GiUSBHlc2EyfqU5sxSDmlpCRKHEQ5K/USvty1wfOW/Mr3HKJNdCK8UXHwlBbCs/kn3zKU5JlilIhEnijgkxCcSr7XNZxSexfrwoM8v/lJ5ess1fRYPYtKmz8utOdI9z+F5FNlGGngexdpk1tuAX7+GRg50n5+VembOKWWGxVyDRvqjiPpdGfl3nuBo44CunWzLFzzMTDrWv/jkdeXvCs3JA9JyhVFlNr1r56DJST5i1L9BrUD5gBdWqzGR7eYy7//XhfS0tPNXCihvouBSMLRKyRKOR10u2bD0/4yv9cUXn8diClyF6U8hbs0Qcq+L6lNtWIIORL+Pv0CoMkWXfBb9py5yer39fJIgU4pUkORnDXp2Nmvny56Z+ofA19ptvDSS0CnTsD7YgD8Pg+QKDaKUmGHTilCCCGEEFKrnFJVKUpJiZjqymQrF1NOKSmbU66oHX8BBTvLcEqVEXQuyowSDbxF/gJQRnddUArg4CnTKbX8BX2a2qn8rc4bHQUc8iZw8KtAu8tCf16bC/SplASqcse9C7XJ0KF6mPfHH9ufYnVKyUDS2pnOiZTJSQdGrRuf5CAtfARY84n7xlKKGAzlAJNAeVUil9DEb7PUhvqyHh2321wW4lYScUjYZBit1D0rVXBSsui8f0PBJmBtmWR2eBREEAXQ1tI8UXG56G/5W+zB7ioLrNChYAnq/nVDXHZLngY2/qA7yRRrPzfFK+PerUnQKUXU98eppwKtW5udPm15atbPkAivJQw6ry4oShFCCCGEkBpNOJ1S1pDqq65yDNCFGBGlDFVi3j3mMtV1zonVGSVlf26/wluFqrROQIolCNva1a/XY7rI1ffZst+ICjq3lrFVhPaXAR2uMoWxUBARa+RioO2FQLphZxJXmeQVydvoZQo5TqeUhHavWqXP9+kTgmDz19nA/HuBLYa9zUrjoUCTMhxe6lz/c7numBLSXYLlVSi8VZxxcNZZ9hysDz8EevTQSw9DzsQyUPlUWufFtZ/p8x2v06fZ+gkaMMD/eZr7TGWRqRByI1MKhfZMKX2ZIUpJ+WbH64Ehk/QyRyUsLn/REKHEumZkkangfLlvo2pe4Q2dUsSJfK/s22eKx0qUypCv3qXP62Wr+YbDkE6psENRihBCCCGE1GjC6ZS68UZzXsQTV6eUs1RPRKpAIeDWzB2Zd9nOa+1qJ/u2dvLLGmjOt70AOCMb6HxT2W/Euk8psQpFyKospGRRCTsiiCjXliqPc0GJUorGjXWHQ1DBpqTQnh9lRQLch0ws2x2W2s6//NCtJE2JiyJKuQWBQ3dlaINcQ4B6wTCpffeduSxUfO9x2RjAW6KLlUooknD90iLcdx/QxUU/85XWqVD9uCCilHJKtToHOOgFoPHRwJFfAYe+owely/pN4/Rtut1lf24Ny5MSmClFAqHKgqV82Pa98++NQKnU7RnQKRV2KEoRQgghhJBaH3Quv4RXpEzKuQ/JCHKlaK/pmGl5un1doNI9Ia6+PWOpLAFJSrRanAJ0+j/giC+BlDb2bUN1LElekqLF6aZbpjpQ2UbKiRAgQ8maoyS6j7XDnKtTar9hd3DdKMg1sWJ1pQktTnPfTjmlRCAqyQ0oiChxTXKvVG6NYulSc/6oo4K7eLT3mL8DWPelvqDvc3r5prg45Bhy12udIRcvDnavpttFqQI3p5SxzCnERUXrDjmFCFSSb2YTO2ueKCV4EblOqWXLgAkTQttWxP2tgT+SdQ5Vlq11UzVoU2+e/4Z0SoUdilKEEEIIIaRGI2KRlXVGwztFSQnQrp3eUUnmK8qjjwZZaR3oZ3QDRm0oW2yy5gAFG+xYy/cSm+md9fo9B7QMIJCEQoJRuiU0OBTVSgiilGAVFWWwHKhbnW95thE+5YYEmIdCijWYyQMc9JL7dlI26Yk2DtS4F1zYsMEsEbKKUr//bgpIxx67Gt9/XxLQXOdzSkk3PMmBkhJOKUUUQVKJbVIOWda9qtxdSpCUsH7JznFzSrm5w6ScT71e24t01S3NYs2qgSHnQmmpMcQN4Giry3TuLPcXcMklZW87eLDuSBQhqyz+/hvYYkSV1VT27wd+/NH/3wvF6NHA2rV6MwVBXIYpOS4dTylKhR2KUoQQQgghpEYj4ddWJDzayq5dwMaN+qBph9GpviJYyzr8UFlCyn1iDR2vf3Dg51kzpZyuJwOvNSw6mOuqPGQeZM43GoIaIUrllW9UG0iUio93iFLibjryG6DLreZGqe1DexEtw6utLvgcOzuwo0wEmRBypW64wRQHrKLUZZfpnQSFI4/coLnAdgbJGK+fshNY8Yr+oP0VZnaTyjOziFL3369P7747gFPKKnqq0j6nKGV19CnkXAz/B+j/PtDjQX1Zeld34bOGIJfJ55RC3XNKyXddIFSDAOHdd8ve17Rp+tTZdMDJjBlA//56l7qajGS6nXAC8GyASmX5N6JNG2DvXksjhf1GcwOFJ8YsNyZhg6IUIYQQQgipVaKUGty7IQHTTsQwEcqv/NasKmu2lF/5nhr9Hvsv0O1uoN2lwXfc52ndTdXhavf1tkypFqgURNwa9AMwcGzlCV0VRUq/AjmlinOBOXcA677G8OGhiVKxsTA75gmpHYAWJwNdbgdan6/nIYUawC0ZUsf8rV/LzADJ6r4XVqJUYKfUYYfpU3GgqI6Cgoil6r5NT9ctYfXqubwngzb1LbV+KksqiCg1Z47uBLE5uZQoJaV4ar5gh3vQeSDXU2IjPctM3HtCZl9zndU1VUedUuK8fPFFYJ5LlVe4eflloH594K23/NdNnAh07OjvHHKyezcwaBDw6qvmsocftneOdPLtt/pUBYWXhYg/r7zi/vpVibikBLfzo5BbQn23a/lvzs+ydKwsT1MHUinwjBNCCCGEkFolSknnJOt401r25Va2Iu6VJk2AL74I/jrWcipxtmiCyeybgTWf+g/0BRExej1SdrlHl1uAU7fZQ8steK0OqsoSpYRmxwPNT0C1E6x8T9xAS54E/jwNbz/5j80NVaYolW8ojUnNjNdpCBz2AdDu4nIeXwOgnjXVPgDq2iunVO4GMwDfcWySe2YtJT3kENOhkZzsn9Tva01v0DjNcHDIPWNz2xkbbp/m+xBERwO9e+tT1/I96zmSYxbkuSteM9+LNYMsGM1P0V2C0nFShMAaSGU6pd55R//+kPNb3VxnNF+8/HL/dfcYjUCtSL6ZKlVTHHwwMHUqcM019uWSgRZKR9JQOPJI4NprgTvuQLUgmVGhlHFLKR+KHM5Bq2uVhA2KUoQQQgghpMYizqfXX7cvW79ez01Rv9xbHU6S3ePkJSMm6M47g7+WuAhsQdNrPta7n007xxy8WAf6lYS3wREoQQy84qYKteysNiFum0Ci1MYffLPNoiZqA+D/+z9g5sxQRKntZWd6VSZWp9Suf4HvWwM/H6SLlwYxMeY9ab0vreJAfHyJTSSwld4ZNEgyxKPE5v5Co7DlF7O8z4pkRpXk+QuoKmNrn+HAWvMJMPNq831Z3XplXcvjlwInramx92plOqVmzUKN5+mn9c+LGw8aVZeq++OqVcFDwN0obwMJ+dFAObus4f7hJJQOrd27u+TDiXOShB2KUoQQQgghpMYibe/d+OUXM5jcOQBxOqsUwX49l32owZRPlNrvSFS3ChOVSXJrTEx8E8XHLgJiVGu5OoQq33NmSm34Htg21Xy8fzUaNgSeew7o0SNw9z2fKFWwPbzZRlan1NrP9S542cuBzb/4iVLilLJ2ibR2OYuLM29E6ZQmIdInnWR/qeaZhiiV5BClMnoAPR7S52ddB2w0apYU1kG29V5VLj0558KO6ea6tM4oF7Gp1dvNMYyZUqU1MJbK+bm47TZzXkrTtLI0g2eeMeeDldMFWxeKtifC1QsvAGvW2JdLmHi4mTsXGDDAfCyfryuvDOAuc5bvNasBztIIhKIUIYQQQgipsXz+eeB1agDkFKUC/Trv7NpnZc8el4FfrjMEN1rvwlYFFETVA+Iso8m6RKDyvdUf2fOMsu02jiZ7n8PKZ9uhe4sFAZxS26rPKbVpvLl897/AnkXApKPQJ+9cxEYX+olSqgQqJsar/SkkV0pK++LizG0lgDmxxFBI3fLAOlxlzv95hs2p5Rtky31qdX20PN04kN/1cPMCS01W/xBSsWsRlemUqomilBI+3TjnHKCppQfDEUeY885SPiuBOtY5CXRKpdxWHI4SJF4R11JVCFOKvn31XLDly/UfLESgkn9XNPFOBf8f9DJw8CtAN5c6SFLlUJQihBBCCCFVjgxmfv01cPlIqGKRFc3N5FJeEqxD1fjxerbPV1/Zw4ultMWZx4Jch4ol4ok1eIqUX5SyjmpVKVl7o4ws5z/b0xquvwntGv2HNy69wl+UKi0GCndVj1Nqz0Jgr6UF5K7ZwNw7gG2T0aTgE5zR/wu/8j3lRFH3rBOrKKUFoIsDS0h1pFer9ysDaEFK9aziqVuelMqikj9vKbB3EZC3WV9+xBf2jnp1gMp0SlWCrhVWJFx/zBjzsQSjh+KGCtYJ0opVaA0Vq0tQzqdk+1V2WV+w6yRZa/Kd0aGD/r3+2mvAGWc4Pi9ZR+qNKEJtkEAqFYpShBBCCCGkyvnoI2DoUP2X/PIQ7Nd9CbR1E66CZaCMHKn/Qn766cDAge6vIwG9Wmi06u6miA+T+FFXRamSXKDYONGlUvpm9LBvOkKfirhSYlw8EU8MoqNK/EUpcftoeMIXTqycUms/NV7aGEpJvtTOGb7NDmn3j59TShGoJNEXUq6EK+UCk1BxN2QArQQrJTDZukS6ZJ9Jl0IY97XPZVb37ulSb912Sllx3mNy7xxzjClMWb8L3cqapUxWifJOYV5h1eFDdVRZWWjRb3/+GTjzzMov6wv2nR/wdwS5P3yflzrqUq0lUJQihBBCCCFVznff6dN/zAZr5aZfP6BzZ/sAXwZlRx1VsWBea4tz64BN6xolooezfC+tU4WOO+KJTQFiku0lfLlrgdICICoeqH+wURbpBfZLSyyr6ATkFSbaBpa6KKVCzusDURZFpypRYeAqSLzrXbowJV0ALcfbsfFy7b50K1vatq1sp11iomWwHCxYXwlWVlHKrUukIsUIJhcx0JfHFabSx3BmSnkrxyklmoVVUKkp+MpXjUYQVpQTLyvL/7vwBJe4pJYtTZfejh3ur2fV9uR8uAl14tAKxHHHBW9EURk4z0NIlOQDpYVV1sCChA5FKUIIIYQQUuVU1LRw2GGmICWdsJYsAYYM0Zc98QQwevSBZZio8HPllBLngFY+lbvRzCsa9ifQ/GSg77MVexPEdEupEr19y0z3jpTMSGmZtn6VX/5USkIOXnklkCgVRlHFKeA0Ge4aEt603iZN5KyIq0TISMnVQ9QDiUuKxCb6NG+Tuaxghz2ny4rqlrdvCVC4O/znL0z4RKkDdEpJV7vZs1EjsDZpsIpSzpI8JUopocl6D7qV6Ml3nTQXELYbH6lg36cSIH7QQf4OrbK+c9X6OXMOUEgKQH5+BZ7kCzn3ADFSr02qC4pShBBCCCGkyqno+FD90v+Q0XBMUKKU8PDDgZ8TCqr0T4lSWpaUIO4XIbEx0PBwYOA37qHTJDSUS+ePU/QSPclhEjK62wWT9V/Zz790osvajUGDHIPy/Gpw+jgFHHHOpRvHbxHeRJSSAb5bSP+cOWUrpvVSjMGyuLCCDZbdnFJqXglWbuV7O/4Of+ljtZTvHZhTSnNM1hCsuUyJiea8s+ROlYdK8Hgo34VSytysmT6/3mEMVTjFVRGWrJ1K5bu9LFFoyhTdYTVpkrlst6GLVgYVErhUyLkIv6oUl1QLPPuEEEIIIaTGilJqsGEdiJXVieqmm/SpCAOSZdWunf64q0ueswpF9xOl8gxRJKFxxQ6c2Ol2pz4t3g/MvxfY/qf+uIHRu729EWa+9nM9b0qdfwCNMnbbyoO0a66CwOMbVI8oJQNZeWwNCW9xijZpkLoTcTHuNqlu3cp+mUwlSsWkBQ/Wd+tqmG+IUgluolR7u+AXztLHainfOzCnlBJragKBgsGdolRUlN0ptWBB8O9fEXhVx7z/7H0GfLg5/qw5fqH8CDBsmH95YLC8wLCIUqGUyJKwQFGKEEIIIYTUSFFKBkmLFgUXpdzCpEVokoHUbbcB559vdvx7+23g1lv9tw3qlKIoVTk0Ogrofr8+v+QpYPMEfb6BUZ/ZeBgQnagHoUuJn1VoKdqDjHSzfill7WPA/PuqoXzPEgouIeOigFidUs1OQKlHt6g0ybC4l9yQ8rzFTwFrPvNblZ4c4mBZHY8KLS/LKZUs6oPHpXypblFZTinVSKEmsM1yideuNbvHBeqop0r8RKyRsj2rsNSqlTkvjSeaNvV/jbJEKatzy80ldcMN/ss2WapMK1uUOqDyPYacVzsUpQghhBBCSI0UpYYPN+cDiVKKU0+1O6Hkl/z33/cfqKWn+w+uJHxX/Yrv55SS8j1SOXS/VxNufIgIVa+XPi+5Uqo8Mm+jrXxPSInbq5XDffyxF/FL7zZXVFemVFIzM1cquTWQ3g1odDRK4pr6SviC4dk6CZh7OzDtbKDAUEYN2jQLElbu5pQqCFGUio4D6h9iPk43Wq/VMSrLKaVK4NxyncLN9On2x19+qQtSgTrmWUvjRMSybmfN4RM3WIMGwYPO3QQfq4Dl5rCS71X5QcBKnz41zCmlyvfolKp2KEoRQgghhJAaKUqtXGnON2kSfF/PPmsfmIjQZA0EVnkr/fvbl510kp5Rdd99gZxSxsCfHDhRsUDP/5mP6/XWl/llJG2yle9pFGdr7pBzRhkB9Ipw5nzFWGoIVRaTdBY8filw7L+a6BOd0jQkp5Rn91zzgRH6LkLDVVcBw4eEKkopp5RhWynKBtR+A3WKPOQNoPX5QOOhwID3UBepLKeUU5QqTwOFyuaFF/yXSZi+VWx6/XVzXho2WEUltZ2Uvh56qD5fv74uSClRaovjIxeqU0p1KFSOK2H5cv072XpMTp56CpWG+u7v3h3YuBHoZWjdoTmlKEpVNxSlCCGEEEJIWHFrKV4WqsW5oHXHszBihN7afK+lGunss/0HkZJLNHQo8NhjgV+H5XtVjASbK3GnnsM6oXKQxO1jLd8TigxbRY4lYTmuHtB0JMKGlOv1eBBIbAZ0v8dcHh2vu5BkcJWsj8ybZZri2ckn69PDD7fsaq8R9gMzH+u0E3bi1Rf2IbqkvKLUdl2A2fQTUFqgB5qndXF/Tr2ewGEfAEMmAhl1zylVmZlSKpepJohSbvz5p9kxb+BA4Aojlk3o2NGcly6lKgNKuvN16qR3MRX3lQj3SpQaNw747bfQRCmrU0oJXoccAowaZYposl/rMTn58UdUGtbsQRHHxCWbnAw88kiQJ7F8r8bgEg1JCCGEEEJI5WJ1N8ngzulCcEMGGDLYePllI+952x9AUnNcemkbXHedvYNUKKiw7DvvBKZNA374IZgoZYgiLN+rXKTL1cGvAJt/Bno6WicmWZxSjvI9LWvKKkpJRtWQSeHvmtXjAf0vECJYScfAzA2+RW+8oYukRx8dRJQqzgW+bwPEpgKdbgytrCg+S3//3mLdWbZpnL682YnBA9LrOJXllIqOrhmiVKC8pNNPN+dFbHIyeDAweTIwdqz5vaa269zZ3E6JUoLco04nqpsoZS29U6KU7Pvjj/Xnh/v2U+dIdR8Up5QIcW6NMMwnGcpafN3rQFnboFOKEEIIIYRUOdaBjls4uRuqq5PmNNmzCJg0EBjbVht4WN1OSpSSAVEw/Dq4ucDue2GgzXnAYR/5DwaDOaWUKLXfEKVS2tbMNu5Jzf1EKSmTEgEh03i7Ud5Cs3ugsGM6sGeBVqKoCXL7FofmlBJ3VqpRprd7ju6UEpqF0T1WA/GicpxSzqDzULrMVQXr11cslN267NtvA4tXzpw9J26ilDVg3SpKCeURpCorp8utS2tQQUrIWWV+l5BqpQZ+kxNCCCGEkLrulJLHIiIFanUu+SZqwKL9+r1rtrkyf7tt8KFEqWOP1UtVAmEdpAQVpUoKgEIjfJpOqfChMqVy1+klab6OcRZRyhdAbwSN1zSSWmiTFpmmkuAcpKeWrodHuu8ptv5udiMUds0JPetGlUBOOR4o2A7EpgENj0CkIue6tLRynFJOZ1R1OaUkqFxo27Z8opRVbFKijVsoubXUzykUiQNJMprcnFJShv3oo8DTTwcWvMpCXlvKEA+UfftCa4hhI1uJUu0O/ADIAUFRihBCCCGEhFWU+uYb4LnngPPOA7oEiL6xLtdEqVJLDcv6b2wDIGv5njVsVyGlgieeaF8WVJRSZR0Swi25RSQ8qI5xu+frLhdxQqW0tmdKFe62B43XUFFKOaV+/tmxvjgHBxUYo/isQebyVW+Z88oNFhdCXWqrs+yPGx9jD4+PQCrLKVXTRCkRcFavBs5yXHKnCzRUB5RChJx7LBFp1vD0CRat1IqUPr/9tv48lVclGU5l4fx+FpHsyCNxQMg5uf56e/leSP8g+ZxSFKWqG4pShBBCCCGkyrEOdC69FLj55uDbq4GOoOVPKaFI2PlPQFHKbWAknaK++y40UUp7vrXzXk0sEavrTikpYxPiG5huoWKnKFWvRgtrjTP0e2j4cPvqqDUfIMVrdObrcA3Q8QZ9PtdSo1W0L3SnVPMTgH4vmo+bjkCkU1lOKWe5XnWJUhuMSlBp5tC6td5hrrzle2Whuo8686KcHUytPOyMhEsqOzBeuktedBEOGHF+STdOCTSXzEFFyE4pcRVq3ykeIMVwY5Jqg//KEkIIIYSQKsc60CkvUfJ/rAU7zQW7ZtkGQNZufM6OWcpF4CyhCiRKaQKXZBopUYqE3ymlSG4LxBghX7OvB75tDuyZH7qLqDowwskT4/KR1cAlhGifXq9a2uAIoNUZQL0gvetDbVXf9iL9XpW/FkarvwjmQJxSIoaPGQNs2uQvQrk1RginoK/y7kIVoJxdSoVTT3V/DRH+1T6eesp0SKkAcWfou/V4yiNKyXfxSy/hgHn9deDLL3WBS2W1lUuUUqV7kgEn3TNJtUJRihBCCCGEVCky0Pv338Dr160LwZGgMp6Efcuwa5fpgjjqqOCilCZqITRRShvI7TIONs3SoopUPbEpeiaSIr2LKUqVFgF5G00XW011SsWYx//kI4bjyYInT7e9eFuerS9I7xp4X2V137OetxHz9b+aKtbVkkwpKQMTF+ewYUC2YdhT3HYbws727cCTT9pdS27fXW7le+ec47/smWcCv5YSmUSUk3w+648JQ4cCDz7onuOkCFS+ZxW0LrlE3+5ASvYky8p6LbKyyvi3Q+6DNZ8AO2eZy1i6V6OgKEUIIYQQQqoUt1/srbxlidNZvBh4913z8bJlxozVKVVagGGH6eVOffvq3c0CiVJXX+3+mkGdUjv+0h80PDz4gZPKJ6OnOZ/WRRdc3KipolRUNLwx+uj8grNdRKlcQ5RKala2KBWqU0pIyNL/yAE5pT76yPweEkHISWWV8ElJsbh9nMKXE+naqFCiVKjle5Lf5BT8W7UK/FpO55PELqkueyIkSYnf3LlmppUzAD2QU8r6o4A6zmBlgWXx1Vf2Dq7Wfbmez1XvANPOBX47GijKtotSqRSlagIUpQghhBBCSLWy06I3desGXHmlKTD5OkNZnVKSr1JvpdYq3dm5ySpKSRv0QKUi1nK+cePM+cyMYmDHDP1BBHcxqzasmUj1D7I5j2qFKCX3luH28hTt1V0as24AVrymrxS3lwz4VfdA2bbvGKDBYUCjoysuShEfFXVKieDi7AAaLBvvQBAnkuQrOXOZrDz+ODBlir/4csQRwK+/2h1CgfKjrELRa8YtGKooJY4p5YaSdSIu9eoF/PNP2a9lxa30L9CPAqHg7NiqSgyFQw5xbFy8H/jncjOrbaPxZc/OezUKilKEEEIIIaTS+OQT4Npr7W3Fy8Iaam7FmhXic0qp8q7sFWje3D9DxCpK9enjXrrnHHBKGPXs2fpgKyXvLz0AN74+kN4t9DdBKoe2F+vZSFkDgYZHBnb/1GBRyicmySB45z/A8heBmVcD+9fCIwHL1lB3ofONwDF/6dlQFSnfI5XilLKK08ECtisDJYBJfpO1M6mVu+6yP1ailAjqQ4YAbdoEKN9b/w2w6DGgOM/2/RhINHLdB4BbboEm/AvNDA1VdcxzI9D+v/hCz6yyimIH4pRy5gPusvxecd11jo1n/5/98YZvbdluSG1f8QMhlcYBaJSEEEIIIYTYOfdcfTpokN4d6UBEKWtZHgoNUap+f2DLL5oo5YZ1sKN17QuABBlbf8mXMkCNpXP0acOB7LxXHSQ2BkZtADzR+uhTHjuJigOiQ000rgaUcCpOqTyj/kkwHHhe8QXEWW9ugzirCkunVIUzpbzKKVU+UUrcR2VhdeVUFu+8Axx6qC7CS8ldIJxCjrXraCPVk2HpGOBfo7Vp4S4k9HrKt03XIJWigb4vZ87Up9L1T/Hoo8Ddd/tvGyhTSjL/JJvK6o46EFHKiRKl5N8bv0zBrb+bgeZSOrv+K2DXHGDvAn15Ru/KOxBSYfgvLSGEEEIIqRSmTjXnd+wIPVtq9+4yRCkpwyk0NmpwqD4NIEpZf0UPJkoF7Aa4b0nZWT+kaomKMS9kcht3l5TTLlEjRal9QK4l1Ge3LngWQNpBRpXh/vKYIe+kXHi96t4oX/neBj3uy8bEicALL1SuU8qplV12GdCjh92N5IZTyLGWxTWRxpXbpwNzbjcXrvsSUR6vFpR+550W4d1K/jZg0lHAjEvh8fiLeKpUzypKnXmm+/EFc2I5y/UOpHwvUPm3n9AlJzrXsHoN+1PPqJN/S37uC5TkAzGpzJSqIVCUIqSSkfyKWZbmDoQQQkikYP313KoZqHDdr792f9706XpHJSctWxozKptHqB9ElFo6Bu1X9EG/NrMOQJQyyjrYea9mIOJgfEPHwhosSNnK9/ZqJXs+xKEhBhZPAAdUvMUpldCwZgtvNZiKOKUkOFuVqllp3FjvyKcEo8oQpSZMCL4+0GE7RRfr7aHlQS17HvAW6w0axE0o997yF7VOdY89FuB2WvwEsG0y8N87aJnuCGuy0K5d8E5/oZQHBnsv5UF1I1Soxhh++5SSb+naKSQ0AYZMBJoYbQWF5qPohq0h8CoQUolIu+tTTgEOPri6j4QQQggJP4GEnsLCsrvwqa5XViT0XKPAqM+QrmYZRuupnP+AUktwVWmxVraSmD8X1w57ueKi1F7llOoS+MkkvK6pY2cDw406IqHUuKFqKrHGqF06feVu9HdKBRKlEiylinRJVQgRXirilJozxyzNk4BxhSqnS0ioPFFKfsAOxN9/60LYe+/5r3OKLk88ATRsaAlL3zFdn/b8n/4nLHYoOMLS54GJRwB7l+qd6QzaZs4LSZSyZf1VUJSyCm/lEajkeYG+uxcuNDYQV61M843gQMkHjI4DpOPl4HHAEV8Ah7wOHPpm6C9MqhSKUoRUIjOMZj2EEEJIJGIdLFh/lVdtxZ2h5FKyovj9d3+HgK+7VJ4RABWfBSS1AKLidWHCWhq1a7Zvtl7KPrRo4d71SXHyyfq0tzVSRMqtVBB1aqdgb5WEk+QWeic+3+Mgfe1rAlIWJBRnA0WWwDTj3ir0BOooaBGrkpRNkITDKTVtmj494QTgjjt04UgCupUAo767KkOUUk4jt+8n6ci3bRtw8cX+65zijYj2su2998q9lmt+H2b0ANpdYhzwRi3w3Ma/NwLb/wJ+GWC7PxsnLw/p+OW4J00KPVOqrGwu578LZTnaAqFVqix5CvgqE5h3F5C32V/sFWdUy9OB9lcA0UF+tSCRI0o99thjOPjgg5GamoqsrCyMGjUKy5Yts22Tn5+Pa6+9FvXr10dKSgpOPfVUbN261bbNunXrMHLkSCQlJWn7ue2221DsuGMnT56Mvn37Ij4+Hu3bt8d7bvIzIZXY0vqee8qdr0gIIYTUaqwDNiVKbdyotxWXgYx0y7OKQtZ251I689VXATKlsleanZJkUKFyQDb/bG682+znfsKwzVhldPy28d/7wOqPtdlnnwXeegv45RfL+gIjCCs6CYilU6XG0e0efSoDypqMcjkV5QCF/in+AZ1SQv/3gcRmQC/D6ULKTUWcUmvW6NPORtXuqFHA6aeb68sjSrmVIluR70Th6qsDd+VzQ8thWv4KsOJV/5XiHBViM/TAfPlT4qi1hDTX0uHBKphKh71U+zhccYV83EoKgBWv+UpQrZ3/FMkly4CZ15nfxas/Asb1APb577egwJwvT5WqKtUTrrzSvk7rtDr3DrMsUf2YkSiBW6TOiFKlpaX4/fffMXr0aFx66aU4++yzccMNN+Ddd9/Ferci3DKYMmWKJjjNmDEDEydORFFREY455hjsVz+nAbjpppvwww8/4Msvv9S237RpE06R+iiDkpISTZAqLCzEtGnT8P7772uC0/333+/bZvXq1do2Rx11FObOnYsbb7wRl112GSaUVdBLSIhIZwopO7CKUtKZQuy3qmSBEEIIqesUGfEd1oHG5s1mEK/1l3T54UbK+dq2NTtfObv1+USpHIsoJTQaqk/X6AKTLQtKNKX8Df4lIVsnAzMuAqafB+ycqWWwXHqpXv5iyyBR5R6k5tHzYeCktUB7x2i0ppbviVOqvKJU2wuAkzfouUAkLE4p2ey55/R5q3BuRYlSwbrvSXOH998H0tP1jnpliVLtja+zUNm/cxsw61pg5jVAnlGaBjfh3qP/pRjK0f7VloM0LGEuXR8bJRvKnINXRQNb9gIw82pg8nFaqbStM6pB4uL/A1a8DEw7F5h7NzD9fGDvQmDh/4KKUsHcT2++qWd6yTUSd5ZViHrmGfuPCumJRpm3Qr7vVZ4Uqf2iVF5eHv73v/+hRYsWGDFiBH766Sfs2bMH0dHRWLlyJR544AG0adNGWycCU6j8/PPPuOiii9CtWzf06tVLE5PE9TR7tm6/3rt3L95++208++yzGDJkCPr166cJYCI+qdf55ZdfsHjxYnz00Ufo3bs3jjvuODz88MN4+eWXNaFKeO2117Tje+aZZ9ClSxdcd911OO200zBmzJiKnTVCLOTmAoccApx/vr+VVSy1f/1VXUdGCCGEhBfrQMO5zJnvpMaLMogLhK89uhpwpRijuI7X6tOds/QsKcH6a7z8Qm7NmxK2WP6RlhIPFZxuO9hdtkEaqWHIQDu5Zc0PAI+xZEpJ2LmDgEHnpHIzpVw+4/K9I40V7rsPyM7Wl40bZ67vbkTWOQnFKTVkCHDRRXoZswjegdhi6ElubqNgDOprKa/b9a99pWr8kNLOvwRUdaATtruIUg0GaJOOLfT2gzfc4OJA2vq7/iB/q5aNJsKbdCZUyA8Oni2G4WPvYmDxY+bK/f5iV36+KRiWOL6qnS6tl17SxSdnIynJsBo2DHj7bf3x+29Y3AFW6JSq8YTUjLFjx44YMGAA3nzzTQwbNgyxLmlka9euxSeffIKzzjoL99xzDy6//PJyH4yIUEKmUbwr4pS4p4YONX4N0yyVndGyZUtMnz4d/fv316Y9evRAo0aNfNsMHz4cV199NRYtWoQ+ffpo21j3obYRx5QbBQUF2p9in3jOtV//irS/2ow6/tr+PmoS67Tybf0zsWiR2xbFKCoKfx0fr3XkwGsdOfBaRxa18XoXFcn/WuoDwry8EhQVlSI3Vx7HIC7Oi6KiYtx/fxSeey4KDz8s/z6qwZ570m1Wlvy/FxCdvVL7JbU4sRW8siChFWJiUuApzkHRroVAejfEbv7JfKK3BEU56/UyKIPoXXPNX2PXfYmS1G4o7WppFyhHnrdV+5/j0rhMlITxvNfGa00C44lK1O+jwj3wFO3z6xWY78nkta4ivN5on1OquKRI/76w8PjjUbj/fj3MacGCUnz5ZQmefFIe68859FD9O8fG/tUY2HYhJuAU5OTo32tuJXsLFsSG9Lnes0f/nmzQoDik4fjy5UXYswdon7kGMPSlkj2LUJo1zLdN9N4l2jsoSWmPUuP1ouMb6styt5jLclb7uVJKMg9F9KZxiC/dhK1b8pFRLxovvGC+Fzn+6IIdvucV75wHb1pvDBqkl11//nkUzjs7F5jsfvzeXXNQnLsTiNWz1KLm34kJl7+NIzZOxry1vVFcrP/b4I5+HNu2FSMnRz5JZhBXcbH+nsQYcOqpQHL+DuBXwJvYXHO7evbowe0lcQ19778q4fe4P6Gei5BEKXEjicMoGK1atcJdd92FW2+9VXM7lRcpDRSR6PDDD0d3Q6LesmUL4uLikJGRYdtWBChZp7axClJqvVoXbBsRm8QFluhIV5Osq4ceesj1PEhuVV1AyiVJ5bBxo+QGHB1w/axZf2HfPn/rdrjgtY4ceK0jB17ryKI2Xe9WrY7A0qV6XceNN0ajQYOfsXy5/Ng4APn5ezF+/BT07avngvz3n/63dav8v5U5uFIcffRa/PrrXM3aMCJ3qTYgmjpnE7LnjdfWH1HaAvWxBAsnv4NiTwJU49sSxCAaxZg+6Uvsju7o29+w3H9g+7+4RY9gyYoNWB8zGMUePQOoTdGf6CklhzsLMGu8/jrhpDZdaxKYJsXLcYhUnW5bjjToP0wWIRGx0G02+6Oa8FpXEXv3DvQ5pebNnYMNC+2h8o8/PsInbHz/fRQ+/XQC/vjjOO3xW29NwKRJ/vV5J+0fhbuPAH6Z/Dtmz66PZs2M/CYLOTkinsi+TV58cZaWUeW81rt3H68dw6JFvwE4Juj76dVrGxYv1rvqxa+don0/CesXTcK8leb32xF5MyDfvHNW5WLjWv27q0vhPsgWa5bOxMLV+rJBeQtgH1kDf68sRX9EIcpbjDnTPkV+VCbi40eioECXCsaPH4+jczdCpeytmPc7li8x656lDHHe31v93sm26N5ILN2B1JINWDz+bqyJHaH9YHBS7rNIiQNGn3o/Tnp2rOaUktdw5yTtv3PmzMPq1XItO/jWOJ/TsGQuDhNDSX40FnpPweHQRak5S7dg48rwfZ/zs22SKyVFlSVKlSVIWREXVTtrz8gQkWyphQsX4s8//0R1I+LazTff7Hss4pWULkreVVpagG4ZtUitlA9KIMcbKT9a+9EgiNB68MHV45TitY4MeK0jB17ryKI2Xu9HH7W3k8rIGI5evfT5hg3TtKgHJ9uNZndWOnXy4qefpHavqRY+HjtW/x/bI4+7EIjWf0yMWjgDWLIEvZruBfKWAVuB0oaD4SnNB3bOwGF9WsLb3Hi90kLEfK2HmBcNn4+YCb0QjSL0LHwL3ZuVoOSg1/V9LpoNLAYat+qGEf38j7WqqI3XmgTGsyUW+ONJpMbsFTUK3qh4RDc/CVj3GUqT2yHb25TXuop45BHTKdWrV0/0bGV+jqX0LjfXPOcJCV7s26dLKW3benHBBUP8dyg5c2P12Z4t5yOrzbUYMcJIQ7dw2WX+rfR+//1wdO78o+1aS+5UcbG+7cknH4Xrr/eioCBwOeqwYfV935tRC/8BlujLW9bLR7PB6vutCDHfX6Dluvc68iz0qtdH337FKmDu12jTJBEt++vbxoy9HCgASjMPQdSuf7RlBw+9EJ5f3wLyNuDowzrBm3kwevaM0jJzBXn9mLHF2vOEji1S0N75/bhnLuDQYuq3OVwvuZ57E3rG/Yauw58DctcAhqn1qEH5wLN6ueWxx47QywQD0LNnLxQW2s+T898Tz/pcYAaQWr8FDjny/4BvH9CW9+43AL2aVf33Ob/H/VEVZ5UiSglSkvfII4/4psEcT1HB7igXJOPpxx9/xNSpU9Hcki7XuHFjLRdK8qusbinpvifr1Db//KN/oKzr1To1dXbsk8ciMDldUoJ06JM/J3Jz1ZUbrC69l5qI3K5isxW83hj/sNUwwmsdOfBaRw681pFFbbrezuYe8ku7ygtJSIhCbKz//yNKAPo55wCffKI/7tQJ+Pprj/me9xqdo5KaIzbB8uNgA90bFbVvsa/LUlSfx4Glz2iiVEzBFrOHera4+L2aoBWb2R1I7QBk6/ksUXvmIEptV6xHSUQnNEB0NZzz2nStSRAS6mkTj5En5YnLgOfgl7Xw8pJGw4Epi3mtw5ApFSNjUss5lo6fVvLzPbj+el0gat7c8p1jJccMFE+IzUdhYTRiY/0FqA8+8H9qdLR+HNZrbc2fzcyMRUKCPYtPEnDkB2/JvRL27LG8XqGp4EdlLze/t/auBIr3aV0fYxsepHcoFZL0LKWowh36tsW5QIG+j6hO1+tB5GldEJvaSvt+FVEqplD/3vz4Yz0X6667gFhp+2fp1Bedv8n/+7HUbFTm265ed6D1OcDih+HJWYnY3dP0nDWDJK9ZXRUVJefI/xya5zLG798Xv+tVmqPvK74eohLTge73aRlaMS1GAtHh+6zxs20S6nkIWT369ttvbVMnGzdu1MrvrtB6RoaG1+vVBCnZ52+//aaFkVuRYHN5I79KOxaDZcuWaeWBknElyHTBggXYJonSBqJQiuDUtWtX3zbWfaht1D4IqQjTpgESVTZPd4basIYksvseIYSQSEF1pko1cp6vu07KLvT5uLjAg0gZAIl4JT+qLl0KdOtm2cAZcq5Qgb77lpitv0VsSmqhz+fpob22oN3k1voL1uttrpMW6opC1X2PQefkAIhVhU4GcRn6PdXpOv0eJOHpvmeUTiqsgeZOHEkvJrnm90ij9K2+cPRQWL/e3wGljCPifxDNTEQpxa23Am+8oY8xFOKs8pFntDIV8rcARcbOCoyNEhqbgpT2OMvYdps98DwmBWh9LjBkIjB0qv6dKKKU5f126ABMnQocJ5WNJfma29Q8DqN9oBVnl8moeKDZ8XqOVFO9PBLb/9K78alN8lbD4ykNOF6SnC5rQH2wzoe2Y1Df6T1HA0dPkl8ZyngiqW5CFqXEASXd69avX691rvviiy+05Tt37sQ111yjlex9//33rrbsYCV70jVPAtJTU1O17Cf5k5wnIT09HZdeeqlWSvf771LDOxsXX3yxJiZJyLkgJXUiPp1//vmYN28eJkyYgHvvvVfbt3I7XXXVVfjvv/9w++23Y+nSpXjllVe047/pppvKe74I8XH44Xr76osvti+XL3HrPyDMuiOEEBIpqEFDS6Pp0+bNktWpz7uY0G3IAE2JWQFbnVtRIebF+82BiAz8HYMrrTvf8pf1eSUIdL3T3E/hLpfuey79zgkJFXUPKmLZbS+cBOq+N3y4Pj3ySL1bnJUA/a/solTaVjz3nP69FoyfjPK0DRZdXLHT0L0vvND/e7GnCoyC/sO3cNlllifnO15471KzxFDbmeN7yylK7TecScmtdCGq8VAgoYG+zPm9acXiktLYPQfY8Y/7Nk2OBY78Ghgyydyn+hFAfkDYY4pSntJCtGm0KWAZt3UMJQKVtfOhs0Og7RhEBCZ1U5QS8ek+6Z0JYNOmTTjnnHO0x3379tVcSNKZb+XKlTjllFNCfvFXX31V67g3ePBgNGnSxPf3+eef+7YZM2YMjj/+eJx66qkYOHCgVor3zTff+NZHR0drpX8yFbHqvPPOwwUXXIDRo0f7thEH1rhx4zR3VK9evTRx7a233tI68BFS2cgvwWPGmI/plCKEEBIpqDIUtzhSzSm15jPgl8P0X8xDJXuZf6tzNQCTX+MVSrRyDq4WPQJs+NYcjAmZfYDhM+0DOoFOKVIZxNWzt6G3uvFIlSJaSyCnVLqhDZ52mpTO2Z93mCRku6HcRYZTSvjsM/sm4uJRvP66ua/duz3Iy7OX+u0ydG/1+lanlDVVZuxYvYzP5vdQTim5v7QXmGN3SsUbApMiPstcX1oC7Fel0MavBlZ835vm+w3oghJmXOi+jQhCLU4Bso7w/wFBjt/ilBIO6qKHxm/cGFyU+u47Kes2H8s1DHicFIFrHSFnSqnuc1KeN23aNM3hJOLPWWedhQ8++AAxUmtaTqR8rywSEhLw8ssva3/BOv8FTuzXEeFrjvKPE1KFyP90H3usnomxbBmdUoQQQiLPKdW2rf+6HIn7mH29PkCafRNwrOOX9kAoAau+9DNzjD4Tm2rt2m2ilLQDt4pSmyz/j5hsGYwpV4EIUYse07fbaRwTnVLkQEnr6i8ikGp1Sqn/J5eYG6sr83hphhcIi3OoQaou/qio46++ArKyAKOAR+OMMwDpiyXjAflhWu/K5++Uql/fX5RyClS2MmZ5L/lGRrKE5v/3HrDzb6DDlRYx3fG9pT2Wc+HVt8lVTikXUUp9f1qcTH5iT3IbrXuetp99S/WMqpgk99I5K0qgFdereg9pnbV9dGkuotRA7NXj12wUF5vz339vX+caYW0VxkjddEpJRtMRRxzhE5LOPPNMeDwe3HLLLRUSpAipq7QyfoQ1cvYpShFCCIk4p1Q9lzH41q1e8xd9yUMJBSnNU7/ci7vJSZLxC7yQ2tH+i7/knpQWmYOs+ocC7S43t1cDOMlLmXc3sN3SAZpOKXKgZPYz59OMe5OEhUBOKasoZc2Qeu210ESpesm7temiRbomfvrpwKBBwPz55uYq11kJTEVFFXNK+SHfnSIIicjUdGRoTqmoGHOZiEHqvbiJUvL9KOxdZGZVuZXFnbQaSDBO3p75oZXOpXUxv5O9xfqPCVkDtUXNM3SnlGqIYXvZIGMoVSJuf4KhbFGUqruiVJwjnVICyKXLnmRBEUJM+hn/D6I+MizfI4QQEglYg2jdRKmkOEsgiAhBoaDypERAcnObqLIQIcMIZEk0wn5FkNr4A1CSC0QnAcP+MvNThJhUwBPgh9U4ilLkAJESJkVDSykTqTanlHLeiJ/iyy+B1q2BZ58Fmlm+RvywCOiZKbqi9NFH9k0O1huB2kQpJTDl58fYxBUlSrk5pYKKUnnGcYjIpL7r9i3T32OgTClnrpQSpazfm74Xb2xk7nmBnUZps6LQIvbId2u9vsab+deyTRBRKrGR7rJSNDzcdwz1k7f5hZq7OaWs/PIL0MLoZ+EqSrF8r+6KUv/73/9sU+Gdd97RMqAIISYSnmgVpaxtXgkhhJC6igwg1MDC+pulKuW7+Py99sFDCDEOyF6uT1M6uK9PaGjO1+ulT6Ni9S5Uwh+nmuuiHG3cxeoQyBHlNrgjpDw0OBQY+B1w6DtA42HVfTQRQ7BMKatTSkSh1auBMvte5ZsJ3GmJ2YiJLsJWowLNDSVKqde6+ebB6N07xiewqPK9cjulVNmbuJRS2urfcyV5enh5IKeU2l7IWWWKUs4gfoUqkbaKTdqbcWQ1qeDyPQtctgngUmpg6Xrf4HCfeJWasKfcTqlhgT5OzJSq+6KUBI1bp4J0vKNTikQaK1fq9eNOpIuHtLQWG6+QkmLJ0CCEEELqONYfYawdpf74Qw/tveQ8iygl7cWtAeOByF6hT1MDiFL1LWEuMlBTOAddGT3cnx8oO0oGfIQcKJL90+5iXSkhYcMLf6eUOJSka7ZVOCp7R6VmXpOjhM8NcWCpS60cUcKKFR5NAMvNlXm7U2qBRddxy+Lzc2yJo0nK8tR3omQ7+ZxSLqJUo6P06eoPyhal1D5z9JK6gC6oVKPphMrzc9vGSZNjjGOsD7Q83SdepcYHFqUCOaUCwvK9ui1KfeZsMRCE9evX46+/ytFRhZBaxjXXuLctHTAAOOcc/w4fbsF9gZAvX7cvZUIIIaSmo0r3nIM+MdWfcAIQU+ro4OTW5am8olTrs4F+LwLD/9HLShTOQVfzk92fT0cUIXWO0lJ/p9SDD5rrQ45DLtjlE7a80cnaNDPZojY5CCZ2yXjgrLPMx8optdnIwreOHYKW7ykXqMppmnwcsG9JYJG99blmw4jibCAqzr37nqCV78EMRA9UFqd+ALCKV8GCzoU2F+gdT0cuBpKamk4pQ5RyK98rdy4vy/fqtij16quvokuXLnjyySexZIlx01vYu3ev1v3unHPOQd++fbFT+RIJqYPs3+++3PkPXHlFqexsoE0bvXMfIYQQUludUvLvYXOLJuQziahcEqcoFayMryxRSoSoTtcB9S2hLqqzk+LkTUDTAP+4xhi2ZqHb3fq04w2Bj4cQUqOR7xs3p9Q6i84SslNKlcXFZsAjuUhlOKWC7ffWW4EffvAXpS66SJ8+9FAZx2It33O6Pwt3B3ZKpbTRM5wUEpIeE6BOUFxY2mvpOU8BBSclSu1fC5SW2I8hUKdJuTD1DzIzrgxRKiWIU6pcubxyrYuyjeOkKFUnRakpU6bgiSeewMSJE9G9e3etE1+HDh3Qo0cPNG/eHPXr18cll1yCli1bYuHChTjxxBOr/sgJqSaSjM6nZf1DFKoo9fTTesnfBx8AGzYAkyZV0oESQggh1eCUkoyUvn31AOFvv3X5Fdv3hC16W/PPE4F59/jvUMSqvUsq1r2s0/8BzU4ABnxgtiN3o+kIc4DX40FgyESg7zPley1CSI13SkVFVUSU2m5m1xnND1TYuRvB9jtliv2xyp595RVg8mTgHpevwIDle0K7y0J3fjY4zJxvc17g14hXoehbA5TFGYObxOZ6kwgpw87bZBfwrM0kghFbtigVyAjginaMXvtxklpDqOZFTWiSvx07duDPP//E2rVrkZeXhwYNGqBPnz7an3TjI6SuE+gfHKdTSoUVrl2r/391oDiB227Tp9OmVeZREkIIIdUnSgl+AcJOUWrW9fqgRlj8JNDzYXsJnuSVFO4CouKB9O7lOxj5NX7Q2LK363CNPtjM7KPnSDUeWr7XIYTUONycUtb/Dy+3KBXf0OeqDCZKWUPLpbvf6aeX/RIyXlB5tOVySiU1A47+HfjVyIwKJkp1vF7vqCdh44FKmbV9W0Qp6+BFuaCUA0maRiS30sPT5YeFNR/qXU61YwhRlFJOqbjAotT06fbHUlHy6qsB9pezxnj9hkC05UKQuiVKKUSEGjVqVNUcDSG1ACmzU0gL2Y0b9fnoaHeRSpxPd94JPPFE8P2WO8yPEEIIqWYkB2T2bKBPH7N8zxpy7loC4nuypTbDWwzkbgSSW/gPMqT8JNqwFVQ2MrhqY2SuEELqpFNK9JVvvjHXW0PIXdkwFlj5JlC8z3RKRSX4ZUo9+ihwt1H1K1j7f512GjBjRhH696+kpgl5m+2ZUtYueGU1aJDv1aG/l/0aSpSS72Yp4ZPupLJP5Yayuk7le1lEqQX3218/JrVcolRcdAESYvNQWmovKVy/XjoX6vMHHwz8/bfLD/z7lgPb/wDaXqwfi3ZcRgg7qVXQ2kRIOdln/PskfPKJOe/8orT+CvPkk2E4MEIIISTMnHcecMghwBtv+Dul/FADm0C/Ymcvtz9WYbuBQnkJISSETCmJx7ByxBFBdiAlw1NPAjb9CGybarp/RKABkJVhilKHW6KarJ23FVLG/Pjjxj4syI/V+vF5g2fquX1/ikNKUdld5mKSzJy9bxsDkwbpmVH7je9icUe5dTtVyHkKtdOkvI7hjL122Mt+TqmFC+0dzv12K+dt0kDg78uA/943RSnVGZDUKihKEVJBUUoEqX79Am/nLOdbtKhqj4sQQggJN59+qk8/+igEp1SeYS3OtPzjKb/6Nz3eXZTyDYQoShFCKuaUEu1COmcr5s7VO4IGZIGlTZ8iqZUvU6ph2i6bWPL77+5OKUXnzrvx5ptmOcSHHwKPPWY8+Oss4Kt6wPrvgr+hVW+bJXTOjLx6fdxdUxUltb05v2O67kQqMlyuSRYna6ajuUSwzntuiCBliIZPn3sb4ks3BxxHueb5Zq80SxrXfwNk0ylVm6EoRUgFRaneve1fmE4F3ylKSeCrG6H+oEAIIYTUVHJzQ3BK5Rp2hcyDzGUSMK5CzPcZnfYU0tnJ+es8IYSUgdUpNWsW8OOPZtRGr17BnugFtv5uZhMpmgzziVJJMWb3PRHgu3WDTaRyw+qgat3amNm/Hlj3hZ61N+u6wI6pXbN1N1Ag4af/u0Dbi4CBIWTohUKXO+zZVJsnmF31Yi2qW9Pj/J9bklfhl830zAk4jnL9N0UEM8W+pUDOf/o8RalaCUUpQsqB/HuhRKm0tOBBic51HV0aB0mtdKiuXUIIIaQmYf33a948YOZMfX6TUWUSUJRqYhnMyK/7qcY/kNnLHNuzfI8QUj7kx17llFq1yot33jHXdeoUQomchJt7ovVOnM1PAvqOARr010UZR9C5iFJWZ6jqqOfE6qBSjZCwd7HldTeaIryT7X/5v0Er9XrpwpQ1j+9AaH0WcOoOoP2VpgvJTeyxlhEq0rtW+GUTsDWgKFVPP/V2ds4w53NWAjv+ClxWSOquKFVYWIhly5ahmOnMJILIyzMDyUWUCtZw0umUctaZr1kDjBlTBQdJCCGEhDljUXjgAX26xehc7qdgqZbm6V2AbncDya2B9ldYnFKW8j0p61BB5yzfI4RUwCn11luleO01c3nAzm2KXf/q07Quutgz8Dug8436snj/8j0RoawunnKJUuLusSLCihtbJlWsPO5ASetsL6t2Kw/sZdQh1j9EL8vu9Ug5X6OLbzYB2wJqbxlub3uX3VmFEsOqy0ypyBClcnNzcemllyIpKQndunXDunX6r1jXX389Hn/88ao4RkJqDJ99VrZFN5BTSmVtBPqfeUIIIaQ2sXOn+/IrjR/YbRTnAKVFZhiuDF5OWq3nl6Qa9oX9q4GSQn1w8V1Lc5CWVpa9gRBCTEq9+hDXY3TfEwYO1P+CstsQpTL7+q8zyve6drA7paz/vx+ogiIlxesvSvk5Q10sphIyvuVXfT6jJ3CMpWStqkntYH/c8Ej/bbrcBoxYABwzAzh2VvlzrY76yTcbj11ah72GDYE//rB3JXcVpdS/D8rRpbB2JyR1V5S66667MG/ePEyePBkJFml46NCh+Pzzzyv7+AipUVx6qTnvdEnZ3LReL2Ki7W0kCi2dr4W9e6viCAkhhJDwsNmeS+vjwgtKgdUfA7vnmwsLdpqd96TDkxUJ7pVOTN4SvYPS7nlmKLqscwb7EkJIELxe/X/Ko6L0IG2VBVsmO2fZw8NdRKk4r12Usv7/fyBRytUppcqZFcpJalu2GSjJBTwxwLH/AumGeykcOMv1slwUvahoIKN7xQNyk1vh+1X36LtCPvr3B3bs0MVDa9mlnyhVtA8o2KHP934MiDJqKOU8Maw3MkSp7777Di+99BKOOOIIeCwXXVxTq1YZqfeERDLyS/Dvx2Jkbir6t58e0CkV6BdmQgghpDYgXWjdaFL0BTD9POCXQ/Vf+oXCnbaBnQ35/0nlhpKSFmvWypHfVvpxE0LqeKaUi1OqyDBqBkRKhlUuUYMB/uuN8r2Y0t3weEpdO40GEqWs2/m2yd1oF38k8FxRnKcL+yrMW0qYRQAKJylt7GWDVdRwosSrm1yivEb5naVLoWLIEMeTVKc9CaOXrC9xa7U4DTjiyyo5RlIDRant27cjKyvLb/n+/fttIhUhEcuGscCWXxCDPFx19GsBRSmj8pUQQgiplahue07SiozEcynD27vQ7pSydnWyPckIyN0zH9hniFIdrwcaHFq5B00IiUin1HEuzeJsyHdP4W4gOilA+Z6etu1BKVITsm1i01FH6RUUZ5zhvuvGjYEjjgAOPxzIzLSEqgvpRvs+ee2iHGDCAOCLJF3Y/9PYoeTvhZvoeKDRENONVEXj/HUbdVFq/pwA/6BIyaQzP13lXEn5t5DWATjyS6DFqCo5RlIDRamDDjoI48aN8z1WQtRbb72FAQNcVGVC6hANGgRe5/uuXv+1b1m35ot882++ad9+bYAmG4QQQkhNR7rtqfKK66+3r4v3Wur6dkzTpwVGyUtcAFEq6wh9uuBBYMnTB9zJiRASuTidUt99B5xwQhlPWm1Yc5oMB6JcLE9SehydaOvAF22YlyZM0MuZNUePuEMdrbVljDB1qp6VpI0XSouB/K3277nCPfr3n7WrnKI6RClh0Fhg6FT/3KZKZOVqXZRKiAssSvmhQuItQemkduPoD1Y2jz76KI477jgsXrxY67z3/PPPa/PTpk3DlClTquYoCakhHHkk8O23wGNGswkrZjeNJb5lnZsu1Sy+Xm+UViMtHfdaG/+u5OSE6aAJIYSQSmb4cHO+5f+3dxfgTd3rH8C/Sb2UtmihuLuNAYMBg6FjY8zdufPdubvc/ad3epnf6Z0bM8ZgzBgOG0OGu3tbqLfJ/3nP75yeE23aJmnSfD/PU85JcpKc9hB784rbcLx4p6UMJW+Na/mer0yplqcCi65RfaUMVW2aS0RkzZTSy+wmTXLboPQw8OftKtOm2y2qdG/z++qy9pf6vmEpPy7cgYvOPoiy9HYuJXlaIZEEo2YdB+ybA7Q5FxhgNkZySTTSAlJOwBZnNhTfOc21hC8SglLx9YCmXhqcB1FRqR6USqhGUEomuVJsZkpJL6mlS5dqAalevXphxowZWjnfvHnz0L9//9DsJVGEMErwJA3XXXa2/mJ02Bzpmpacj/7tllSc3r698rIHIiKiSLdH/5Jf9NCrTwzx5TmevT+K/fSUEslNgCbHmqf7Pw80YukeEdWgp5TNNWOpwrL7gfWvAH/eqgYyHFqqAkUycEEypXzR+0o9dPdBPPqol8tzV6qAlNjyIeyrn/R+O0Y/KRniYDwnGgGp1mcD5zmBztd57+9Ux9QoKJUexsbvFFmZUqJDhw543b0WiSgGGIEka8PC0aOBH3/UJ/PJC5qMvbbZUZg+Aim5P2FEt1+weOMAbduCAs/bIiIiimbu3Rvs5bmeY7sr6yklej8K/HET0GEy0OmqUOwqEcVYptTXX7tdWJYPbHjDPL3nZ6C8UK1LD6W4RN83bASQSswJfC7cJurZVz8Ne+J/Pbcz+kmlZAOJbqPljOC8BMfW/kcrQkQTvby5DqpyUKpgpwoiCgalYjdTatq0afhBCmfdyHnff/99sPaLKCIZgaRk9fypmTZNTdJrd+gW4Et9bHVqa6S0Ui8gZ45fV7Ftfr55vUL99c+dNEokIiKKZMaI8zFj1Lju5vrLn7CV5Zkn8jerLOLKyveMvlLjFzEgRUQ1Ys2UatnS7UIpKZYvkK3ZTbumq/VmY/zfcGVBqaK9+u2MBpKzYCs7jEyHWUHhPSilGqhXkPNE9onAMe8Aw78C0mqpfC8Sg1K7f1TLjJ7m5EKKelX++HvnnXeivNxS769zOp3aZUR1mRFIsgalpI5cm6Sx+hnzTKkPT1WvgplJu7wGpZgpRURE0Spez7V//nm4NPytyEQwyAQ+mSpVvN9/o3MioiCV71kzpYwAeoV8t/HX+2YD+35X6y0m+L9xvXyvIvPTXbEelEpuBjRUbW3qO1yzpzSFuyzle26ZUslNzV+k/UVAy8o6tEe3u++tYlBKpiSKrJEhmwhIURCUWrduHbp7zGUEunbtivXrvUSCieqIkhJghT7ZOi3N/UK3xoQySSM5S1utF2c23sixtNlgUIqIiKJRWRlw6JBaz8hwDVJ5BKWMrIDC3Wo9xUtTRiKiEGVKeQal9PHXRoNx6U8kAxYa9APS2vu/YQk2CeP5zFemlASW6rXRVlOc+7xspwelkpsDCT6CUjGicZb/oFSiezWlMTyDTc5jOyiVkZGBjRs3epwvAal69eoFa7+IwubVV1Xm0xy9L6E38l9e+kiVlqrTHi9wRZYXJxkX2/6SiheVenF7Kw1KnXwysFrv2ec2RZaIiCiifPKJWkqWcJMmrkEpu60ccBS7lqFIU98iS2YAEVGILFtmZkrVS3WgkXtyZsFW76V63W6v/Mb1KggUesl+cg9KpaqxpClOPUvUZR/08r3UbCChfkwHpezxelAq0XtQqmK6ueGwHpSq3yXUu0aRHJSaNGkSbrzxRmzYsMElIHXLLbfgZPlkTRQFPv8caNECmD0buOoqNVXv4ot9b3/DDa6nPYJSJTnmm+0zc9UY6wT19XGSPc9rUMooBTzpJODtt1VPDiIioki3fLlannmmKmG3lu/VS7ZkSRmZCL+MNz+s6R/UiIhCQd5rG5lS7ds5XbM4rZlS6V3U+3Uh79lbnx54UMqtoXkF43kuSTKl9KCUo5JMKZvbx3H3zKk6zp7oP1PKZZBGeQlwRE+OYZPz2A5KPfnkk1pGlJTrtWvXTvvp1q0bGjVqhKeffjo0e0kUZGecAezcCZxuef3Js/Rldbd/f4BBKXkRsuvv0PVvPhLthyX/SVs3yh2smVLSiq2BpcchM6WIiCjSy9mtpXvWsvZ6SUZQygZk9vHMADB6shARhcCll5qZUk2bOjw3MHpKSXndsM+BVqcDQz8137/XJChV7JkpleqtfM/aU8pdjPVJikvwH5SSL+4rHNmgSi3j05h1W8e4x44DKt+bO3cuZs6cib/++gspKSno3bs3hg8fHpo9JAohawmdr2l43l4fKrKa5EVp3kVAnF66am1WGK+CUnG2MiQlFKO4NNlr+Z7RND3GXoOIiCjKg1LWXh/awA9rUCq+HtD2XGDD60B8KtBoEND5ulrYWyKKJS++CDx/mcq7yPIWlCrYZgaYpIfUsM8Cv/EUPShVtEdl7UiAZNf3QJNhQHIT1/I9vbdsivMAyp2W/XCUmdsZJc4xLC4xyW9QKkv+jHt+BQp3AHGpZpYbPzjFdlBK2Gw2jB07VvshimaHJYlJd8QyHdad3ZJT+O67ljfiS+8C9vxsXugSlDK7oddPPqwFpbxlSlkn+REREUVjUEqyfmfOBE4+wRKUanwMcEaOykDgBwgiCgNpcTx6tHrj3rKlW1BKAkJGNlNKi6rfeFIjwJ6k+uZJkGTRtSooldEDmLDcNSiVkg0n7LCjDOUSxErUS5dlXSoobHEqkCXang9sfh9ocy5ijZEplZRQApvNAadeeinatgVQehiYNcL1Sizdi82g1AsvvIArrrgCycnJ2ro/119/fbD2jSjspHTO2/tm63kusViZ2OGrDtwepyL65QVaUGr/4SYVQakPPjBLAo0Gfny/TkRE0RqUOv54YPNmoEViPvCzHpQSce6jk4iIQmvgoHhgBWCTTCYrCRpJ1pIEhJL0gFBVyJt1ybCSMrLcv1VASuSuBA4uMYc8yG3b41Xgq3AbbJKdld7atXRPMqmMflJHvwg0Gwtkj0esiU8yv51Pii9GUanZ2VwbQpWjjz63ajY6XLtHkRSUevbZZ3H++edrQSlZ95dBxaAURTMJGhklCN4yqnr31tNIhbyo5a1y3dCaKWX0lSovwBOPHsZZVwD5+WrK3vnnm5t4y5TyFRwjIiKKxKCUaCMT0HdZMqWIiGqDBJ2Es8xHg/Es9eVxdaS2UkGpzf9zPX/3j2alhJQsy93Xaw1b4TbgyHoAx7r1k7KU7iU2ANpfhFgUpzc6N0r4jKDUBRcA2fIn2urWv0teW1pwuFpMBqU2bdrkdZ0oGi1a5PuyPXs8g1Ll5cAqPfb05ZeWC/LWAmWWKUPeJmZofaX2oFdXFdVatw4YOdJ1E/aUIiKiuhCU0hivi0avRSKicDMCTu6ZUgU7a97LyWh2vuUj1/P3/GSW7umcDY4C9s9B/MJLgKyhQP0OeoBK6gylNo1SUuNR7rAjzu5AcmIRUKDOHzcOrkE8MeRDoNkoDsyI9el7paWl6NChA1YZn9CJooxkPA0c6PvyrfpADslmGjAA+P57YN8+9QZcgkatrZOspXmrO2+ZUvL6lWA2r9q923UTX5lSREREkegzvS9wQoKfoBQzpYiottj0vAuP8j0vWUrVDUoZpJ+U2D3TnMStczY6xtxu5hBg31z1o12ve/X3oQ5JTrGhqMRzAl9pqduE8w6XA23PMftwUewGpRISElBkHVdGFGUOHPB+vpG9dMstwLZtQLduwOLFwIQJwEf6FyFNmgDxRm7hvnnA6mc8byghw2tQKjnO0lHdTao+SIKZUkREFOmK9ZYpQnpIeShnUIqIIqR8TxqbW+Xr3z6nNA9eUEqCJVbWTKlm41GCemY/qzlnA9s+V6dbTqr+PtQh8vmnqNRPUKo0Vy0T3T5jUewGpcS1116LJ554AmVlbg9yoijgKwPJmK6XmQlccYXrZTfdpJY5eqBes+ltfcUGNB3hO1NKK98DknwEpfr3r9p+EhER1SbrFFnrBNsKzJQioojpKeWWKbVTb0xez1r6UMOgVLPjgbT2XoNS8uX0D6lvo3TcUnW6QPojOYHM3kDDo6q/D3VMQEEp9y/+KfZ6SlktWrQIs2bNwowZM9CrVy/Uk7mbFl988UUw948oZN/wtmgB7NgBXHSR+pk1C1i7VpXrefPKK5YTBxar5bDPgIN/AHt/8Vu+l2jL8xsME8yUIiKiaApKdfdWfcKgFBFFUvnesgeA7V8BQ94DDv2pzm91ZvCCUjJhr1474MhGz6CUJGvZEoD63SomcmuaDq/+/cdcUEr/DMWgVJ1W5aBUZmYmTj/99NDsDVGIWatPr74aOPtsNS1IekgJXwEpceml1hvSG0PVawMc2eQ6PcNLplSC7XClQSkrZkoREVEkOnjQXJ882csGDEoRUaQ0Opd+RCseVuvTeqtl/U5Aeqfq33ZKS9fgl7z3l88DBktPKXM7m8rOytM/cDAo5aLUoYJSKYmFFecNG6avlDBTKhZUOSj11ltvhWZPiMKcKXXDDUBamlpPT/d/va5d3SJGxXpzqsRGQILlysnNvGZKxTm8B6XiLNNomSlFRESR7k890WDs2Eqm7zEoRUS1Xb6X97fnZS1PrdltWxtty/1oASfLJD23TCmXDCsjKNXEiLiQsMWroFRSQjF27VKDpypanLCnVEwIuKeUw+HQekkde+yxGDBgAO68804UFprRTKJoypTq0sUMSAnrujfS5NzlDbdDj24lNVZpuwY57SVTylZ2GLff7nm7HTvqK4eWIXXFlWiWqaaCMFOKiIgikTGltoc+cMoDg1JEFCnle1oPJ5jPSQ2OAnreU8Pbtnx8Nj4PpAUQlOp4lVpmjQJS3L7EjnEpaUnaMim+GM2auU1KZ0+pmBBwUOrRRx/F3XffjbS0NLRo0QLPP/+81vScKBozpZJVQL6CW2s0D4sWWU6U6FlS9kT1Atd8DNB8PNDpasDulnyYkqWW619F+0ae39Y89pi+8n0fJG17DTef4GWiHxERUYTIzTUHg1SQD367Z6l1foAgokjJlDI0PwE48zAwfpFrhUN1tb9ELbvdppbW8j1fQanWpwMnLFX9aMlFy9bqg9lTj1v6rBj4mhITAi7fe/fdd/HSSy/hyiuv1E7/+OOPOPHEE/HGG2/A7qsxDlGEZkolqYB8BffT99yjsqfuukudvu46y4XF+/UrNVYpu9LAcKQ+zcNdmpEKBZyWdRauwoqK08uWAdnZkhblqDjvtpOexpDOc+EsmwUkuEXOiIiIapkxibYiKCUj12eNAg6vBUZM4wcIIoq8oJSUfml9MoLUK+Oo54Bm41SgSTTsrybqpXUAMnr6vl6DPsG5/zrGHq8+iHVqb+mzAv0zUtE+z7JJit2g1NatWzFhwoSK06NHj4bNZsPOnTvRsqXbFAKiCJWnD3Cor6rqvPZzkhjr/ferrKqvv1aN0J94wrKx0U8qqVHld9hkiLmasNJ7dlahKtkzHNt5Lkp3fQe050ABIiKKzEypDCPmtOcnFZASfz8JlB3xPo2WiCjc5XuGYAfJJcjV9hzztFROTPgruPcRS+L0L+LL3TKlig8CzjLfDeSpzgg4xamsrAzJbjVPCQkJKK2Y10gU+XbrQ/OkXtndiBGq8bhsI81bJXA1dy7w4YduU/KsmVKVkRepk1RTw3KndIQ1m0VV7MORDR5Xc+q9qIiIiCLJkSNuvRjz1pgX7v0VKNyp1pkpRUS1PX3PEIySPQode5Jrjy5D4Q7zM1ect8kaFHOZUk6nE5dccgmSLHVORUVFuOqqq1DP0pDniy++CP5eEgXJnj1qmaW3erKaMUOV97lnUXmwTt4LhD6RI85WgoZpB3HwSCPccguQmqpffmSj53XiK+m8TkREVImpU1W2b79+wbvNggK1rHjrd2ST5VIng1JEFHnle3w+is5MKeOL+7T24d8nisyg1MUXX+xx3gUXXBDs/SEKS9lBgwaelyUkqJ9KVSVTSsQlAYkNgZKDaJ65SwtKde9uudzlDb3idJQHdttERERerFwJnKpPPi8rU5nAwQxKVXyxcnid9w1ZvkdEdbV8j4JLPiuJcrdMqcNGUKpD+PeJIjMo9dZbb4V2T4hqo+ygOor3VS0oJVKaVwSlVm7v6frhYNcPHpvbnAxKERFR9W3bZq6vXatK0z/6CHj66QAygv3Iz1dLM9t3nTnY48h6c0N+CCSiSGp0TpHLrmdKOdwzpfTXlPrm4CiK8aAUUV1gvJmuUVDKaEwugaZApbQAcleiVSP1KSHeeOTlLAcOLNBWHSltYS/crK0zU4qIiIKRGSys2bmLFgF//BGk8j2ZvGeUoDcbDaw3glI2IIG9EYmoljBTKnozpf68HYhLBXo/CORvdWmFQnVXwI3OiepSppSlDVp4glJ6LXS7Jptcg1Lr3zBv9phpKChOUSeYKUVERDWwX680d/fnn0Es3zv4B+AoBRIygcaDzY2SswAb32ISUS2xu/XjYFAqOnpKSTn4qqeAFQ8BB5cABdvV+amtanX3KPT4joFixr59wE8/1VKmlB6U6pClaqMryveK9M7rna+Hs343rNrZTTvpZFCKiIhq4IA+kyOYHA41EKQiKLV7pjqRNQKo18bcMLVl8O+ciChQdrdJbSzfi47pewV6ZpSQLKmKoBRfU+o6BqUoJkg/jaZNzdMZ1X1tcjqBot3VDkq1b7rRNVOq5KBaNhoAmw0od+jRKgaliIgoREGp0tLq3WZhobmuglI/qhPNxwL1LN9k8wMEEUVCOZghIb229oSqkilVsMM8T0rDS3PUOl9T6jwGpSgmfPaZ62lrgKpKJIjkKDHLEwJVX02NaN9EBaWSktyCUjKdD5agFHtKERFREMr3evb0vGziRGDNmqqXv/fubZ5OSXYCh5aqE42HqN6JBukHQkQUKZlSLN+LjqCUMUxKbHjD/IzEHoV1HoNSVOf99hvw4IOu5zVpUsPSvcQG5hNoFTKlmmbsQ1ryYTMoVWwEpRpomVIOp/6QdDqquYNERERmptQttwCbNwPXXmte9sMPwKWX+r9+ebnrBL8ZM4CNek9zux2wF+9Q32LLlKv0rq6ZCSyVIaKICkoxUyoqyves8larZbuLw747FGNBqd9++w0TJ05EdnY2bDYbpk6d6nL5JZdcop1v/Rk/frzLNgcPHsT555+P9PR0ZGZmYvLkyThidLPWLVu2DMOGDUNycjJatWqFJ598Miy/H9U+KVE47jjPUoWGKjEpPP2kREI6HHb1zXGT+vuQnOyWKZXkminFnlJERFQTy5erZaNGQJs2wH/+A7S0VEAsWeL/+tdfD7RuDfyoV+itXOnaWwq5q9SJ+p3NgFTn64F67YCe9wX3lyEiqm5QSjI33RufU2Tx90V/k2PDuScUi0Gp/Px89OnTB1OmTPG5jQShdu3aVfHz4YcfulwuAamVK1di5syZ+Pbbb7VA1xVXXFFxeV5eHsaOHYs2bdpgyZIleOqpp/Dggw/itddeC+nvRpFhqV5ZYCXf9kpWUo2CUslVDErJm/h4FXhqVP+AypSSUdql+szuxIYuPaVsDEoREVE1TZsG7Nyp1hs3Ns9PT3cLLHnx3HPAaacBL72kTj//PLBiBXD//W4bFu1Vy5Rs87yjnwcmbaz6FzdERMHEzM3o7gFmZR2iQXWW0W65Vpxwwgnajz9JSUlo1qyZ18tWrVqF6dOnY9GiRTj66KO181588UVMmDABTz/9tJaB9f7776OkpARvvvkmEhMT0aNHDyxduhTPPPOMS/CK6qaLLnI9PXs2MHRoDW6wOk3OdY6ERkDJdjSsd1AFpUr05n0iMRMotmRKsacUERFV0113ee+haA1KlZV5v+5NN7mellK9uXO9bFisN61KalSjfSUiCmmmFEv3Ip+/PoQZPcK5JxSLQalA/PLLL2jatCkaNGiA448/Hv/617/QSHLRAcybN08r2TMCUmL06NGw2+1YsGABTj31VG2b4cOHawEpw7hx4/DEE0/g0KFD2u26Ky4u1n6s2VaitLRU+4lmxv5H++9hdfCgvImOw1VXOTB4sNPlsu3b5b+4mRY1aJAcw2reUckhJCy9Q1stT86Go4o35ExoUJEpZbeXorRgDySZ2BmfjrJy+YBQWhGUKi8rrvExqovHmrzjsY4dPNaxpbrHe9kys1SlRQvzda9587iKJPm4OCdKS8tw6JB8gROH00934MgReb3UB27oCgsdiItzuLxlvPLKcpQX7tW2LE9oUOXXQ/LEx3bs4LEOg3Kb9h5bOO0pKKulvzWPdWBsSHQJSpQNfBu2wu1wprSE0xlf/ZGxYcbj7SnQv0VEB6WkdO+0005Du3btsGHDBtx9991aZpUEmuLi4rB7924tYGUVHx+Phg0bapcJWcr1rbKysiou8xaUeuyxx/DQQw95nD9jxgykajOQo5+UO9YVU6b0wcyZbfHhh3ZMnfqVy2XJyWNw5Ig6ZjffvBjTpllGjVq0LPsVaY7tWJNwDpzStNWLjiVfwojV/7YlG3nbplVpP/vll6C19LOqdxC//fYL9jf9E8Nl+ml5Mn6cNg0lJXbU04NSK5Yvw56NVbv9WDjW5B+PdezgsY4tVT/ekyrWfvjBfC2x27tJ4yd93YFp06Zh1qxW+OGHo/DDD947OuzceRArV26W2ryK84YNm46t6/6EvLtav/UgVu8OzusV8bEdS3isQyfOWYyT9PVDeYWYLTXNtYjH2r8G5Wu1z0SGhX9twr74furEyuh7feHxNhUUFCDqg1LnnHNOxXqvXr3Qu3dvdOjQQcueGjVqVMju96677sLNN9/skiklDdKlN5U0VI/2aKU8UMaMGYOEhLrR9O+FF8wgkpRuWuXmqv/iy5eXokuXPgDkx03RbiR8c4q22uGoiXC2Nv/fWcX9/jqwCyjvfh+G9rimyvvpWPAtsHUuGqYdxMiRI9AhpRD4HUjNaIEJYyZAkvN+XqB6nfXs0Q39u7v+LlVVF481ecdjHTt4rGNLdY639UvJdu2cLq+Lc+aYgafS0jgMGjQBy5f7by+aktIQXbtmVpw+6ywHzjprLOLmvwNsAzr2OAbtO9Xs9Yr42I4lPNZh4HQCn6nVzAYNMeH42nmO4rEOUG4rYIZ5csCwE4AGRyHa8Hh7MirOojoo5a59+/Zo3Lgx1q9frwWlpNfU3r16o01dWVmZNpHP6EMlyz179rhsY5z21atK+ljJjzv5z1VX/oPVhd9F+mGsWycRWPO8kpIE1Kun1q+5xnxz3qaN/L5uN3DwD9Wo1WGWasYfXAB0uND7HR5Wo0njmh+PuGr87Zz1VLfZ7EYH0L59AuK3qwepLbmRdiyk6axRvic9PIJ1fOrCsabA8FjHDh7r2FKV4219W/Sf/9hcrnfsscBTT5mXv/pqAnZ4TyCucOSIHYWF9oqm6W+9ZUdCgh0oPaSdF5fStFqvieQdH9uxg8c6POxwwl7Lf2ce60okuTajT6jXTP5oiFY83qZA/w61On2vqrZv344DBw6geXPVZHrw4MHIycnRpuoZfvrpJzgcDgwaNKhiG5nIZ61nlAhmly5dvJbuUeAk8Nm7N3DZZbVz/9KMtXt3YP588zzZH+NQv/yyeX79+m5XLtoHzBgM/HICsNxSqnnoT+935igF8rfoN9apWvsrwSdx+UUH1fNsyUF1QaKaysfpe0REVFN69wLtNcUteRgnn+z62lheLu+b/N/egQMyLVmtT5oEVHQxYKNzIiIKhni39jhJlrGxFBNqNSh15MgRbRKe/IhNmzZp61u3btUuu+222zB//nxs3rwZs2bNwqRJk9CxY0etUbno1q2b1nfq8ssvx8KFCzFnzhxcd911WtmfTN4T5513ntbkfPLkyVi5ciU+/vhjPP/88y7leVQ9H30kZXHyrWnt9J/7z388z9u4Efj5Z5W169e+OYCjxDMQlbPc+5XztwLOMiAuufqjrvXgU1zZAXW62DUoJTh9j4iIghGU6qe347CSQNVVVwEZ+pfShw8DGzZUPkxEthNpaZYLivXXskQGpYgoAsl7dtH6jNreE6qMexDK3zQ+qpNqNSi1ePFi9OvXT/sREiiS9fvvv19rZL5s2TKcfPLJ6Ny5sxZU6t+/P2bPnu1SWvf++++ja9euWjmf9E0YOnQoXntN9eURGRkZWoNyCXjJ9W+55Rbt9q+44opa+Z3rCimdu/JK8/SNN6qfSoNBQbJype/LpDeTtaSvbVsvGx3Z6P3KZYdVSZ+7w+vVMq0DYKvmw8YIPhkZUkV7XJ6IrZlSYKYUERFV0a5dwEl6d199potXUt4urJnGhhdfVIEt44sfyaZ6/HE/QSlmShFRJBo7DzjqGaDLjbW9J1QZewKQqff9lc9Z8qGIYkqt9pQaMWIEnH6iGD/88EOltyGT9j744AO/20iDdAlmUfC4v5F96SW17NIFuPrq0N//H3/4vuz551VpoeG337xsVLDN9XRGd6AkFyjcAeRvAlLc3s0f0b9Krt+x+jttvHGXoJS8mV//ijqdriYhCQaliIiouqwzYEaM8L3d0KFquWCB52UXX6xK3q+9FrjuOtfLjJ6NKCsEyvVvf1hmQUSRqEFf9UPR4ah/A3/cBHS7o7b3hGpBVPWUoshRVOT/29dQkx4XvsyaBVxwgVqXEoVWrbxsVLBVLRsOABoPBga/B9Rro1+23dyuXP9Fc1eoZX0zgFTtTCkJSC2+3jy/qRqCykwpIiKqrsJCYNUq8/Rtt/neVu9wUJHdHBcHbNmiTlt7MB53nOv1KjKlSvQXYVs8kBDdU4mJiCgCNBsFTFgGtDu/tveEakFUTd+jyCE9JnyRVH95gxsK+/cDt94KvPNOYNun+3qvnK9nSvW8B2g5Sa2ntjSzqPbNBf68Fdg/D+hyE7Bf/zq50YAgZEodAvbonWXbXmAGw5gpRURE1bRV/67F4K/6oaHZyrDidbt1a8/tvvoKyMz0EpSqKN1ryDILIiIiqhFmSlHQM5WMJquhIH2sAg1IeXvj7ZEplWpJozLWpX/Uz+NVQEqseRY4pNcLNlJTHasl0Zj26ASK9D9Sz3srLtYypZwMShER1TU5OcALL/h/7Qxm6Z6l9aZXjRtX74sdj6AUm5wTERFRDTEoRQGZPh0w2nJJiYC/Mr1Dh0K3H/qgRg/SkFVGVbtr7m1QXnmx2WQ81fLVsJEptfkD1fDcXXIz1yBWVcUlAfZE1/NS9BoKncOhPySdjurfDxERRRSZeHfDDcBNN4XuPnbsCKzvokgNcLCRexJURU8po3yP/aSIiIiohhiUokrt2QOccAIwfLgETbxP67H6/PPQ7UuyPt3V3ejRwNSpnue3aOFlY6NnlIyKtU4NMgJOpTlq2fQ4oPl48/LGg2pephCf5rqeYDbvcOkp5WCmFBFRXfHxx2r53nuhvy/JburevfLtLrrIXL/llsBu27N8j5lSREREVDMMSlGl9u0z1w8fBjZv9v9t64MPul4nHA3WO3RQy0S3RKS+ff1M3pMsKWuQyT0LqvO1KjBlsK5XlyUIhRTXNC6XoBQYlCIiosCUlprrP/4Y2HWsvaL8BbHGjPFSFli8Xz+DQSkiIiKqGQalqEpvdqXB+bffmqeffNL7dfLyQtfo3OqKK4BPPgHi9Zb9CxcCJ55YWaaUXuOQ6nZhZi9zipBkUTUbC2QZM7VtQMtTav4LWDOljHJBC2ZKERHVLcuWmeuhGgIiXxgZ+vSpelAqJcX3dt98Y67bjXeN7ClFREREQcLpe1SlN7sS8DFGTv/8syrn88YYMx1MJSVmsKtnT+Cee4BzznHdRt6Mv/gi8N136rR1tHWFim94m7qeH58CHPcdsOIRoP0lQGKGamw+7Asgvh6Q1q7mv0S8ZYfS9PQub43OmSlFRFQnTJjgpSdTkBm9HCW45J4xHEhQyldpvJEd9X//B6xdCxx9tHv5HntKERERUc0wKEVVCkoZASnRo4frm1r3AFKwGVOL5JtaaXju6xvnip4Xvpq5VgSlvLyZbjoUOP4H10hRq1MRNAlpPoNSgplSRER1R3m5awPyULw2im16VXqrKszisL5+W183vbnrLrczKhqdM1OKiIiIaoble1SloJRVo0ZAQoLnyOjqvvGuLLvqp5/UUrKz/JVAWLOjvPYl9xeUCjWXTKn2voNSTgaliIiimXyRYpSWW/siBiuTWAJRP+jfoWzapJatLQNlK9Owobner18V75w9pYiIiChImClFFXbvBoqLgTZtAgtKGb0lFi9WfaZWrADefLPqQSnpWWWUG0gGlK9+GBdcENjtVTRidXvTXaF4Xy0GpSxfR6d39biYQSkiorrh7be9ny+vs/7K5QI1cKB63Z45E1iwwMxgDpRMrb34YmDkSKBxVV8O2VOKiIiIgoRBKdLIN7ft2wOFhaqZeYMGnkGp8eOBvXuBP/4ATrH0/O7UCbjpJuDIkeoFpebPN9dfeAH4739r9rtIdtS77wJ79gBdukRYplR5vrme3tnjYgeDUkREdcJzz5nrgwcD8+apdXmdrWlQSjKGJSBl3I/RR3Hs2MBvQ/pb+QqcVYo9pYiIiChIWL5HFWUG8kZZSIDJSoJNRlnAkiXA338DH37oeRvSk0IakFc1KGXNxPJXenDyyWp53XWV3+aFFwK33urjQiMoldwEYZeQYZbxyYQ/N8yUIiKqG7ZvN9clCGVkFxuvtcHoISWMgJQYNQqh5ygDSnPUOsv3iIiIqIYYlCKPN8/vvANs3Wqe/uor115N3br5/pbXKMPzFZSSb3RPOMF8Uz53rproZ/AXzDKuIyULNVKbmVK9HgDaXQQMec/rxRXT9xiUIiKqM1q2VJPxfAWlpIz9ySdVpu+gQarEz585czzPe/xx1/L1kCk5aK4nWtKqiYiIiKqBQSnS7NfjNAYZ/WzYuVMtAyk3qCwoJVlY06cDH3+sTh97rOvlMnb6lVfM8dYGuY70zQhkSlCldYq1GZSq1wYY/A7QcpLXi8OdKSXByIkTgSlTwnJ3REQxwRpU6tBBBZyM10d5vZ01S03mM3z+OXDHHWp94ULzy6BAyt7F5Mnm9V2UFwOLrgEWXgnkWsbn1oRRupeQCdjZBYKIiIhqhkEp0tx8s+vpVfp71++/N/tWnHtu5bdjvOmePdvzMuu3w9IPw5errways9U3x0Z5n2RXGWoUlCo5ZAZ8IrDswGFkSiE8QamXX1ZN6qUk8tFHgS1bwnK3RER1mvQ1NEybBjRrZn7Zcswxqsn4NdeoPo0DBni+vu7YoQZ/3HefHcXFnuNm8/JcT0vgy6utnwHrXgbWvwbMGgHkrAByltfsl6voJxV5r6FEREQUffgVF2mWu71Hlb5RM2YAEya4NjQPpDeVtzfM7tlYcZ7vsT3GZss0v8xMz/u1NmGvsoKtZpaUl55Ota0iU8oRnqCUNLU33HuvCkzJByjpVyLfxD//vOdIcyIi8m/zZnNdhoh489pr6rVQJti6y80F+vWTtThce20LnHqq/6m4jXzFhw79aa4X7QWm9VLro38Dmg5DtZSwyTkREREFDzOlSKtoc2cEpQzyza6RBeWP8W2vkeVkVVDg+oa7MtJv6rTTXEscRMOGqL4jm8wyughUMX0vTJlS+ZZhgEY2m4wHv+gi4KWXgPfecy1HkYw16VtCRES+GSXw993nP7Av2apW//iHmSllWL8+02UbmYD7xRdmWX3TpuYgEA9H1qtlS7eo1q4fUG3MlCIiIqIgYlCKvDZd/e03s4TPaH4eCKPJalmZ/wDIDTeYPaLEjz8C//636/ZSUiblC+6qnSlVXgT8qY/ky9S/LY4wDqf+kHT6qW8MYVDK3WWXmetS5ie9ve66y3M76SFmnQZFRBTLPvvMe0aTPxs2mJnBRtBJrF/fwOW5tn9/8zKZhLtnjyoP9OqwHpTqeCXQ+Z/m+XmrUW1GX8ZEBqWIiIio5hiUIpc3za+/bq5LGZeQbJnOnQO7rYQE35lS7sGMsWPVMitLjbFWpQr+Sd+MjAxUz5zzgCMb1XrrcxCJjOl7tjA1Oq8sKGX9xl6mQhncG9GfdBLQujWwZEmQd5CIKMocOWKuWweEWANN7qRUXcr85PXQvbR627a0ioxmawaVdSquV3Il4zWvfgfg6BeA4751DVZVR9EetUxuWv3bICIiItIxKBWDCgvjXd7YGm+gU1NV6UB6uuv2Pr+BrWJQyloOaGWUBVYWbLLbgZUr1bJa5QY7vlHrA18FsschEoVr+p4Elfr2BX7QKzg+/dT3tjLVyb05/a5dqpm9BAm/+87MenMvRSEiihZffw0cfzyw2k8SUU4OsHUr8MADKkPJWz/Etm3N09aJeKec4vt2ZaiIkKbn7kpK4iuCVFUKSsnrXrmeCp3aSr9CR7Osz1vtfiAKtrveJhEREVENMCgVg267bTjatUvQyq3kDXZH/T2qEYyaNMl1+3r1ghOU8sUo+5JMG38kKGKUB1aJvPFe/jDgLAMa9AU6XoFIVTF9L8RBKQke/fWX6zH2dZxlOpT8Ca3ZUfIBadw4YONGlSVl+O9/Q7jTRERVIGXk99wDzJoV2PZSMv7zz67lcQZ5DpRsUSkfb9MGePhh4NJLvQeXjIEfkmEsGVAGuf4557i+pt1+O/DEE6pvo7cvgZo2dVa8Tkpfvw8+qEJQyhjskdwMiNNfPOu1BWx2oCzfzHiqiv0Lga2fqPW0dlW/PhEREZEbBqVi0Pbt6l3s1KnAkCHm+cabYfeMpVAHpSqbHpSWppYnnojq2fBfYO0Lar2r3lMqQoUrU0r6krj/jZctA77Rk8msuncHTj8duOIK16CUt15kwr0xPRFRbXjlFeD//g8YPbpqX5BYh3IYdu/2HoCSXojW5zxrZpTR7NzqxhvVUoZGSJBKAlISmDJYg1hS4t6ypQpKbdli00oB3bNRjddHr/L1oFQ9yzc+EpyK1yNZXzYHyt1eDCqz+X/metPhVbsuERERkRcMSsUYazBC3mRbm5kb39S6T7eTsr5gBKWMkgYJft15p2tTdfeeRe5lfzLx7c03UT07vlbL1mcDbc9DJKvIlEJoG52npHgGHqWfiTXryfD++8CXX7qeZ+134u2D4KJFQdpRIqJq+uknc72ySjV/l8vr5u+/e7/s1ltVs3HDunXm+r33em4/aBCwaZPnc6rBWp7+1FNAixZq/dtvvb9d8xuUMvpJpbqlIWcdb67v8ZFGVnoEKHCrFRQ5eoptv6eBRNepgERERETVwaBUjLGWYLk3pTYyomQyXiiCUkZDdZm099hj6kOA/Awb5rmttZSvXTv17bOMva4yuYMDC9R6l+t9R74ihMNhTN8LbbqRezaTNRuuSRO1bNnS9/UffNB/CYxkJnibwEhEFC7Wnk9GSZ0v+/WBcu6BoS1bVNn4WWf5vu6FF6rlerfe4ffd5317+YLGXym6fFkkAbXevc3XvXfecX27NmECcO65rplVPgNImT1dz+//rLm+c7rn9Yr2A9/3Bb7pCMw5F1jxL/MF+5B+m80CTD8jIiIiqkR8ZRtQ3bJtmxmUMZpcuwcqJFNKAhLbt1c9KBUf7z0oJb0zjICYeyaWNxIkeeEFFciqSqN1rz01ivYCtnigQQDj/SIkUyrU0/f27fMdlJozR/WGkmDgVVd5v758UJMPS9Jvypu8PNWQV3qvEFFk++or4O231eM+kOfnaCBle3PnmqelOXnjxr63l+EN7mQIiLVpeWWlf506madlEIQxxKOqunZVP9aeUlaffw6cdloAN3TwD7VscJTr+fXaAMe8Bcy/FMhdrs7LWwesfhpoewGwexZwZIM6f8tHapl9ApDYCCjNBewJQHq36v1yRERERG4YlIoxQ4b4PuQSSPCWUeW3kWqAmVK5ueb0NmkUWxkJhP3zn4HfL/b8DKx5ARjwMpBiiWIdWqqWmb2AeLeatRjuKWX0TvFWzicfrKRcUiZR1YR8mJs/X5WrEFHkMqbCZWWp8ttoJ6V20uDcPZB+lFtsxsqYQivktUoCdPL3CJRMIbU69lgEhXuG8IsvBhiQKisE8vT6/IZefnF5TRQ5K9RyxcOqX9T614AEtxG84sBCICVbrad3B+KqGXEjIiIicsOgVAxxb27tzpotk59vrscZbY5qEJQyyhrkDbY0a61MVbKzNLP0Hhn2RGDox+b5efps74zuiAaOiora0PaUMrLgmjcHJk703mS+sm/5fWVJWUmfMinXlPuRhulEFLnkeVpeJ6qb4RMp3CfICpkU6o/1NU/84x+V348MCzECeldf7XpZsCrFGzd2zZQKOHM4Z7n6ciO5qRlMsjIynYr3AcUHgIOWev7SPMCeBDiKzfMOLAbqd3QNaBEREREFAXtKxRD3HlKG559Xk4Duvts8r5v+frVVq6rdh6+glDR2FV26+L++8UHgoYeqcKfyBtpw6E/Xy4ygVP1K7jhCOMKUKWUEpaRs59VXg3ObUm7pjfSXkimP1kw8IgodCcD4G0bgy6xZqnH2e+8haknbI2+/uzQk9xeYsmZK+bJypWfwy9sXKDJRL1jcp98GHJQ6ZCnd8xYhi08FkvVUsPwtKjhlNfhdoKOlfvvgIrPxuXWaHxEREVENMSgVQ6Z76WcqpExu2jTXN7vSs0KaqLr3nfIaENr6GVCS4xKUcm9ybYzY9jspCMBrr6kMnJEjEbi9+vg+UbgTcFjuPNfIlNIbdES48jD0lJJjY/RP8dfMvLJpVYa33lIBTckUkCwLCX5apzoa5Zvz5tVgp4koIMuWAR06qJ5E1QlMyRcKF12EqGUNfl9wgSrbM8jfxT0jytv1fJFsz8mT1fozz6ile1Dq2WeB229H0IwdW81MqYp+Un56KUpvKZG3FijWO71L6V6ToUDLU4CBLwOn6N9g5K4Ejugpz8nNq/hbEBEREfnGoFQMkYlp8+aV4d57XaMD3r5ElUypDz4wM6Z8WnQt8PuZwOLr/WZKFRZ69i7yRvbFmP4WkD2/AKstk4TK8oGtn5pRlcNroitTymlM33MEtSTn2muB555Tx0UCUtIzRZrS+5to6C0oZTSyd8+EevRRdZkcf+nbYjTptbr55hr+IkRUKXk8GsMMnnqq8u29TUqtqqIiFXgOJxnMIX2c3KfqyYAFIVPpJONLJrnK859B+uV5c+ON3s//5Rd12bffml+crF1rbu8+ydRfoL86pJTy4YfnVJwOOHvZyJTy1k/KPSi1X39PICV7Z+QAo381e0altgBSmqvXpF36t1RymoiIiChIGJSKIRLw6d/fiaOP3ot33lHZRBdfXIMbdJSrxqhi83tBCUpViZQczBoJ7PnJtc/Fer1Tr5QjlEjHdhtQ3zIWKQqm7wHBy5QaMyYeL70E3HSTCkwa/b2ys/33C3MPSv38syr1dOdrJLl7zylvWXJ//63KatbosUMiCt5kTV8BGKscleTqwTrswkqyIeW55Dc9QfXjj9XzukzrDKQELhjk9eT++4GTTgLGjfMelGrRwjzvzDPN9X/9Sy0lm6lXLxVMk+ch97+DTOuTMufjjlPZTyeeqM6329UwCOPLHPe/kzyvBluvXvtx333lWkZzUlIAVyjYbpayNxoYQFBKH1OY2lL9Yja3t4bu0/u89agiIiIiqiY2Oo9R55zjRN++lfd48itnmevp0sOIj6/vNShllO8FNSi1d7br6SHvA9N6A/t+B45sAgr0EXP12kbF5L1QTd/bscNMhfvkE7MvykA/n1WE+9Q8KX2RD2jWrAN/JZmS8bZ7tyoFletYP/T9+qsqLTKmSP3736p8piqTHomocu+/D5x/vu/LjSC1O5mcKb0G3UkgRzKFJPNSHsPnnGMGZ/76K3hT57ztpwSvpRzvnXeAhQu990r0FpQ6+mjXbaQ80eibJVP2rKXt8ns3blz1foriP/9R/fOCTeJE993nQEJCgFNHVv6fymxqepz//k+pelDq4GL9tOWPZtWwP7DTMl6QmVJEREQURMyUilHyJrd37wC/da2sPMCw5yc0yXsDcfayiqDU0qXqjbrRxyOoQSkZUW1oc67KlGo6Qr0Z3/QekKen36RHR+mecDqDP32veXOnywc7aW5uBJn8kQ9mUvpikA9p8v9GPsCdfrrKOJAPcP7ISPVRo9S6BKiEZFOMGOE51txovk5E1SNZTO7lY9JXScp1fXnySe/nL1hgZkxKEEieOySYIwEpg2RJWYWqhO/rr1V2kmRGSYDbCEgZrCV0xvOINSglzcKtfZ6sjdxfftn80sToG1XZc6OVZFGJL7/0DNjXCmlGvuG/ar1XJRNDjEwpQ4qvoJR7plSgja2IiIiIKsdMKao+o5Gq4bdTIG9pb5lwAE9+e4f2zXk/vcdqmzahCErpn5q63gL0eVSttz0f2PsLsPwB1axV1O+MaGFkSgWz0bm36VAikKwkCUxJGYuVlMu4l8xUFpgSkgklZTcSqPTGvTk+EVXe1FyCvNL/b8oUIDlZ9XdyJ9ukp3u/DaPk2t2cOWYm0eWXe99GMqOsjAEKwVbZwA3poyXlxdZMKffgnAzu8BaAk9/fGrSrbBiHu+uvBy65xHcZc9ht+xJwlACNBwNZx1UtKOUrU8pavheXCsQlB2FHiYiIiBRmSlHwglK6Uwd8qS3lW22DMQGpSk3M/d73EjNTqtPVQJye8tXiJMCmx1qljE/U74hoUdFTKkhBqfz8eGzYYKt2UMpfhkWgMjLMjLxNm3xnRB0+XPP7IooVksHUp48ql5OAlPAWkKpsspyRZSR9oqx+/FEFs6SPkb+gWDiCUpX1qpJm5MZrjLfyPX/BJsngNJrD+xr84Y/0mIqYgJTIXa6WWcdXvq1HUMpHzaL0mjKUW9LKiIiIiIKAQSmqHkcZkKN/Td7yVJeLstL3aMu5eu9Uf32KqmXdy8B0vUlIchaQ1t61rGDgq67bp1WhFiNipu8FJyj173+7NVOpYlCqqh/QfN1Gz55qXUr/ftdjhe7kw/Wdd6oSJCLyz1cAyl9QSoLMs2e7BoD3qKdrtLc8jRokIOUvIOSe9bhuHULCKP/u6Of7BSMY5SsoJSV83khGr3H7l12G6JejB6Uy9CddfxIzgIQM30Eq65N4uj6Kt9XpwdhLIiIiogoMSlH1HFoKlBcC8WlA87EuF7Vruhlpyd7TXoIyLnv1c+Z6v6c8IycdLgPaXmietgatoiRTyhaEnlLz59vwxx967ZwXDRpUfhsy/lzKfqSpcU0Y5X633GJmdXjzxBPAzTfX7L6IYoGvqXneGL2e3n4bGD4cOOWUwIJSZ58NzJzpeb6RGWT0YjIaor/7LnDPPUDXrsCMGQgaI2jU3K2/tgS4jSbm0nTdX1BKSpF9Wb3afylj0Cx/BFh6l+do02CR2839W61ndA/sOtZAVKqfpujDPgO63Qb0eayGO0lERETkikEpqp5tn6tl83FeM5GGdXGbjKdrVtP+qOUlwJENan3ieqCdJfhk1foMMyAVReV7wZy+N3u2GayTBsXuApkuJR/45MPeDTfUbF+MZueB8Be0IqLAmopLSZth507gjDOAyZPV6Z9+8gxKtWtnnjdxou/blcbgEya4nvfII+b6//2fmpIngehAy39lu0WLfGd/GUEpKVc03H+/yq40guuS8SQDNozfxz0oJQGnu+7yH5SKjw9xA/Ll9wN/Pw4c+jM091G0FyiV/xg2oH6nwK6TZInW+ZvUJ0Gufk8C6QHeLhEREVGAGJSi6tmjf6ppOQloNFC9Yc3oibKm6ivzjs3Wu0wzevhh4Pnng9DovGCbCthIo1V/GVAtTwbGzAVG/wbYo6efv9N4SFYhKLVihQo6bdzoer58SBOtWzu16VnujObzlYkLcAq5P8cf7zsLwdv5+/f7vz0JlLHMj2JZbq4ZdO7RQ01TtRo8WE3JFL/+Cnyuf49gkLI8GTxglPJlZwPz5qlg1jHH+L7fq65yLf2VLxr69/e+rft0Pn8ZmQMHmsFzCbjJc8bjj6vTxj5ag2HGhDwja0ue7z791H9mlHXogwTcjd/DeO4MaVBq/zxzPWdFaO7j8Boz+yk+wBdbmVorEtKBxIah2S8iIiIiPxiUoqqVzf1+NnBkk/lNb5Nhqi/FiSuBE5cD9btoZ7dsaHazbt0auO8+NaWoxgp3mqOrK2t41GSw72lCEcrhqHr53qmnqhHnJ57oev7Bg+rvc9ll3m/LXzlLKEgWQ6CTtYxx9N5I1kejRqp5etu2riPqiWKtfK9vXxWY/ve/XS9PTAS6qKdjzJrleX2ZqGc0B5fHkpTpSjDquOOAkSO93+cFF6ilNSglgwwCydbyxygPlqDSgw+q3k4yTU8ym5YvB/btU5c3baoysaQE0Qi4Gb2ipJTQGgSTBuTempobJDNLvigJdgA+oKBUoY9pDzWVpwel0vUDH4hutwPd7wRGzgxOE0EiIiKiKmJQigJzeD3wx03A1k+Ar9sDjlIVGHJrjGpLa+kRlKpxdpS3oFSUBZtCOX1v/XrXEhSD0WOlof7l95gxZjaA+7bhIB82raT5+Ucfec+y8Dct7JtvzHX5UH3ttYHdv5QU/a23WyGqK+V7RqaQtwlwAwaopbf/9/LYGzbMvK41HuE+JfW004D//lf9uAeljKl2V17peR++Jm26s97fQw8BX3xhnn7jDbMkLytLBaok88sIRhlLyZSSoJXRC8sbYyKs0T/LmjkV8kyp3ZbIYEGIglKH9Qi9/uVQQFKzgb6PAY0HhmafiIiIiCrBoBQFZqeXueAtJnp8s2qv5xmUCqShdtUzpbJRF5UbQSkEHpSSLAd3CxcCU6eqh3fDhs6KXjBPPaU+KBoZFOEkPWBkzLxBPjjKj7dR7f6CUsXFVf/gO3++ar4sZU6bNlVlr4kiT3FxHA4dsrlkKlkzliTgJCSj0B+jTNa9lNd9IMXYsSp7SbKvhGRVGYzAjjy/SJmdZG19+23VglL++n5/8AFQVqbWjaCTlXH/Tz5p3q/srzfS52rOHJUlJZKTwxSUki91jGm1oQxKVSdTioiIiKiWRU+zHapdB/R38dI7Sqb7SE+njpd7bGZLVeORhh69G5MmqRKMe+8NcrPYOhyUcjpVIMnmDLx8T7IHtm5V69IoWD5oWT+UGZlS0oPl1ltRayR+KQ3PJUAkH5qvu853mY11ZH1lQanyAOJ31tKmxYtdmzoTRZN164B//GMMDh+O8xmUGjo0sKCUwb30V55DJGAlZX9Ll5oN0g3WTCkJ8hiPbwkwS+DXsG1bYPfvrz+cETiT38UIillZs52M8rzx473fluzjkCHm6bAFpbZ/7Xo6VEGp3FVqyaAUERERRRFmSlFgCvSoR4/7gLPygZM3Ag2P8twuQdWQ2MvyMHWqKiELagBAGp2LVLev8uuImmZKSWPgvXtdJ3M1ahSi8ePVNGgQ8OyzruVGHTsGHpSS5sxV/SBpLREMad8YoiCTIK48PozSuVtuicPhw0kepW/Wx5MRiJaAtb++Su7bW0kQ6KyzVA8n98eYUTInvE3YMybfSUmd++M10H5z7o9TX5NbjSwqg/SZk6btgXAPSgWyr9Wy5UO1bH9Z6IJS8oXNEb2Wu0G/4N8+ERERUYgwKEWByd9qjoyOTwVSVEaUB5ngI0rzqhYAOPQX8E0XYMnNlezHZn0/2qIuqk5PKWPKntGPRRofW3XujIgnpTfnnms2UjaCUvKBVxoYW8t8rCWAgQalrNsYvbaIosEppwAbNqjgkNixw7Vk2ihpkywiafov/eKMPn4SWLIGplq18t57yltQKtDHk7dsLGt5n78As69pmxJcN5qbG3wFmtynd7o//1Wl9DnQcsMqWfUMcHCxWu+oN94q3geUF9X8tuUJ8a97gWUPAutfU+c1ORZI4hQ9IiIiih4MSpGrg3+qKXtllq+MHeXmN7sSlPLHCEqVFwIOt6+w/dnwhmrSuuZZ4PAG39vl6+Oi3Bqs1xWOivK98oA/kxhTuAy7dpnrw4Ztd8lqiFQyQVB6x0jfJ2tPKflALh+q/9LbsXz9NTB7tut1pURIxtv7I2WNhmXLgrrrRCGTn282+d64UT3WpWG/lTXo1KmTZ7846S/30kuq59Pcud570FU1KGXtAeU+wc4oyTUCY/I7VMY9GCS9n9x7EUoGlDfuU1379EHA3DOlQhKw3viWWrY5F2g0AIhLce2PWBP7fgdWPgqseAhY8bA6r/M/a367RERERGHEoBS5NmOdMVhN2Vt8jXl+4Q7AWQbY4oFkHxlShgRLsxE9Wyoge38z13fP8L6NBMqK9sRGphQC6yklH/iM8pXBgz0vP/98vcdIlDB61Uh2hXyAlkl7EnB6/33zA7Y7+aB+9NHey4jkPAlwWftQrVwZqr0nCg4pI5Oea5L5aPW//0n/JZtHAMef1q2Bq68GrrrKbGDu3kOqJkGp887zvo0RDK8sKOWtn5T79D9/WbcSvLJO5JRJgdUNSrkH+GusrADI00cf9ntKNbUySs99lfBt/Rz4/SzX10RfDi5xPd1sNND6rJruNREREVFYMShFpm2fAw790/u2qYDRbDtX/xRfvxNgr6Qez54A2PVutGUBfEUuig8AOcvN07t8BKWMN/dJ0vE2mCP9Ike5I65KmVJG6Z6UsEhZ2+WW3vOdOjnRrJml9i2KglKS/XTssa4f0iW4ZJQwuZPskc16Zad7BpY0gJayJoP03CKKZBJ8mjJFTcu0+qeeBDNw4C5ce205Fizw3WvJHwniWDMGGzeu2vUnTFABLnl8uQ1gDSgoJY9VKdk94wzvmVveSgIluObLSSepYLOUAfbuHfCvofW+sjaI95WNVW3yuiavo8lNzeEc/oJSmz8Cfj8D2PopsOSmwKftiaTGwMBXfR8QIiIiogjF6XtkylttrpfmqEk+mT3UG2TR2Esqjjfx9dTX3+UBBkS2fCzfvZun9/ykSv/sbv89d05XywZH1eE33kac2HdQSqZdXXEF8Nxz5gdS6RMjU6j+9S/g9dfVeQ8+GHhfKhTtBQp3Aw2q8IkuBIxeNPPmeZbVWANL4rjjgF9/dS1bbN/ePC1Tw6TcT3zyiXn+jh0qg8rb1D+iSHDggP/LW7U6jGefbYyEhOp17Zenz169gLfeUo3PrY+bQMiUvU2b/PcM9BeUkul47mWI3jKYVq0CunVT6zfc4H+fundHtYLg0q9r+XLg3Xd9B72r7dCfnq9ZKT6CUtu/Ahb+w3LdP4CSXBlp6/v2D+t/xKOeAzpMBhLSgrv/RERERGHAj2XkWr5ntX+OKj/Yqn+ib39pYLcTl+o/U6pwF1Bk6WxrBL36Pa16UknZX55b2Zm8Of/7MbXe8GjUVRWZUhKks9bIWMhErL//BsaONbMdjP4r0vRYGh1v3QqceWaAU/fy1gHfdAa+7wPMPhMo9zOfPcSs2VHuH9KtDd1lgt8vv6gP1r760vTzMYBKbkf+fqEiGV3eSgmJAlXZFLj69YPzGL3kEuDOO6t3XWl27u+7AfeglASapf+UlNL6C0hZSY85eRqUHwm6h4JkZY0YAbz5ZvWyzvw6+IdaWifVGplSErCS5uSFe4ADi4DfTlGvmY2OAZL1HcldCdven5FVtsh/plTjYxiQIiIioqjFoBSZjmww+1IIeaO8f656oyxvpGWqTyBkOp+QgJa7vLXA1x2AbzqpiX4ygejAfHVZ9olAencza8sIysg2c883g1xd3Drb1smeUpI85qh0UpUxrc7aFFgaHcuUrYBt/h9QmqvWt30GzBwCrH7WZ1AslKRps7fsCwlKWfu9DByolo88Yp73p56UEAhrgCuYJHtEyoHce/YQVYW14bb0lZIyPav09NoLHAfKPSg1ZAhw442efZzctalLMywk20k06OcZlNryEbDwSmDmscACve666XHAyOlARg91etvniPt1PI4pfhQ2+ZLISr68MZqlp0fBiFUiIiKiSAxK/fbbb5g4cSKys7Nhs9kwdepUl8udTifuv/9+NG/eHCkpKRg9ejTWrVvnss3Bgwdx/vnnIz09HZmZmZg8eTKOuI3iWrZsGYYNG4bk5GS0atUKT0ozC3JVelhlMImWp5q9pPbo9VFNRwZeMifle8Jb+Z6U5slkPikPlIl7h/5SQaekJkB6FyBNryORRq+fpgOHlgKLrwd2fqfO7/UgkBLsr7Mjb/qexkdfKeu4dYO3Me8Bk7+xsNnN5rl/3KzKSfbNBRylCBf5L1bu5ddevBj4VE+oswajJk0yyxW9NUH3JZAx9dXx9ttqOV2vNCWqDiOQI+Vk998PtGsX/UGpQFlLbaOaPG8avRJdMqVaeX4ZlPMXYIsDjnkTSMxQr4Vi9TMqa1aeG43XQMPe383bq6M9FomIiCg21GpQKj8/H3369MEU6ejqhQSPXnjhBbzyyitYsGAB6tWrh3HjxqHIMt9dAlIrV67EzJkz8e2332qBriuk4Y4uLy8PY8eORZs2bbBkyRI89dRTePDBB/Haa6+F5XeMGtI/SkjZQJOh+nkrzTK6hv0Dvy1/5XvG9Dyx+QP1Zlw06KNPJmphXl52BJg5FNigRx1EuwtRl7lkSlkm8OXmShDXdxmL+/j0KjEa2Q96UwUHDbNPVd/iLzQfT+FmnexlBKUuvNC1OfGAAWq5ZEngZXNuceugYdkeBbN8LyXF++M72oJS1umX7s49Vz2vffQR8MwzZhZk1Mv9G3CUAAkZQD1LVDFDb5JlqK9nOXW9xfxSJr2rx83ZDlt6PsoXSL/q6ZhGVhURERNcKjwAAF3sSURBVBFRlKrVoNQJJ5yAf/3rXzhVRvi4kSyp5557Dvfeey8mTZqE3r17491338XOnTsrMqpWrVqF6dOn44033sCgQYMwdOhQvPjii/joo4+07cT777+PkpISvPnmm+jRowfOOeccXH/99XhG3v2S52S7jO7qW1r51lbKA4yx1PU7BH5b/sr3rEEp+YZYMnK0++3lWtpgMAJb8ib9pLXmm/aYKN8zU4bOPFM19p44UfWLClpQqqwQOLJRrTcfD0zaBPS21MQZwUNrKeX6N1Rj9DDwltTonhXWo4f68C69nIxm6GVl5uX33muu9+wZ2kypfftCc7sUWwr0p04jAC39m6wyMvxEeSIwKOWvXNbo43T22cBNAQycixqScWpkSVmzjOU1rJ5eo9jzfuDElcDp+4F+T5jbZI30uDlb/hbzxBZLOlnLk0Ow80REREThE7E9pTZt2oTdu3drJXuGjIwMLfg0Tx/NJUsp2Tv6aLPxtWxvt9u1zCpjm+HDhyMxMbFiG8m2WrNmDQ6FqrFMtH6rawSl4pKA+p3U6WL9U3ZaVYJSRvmel0wpmfBmvT0j6NSwn/eglEhpAYxfDKTr+1SHOa0PSUtQauZMtfzOrYKjuiPdKxyR5vZOVf4hY8vl2Ll/IJJv+43SzvmXAgsvB5be5XlbWoN61/LampKR7ccc43qeZI1ZyQf2/noi3+zZniVDxoh4eQow1rdYPt9Vh4y09zYh7dVXa3a7RN4ypYS1T1zDhpV0Qo+goJT0x5KAcWXbRQz5MqXY0tSrunZOU8vGQ1zPlzLp474Fjp4C9LxXTZlNauS6jWQ/6RlQjqyx6jwJShlfDuz6QS2zRgEdai+TlYiIiCgY3L5/jRwSkBJZ0vnYQk4bl8myqYwbs4iPj0fDhg1dtmnn1pDDuE25rIGXFJPi4mLtx1oCKEpLS7WfaGbsv/vvEZezUguHlKd1gaO0FHH1u8EuzcaN6yW1lCsFdB9xtmR1W8WHtdtyuaxwt3ZZWbe7EffXHbCV7IfTFoeyRsep20/tgAQtTGJD+eCPYN/2Ccq73gY4EwO+/2hW7jCDUqUlUqaaon9Alb+Kq+7dnfj7b/UNfJ8+ZSgtdQZ0rK1se+dpTwKOtE4oN9KL0vsiPqOnlkFl0/uCleWsgTOhCRKkOa/Y+CZK+7/icltxP58E+/7ZKBvyGZwtqv/tvQSMTj45Hpde6kBpqQPPPSeBKfP3b9KkXDvfatQoO37/PQ7ffONAz54OLFokfxeVdXbyyaV48UU7srOd2LHDhg8+iNN6Ul19dWm1gnkSjGrXLgH16zuxf3+ZW6s1cz9LSkoDbsNWU4Eca4oO0iz/4EH5v2tHQoL5uP75Z6BjR/X/KyHBGfHHOiVFnsvi8PTT0H58b+f5eK5NcbNGwHZkA8rGLPb+JYlMzZNAkpHd603OUsRvnwp5+Jc2n+j52lWvC9CuCyDfO5T7OI7DpsF2cAFKGgxD6nfNYSvLQ2nBXu0Lgvg9s9Rt935CXjTUD0U9Po/HDh7r2MFjHVt4vD0F+reI2KBUbXrsscfwkIw8cjNjxgykhmoudZhJDy5Dh9Kp6FmivtWd93cODqyZhi4liTC6WhTaGmHGDz8FfNt9iw9AihPW/v0n1q7Xvy3WjSrYBBlcPW/5bjjtt6JD3DfYG9cXW3+W0WlqfFrj5EdQjgQcWpYkHYSAeRJgdL2duqqwyMwMnDnzB5Ta0vHii31lJpXLdikppfj7bzMAcuTITEybVlLpsbZKchzC+MIrtfUducn4Y5r5N7Y5H0B8UiEGFD2NJo5lWDb3S+yM34uTLNf//ruv4bTFI7N8PZKd+zGoWKUp5cx/AHNSavbUYjz8ZJcKCuJht0+Aw2FD27a56NdvDqZNc32CkyxKYAS++cau/VhNnz6tIstk+/bmMrtPW8/OTsDUqV9Ved/+/ruhfGLE4cM2vPXWL2jWrADl5Tbk5Uk25viK7b76ajoSE8P7YdHXsabosGFDBm65ZUTF6ZUrFyMlxSx5fv75+qhfvyQqjvXOndIrqVsA2y3DtGleapJrQZyzCCcVLNLWN8y4C2sSz3W5PKN8I44ruhXlSMTM1NcQ7yxEumMLcuwdUWSX5wWlb/GLaOMsx664AVg4dxdgq+7rlzynLMA4WyaSnTmY+8O7OLr430hwluCQvSN+m7MNsG2v0e9MkSfSH9sUPDzWsYPHOrbweJsKjJ4U0RqUaqY3mtizZ482fc8gp/v27Vuxzd69rr1tysrKtIl8xvVlKdexMk4b27i76667cPPNN7tkSsnUPmmYLlP+oj1aOXPGdExoMRf2+AQ4utyGhKmnVFw+aOw/tFIC27Z8YP7H2nlJjbphwsgJAd+H/c8fgfU/onOHlujYy/V68V8c1r4dPmbEJL3B682QXDe91Y8u8PuqaxISzZ5SY0Ydr5XUnXKKZ5bU0qXALbc48O23KgBz3nlmMMvlWM+ciTFjxiAhwfM27Gv+DSxT680HXIkJrTz/7vYlvwEbl6FPhzT0btoA0IcxihOGtoOtrBBxP51aMSFKNHKuxYQRPYHU1giW448v08r00tMlKDzG43KpannsMSf27fNMTZowwfy9UlJsLn2qjMukQbk9wGLmhATzPvr1G4F+/eRY2DFliusNrF07AbffHp6gVGXHmqLDo4+6/h8aNuxojBzpjMpjvXatHe+/7/tyyfSU1o+3394TzZu7vgIEk33di7Bt+RDlA/8LpFcSJMtdAcxQq52bFqHDENfnRPufN8O23oF4FOGEgosqzncmNUXZmL9UGV55MeK/uUQ7v8mwxzChyfAa7b8c74Kvs7Sg1NC2+xC3eg+ccalIm/ALJkjJNdUZ0fLYpprjsY4dPNaxhcfbk1FxFrVBKSm5k6DRrFmzKoJQ8ktJr6irr75aOz148GDk5ORoU/X6601lfvrpJzgcDq33lLHNPffco/0nMf5zyH+WLl26eC3dE0lJSdqPO7l+XfgP1rx8ARLW/Vtbj4sze21Jn4uEND1Q17BPxdn2+u1hr8rvnZimf+tcjDjr9aR/lN5nKqF+K/mD1vA3qXuk3Esygux2J+bOsWPECd7/Rp07J+C//wX+9z/goovU/01ffP6/zdXHlXeYjPj2ljF3Vnofr7iCzcDBea63e3gVsGu66kll/R2cpUj4cRAwYQWQ4j3wW1VuVbxetW/vvdG49Xf3fFgnaE3Pe/UCTjopsJ5QX3zhen25+Rdf9Nzu3nvjcM891mmKoVdXnqNilXs5aVZWvM+nyUg/1ta+btbHsUzbk8zFa66xaVVt9euH8HcoLwGW3qKt2pfdAYz83v/2RWbWkX2/fHETbzYpd5QBOz73ejVb8V4k7JuppsPu+R4ozQFSshHfbARgr/lzwAFbMzTEGsRtflfdX9ZIJNS3TKqlOiXSH9sUPDzWsYPHOrbweJsC/TvUaqPzI0eOYOnSpdqP0dxc1rdu3QqbzYYbb7xRm8739ddfY/ny5bjooouQnZ2NU05RmT3dunXD+PHjcfnll2PhwoWYM2cOrrvuOm3CnmwnzjvvPK3J+eTJk7Fy5Up8/PHHeP75510yoWJN4/IV5okVD6tlm3OBFvqIaZGuj6kW3vpq+BNnTN/L9z55Ly4ZiK9fxb2OHeUO9SHmvPNcs2zc2qdpp+W/cc2anEsdm5/MNCPbqXAHsHe22ahX5PwF7P3FdfvWZ6tl8QHgx+FAiVtX8hAKJIlxwACgbVvX/lAffiglRMBrrwV2P7/pAynFkSPASM9BWRXKzV71RH7t2OHZENz9MR9NvH0xJknKzz6rnreSkyUgFeKdWPeyub5/vgos+WOdcCdDPvLWqMbnMuDhowRz4INBeu810xuRH/pLLTe+aT4XBiEgJQrsWa6voU2PC8rtEhEREUWCWg1KLV68GP369dN+hASKZP3+++/XTt9+++345z//iSuuuAIDBgzQgljTp09Hsryb1b3//vvo2rUrRo0apZXiDB06FK9ZPl1KrxnpBSUBL8mmuuWWW7Tbl9uMVQ0dqzzPbHKs62l7AnD0f9Qb7q5VDOBVTN9zqyEt1N9QJ2e5jsgm10wpp3pYxtnNiMaFF5oTuYKmcKdapvgJOqaq4C6k6f3+OWq90zVquX8eUKBnFqR3BRoeDQx6A+j3FJCQDhxeB/w6EXCU1lpQauJE19PSEm7DBjOQt3+/64SzQIJI1rkJkjX1i1tczkomjxH5s24d8McfQMuWwD33uF5W7YBzBBhhtsaqHVs/A/640Twt2UsH1FRen4r06bCGnd8Ca/8DbHzbPG/gq0Cq3qSu72NAq1PVet4qYN8cYLvep66taz+qmjhoNzo86hiUIiIiojqkVsv3RowYAacx4tgLyZZ6+OGHtR9fZNLeBx984Pd+evfujdnGrPgYZ9vxNTIdmyoPSonO16qfqor3lSmlv+FPDk5JV13PlDKCUqeeCrzyCjB/PrRSs6BwOoDC3a6BJ29S9MuK9N5t6V2A1mepD2r7flfnJTYETrIEOrvdqj40/TgC2Dcb2PAm0Ek1VA9nUEpK9T75xHM76R0lH/YlICWZUmmq2lQj5X8+Ws1ViLMkP1QWKJQSpiZNAtp9ikHLlsnkTO+XdewY3RXO7gHhsFv1lFo2HqK+KNk9E9jxrffXOoPxPCfZwRJwX/4w4LRkVw37Emh1CtDqDHV5g97Anl/MwL1xn20vABoNCNqvciCuh+sZDY8K2m0TERERxXSmFIWffasK4JW3vwJIamwGFTJ7B+9OjEwpKXuwKrJkSpHPTCkjKGW3ObQG3pKNIxk+EmA55hhg1qwg3FHxfv3Dls3/8UgxhwxoWpwMZHR3Pa+e62RAjXwgkywCsegq4IfBZgZBiBzl9jlNekRZkipdrF6tlpKZUlxsnh9IL76iInP9Tb1Sxxcp7yPy5ZtvfF/20Ufh3BMpO3sXmHM+ULQ/aM9lnS1V4MZjMiykfPjAQrU+7Aug3cVqfftUNRXB5/X0oJRkB6d1AMpkMEehyow6u1gFpERSQxWQEkbz9CMbzee4brcF9dcptyXBkaWXCbY+E7BHbDtQIiIioipjUCqWlBXCtusHbdXZ7hKg/4tAo0HAsM/MPkHBYPSUci/fY1AqoL4y3sr3hPT7nzdPJtEF4Y6M3igSmJRSTX8BRinFMzQerCZMWY+ht6CU6HS1+YHtwHxgzrlAabBSvTxdeSVwxx3AqFGqcfnzz1d+nTlzZFSpeTqQTDRrEMuXNm18N3smqqwP2ksvAfrsjuo7sAg4pPo1VkpKbOdfDGz5AFh2H4Llu+9cTz/zDMIjR++bWK8dkJIFtDgJsCepbCZ/fxOjxLxeW+CYt1X/QwlIDf0MsA4FsZIJeAmZ5mkJZmX2QrCVD3gd6P8CMOCVoN82ERERUW1iUCqW7J4JW3k+Cm2N4GzQH2h7DjBuPpDlp1Nzdfgs32NQKhBGptStN4ewS3ZFPyk/pXsG+WBnqK+m8aFBX++XW0mwS/qvGE3tJePg4GKEipQ6Pf448OOPqiyqhZ/hVNJsWXTr5lqCF0hQypop5U2XLmZJoPSU8peYQbHN2s9MDB0KvPcecNVVNbxhabr9wyBg+tFArp4W6E/BDnN909ueWa7VJCWIMhXT0El/+gg5o2F5/Q5qmZgBtNDrCaX0uLJMKXmNajoUmLQVmLgeaDzQf0pYuwvM0z3uCU3PRMla7fJPlaVFREREVIcwKBVLCnfCGZ+GXXHHhLbReEKGWpbkuN2/3sMohT2lfDn5ZDModcXlQQxKlRwCfjkJWHQN4CgHCrap842Gvf4YPVjkg5qR+dTjXvPyhmpQgVdNhwFn5QEtJ7lmMNSyYcPUMjfXM1NKek3JlLDqBKUeewyYOROop1ewTpgAXFuNtmwUG/7SB7YZRo8GLrggCE/PWz+VfFjAWQ7s8FMjaDCeD0R5kTlJLlCSYbT5I88vIqSStxHCr2Cr6/RQYQzs2PQOUJrnv6eUZD9pyya+M6SsjnoOGL8YOGk10OHSmu07ERERUYxhUCqWdLoKZSfvwurEs0N7P0avKhmpbcVMqUpNnQo0bmI3m5EHy9opwM7v1Ij0XdOBfP1DWz3LhzZf+jwK9LwPGP61OeJcsgiGfqqCU23Oqfw2ZHS6yI2MoFSW/l9Qgk/WEjspn2zeXDU7twarAi3fu/NOoFUrMyglXrZMpScyrFgB/Oc/ro35TzstSDd+eK25vvvHyrc3ng8MM4cAi/xEU6V30s8nAEc2q9NzzgLmngv8cavHptddZ2Yl1pjs55+3qdLEyrZzf35rMliVGkugztv1JTus7IhrUCpQ8rzYsL8aBEFEREREVcKgVKyJS0KpzUcjk2CRb5eFvMGXb93dS8Y4fc8nyZCwGU1srVOfamqLpWuy9FSpSqZUYibQ+2HPEpbWZwB9HvHfk8o9KOUtU+rgH8DBJQinpvpnzvJyYPt28/yrrwbK9D/7Ai/T42UQ6IYNld++NSglWMJH7j6VZCbLpLqdO1UvtKCwBplkAqb1ebiyTCnDupdUw3B3B/8EfjtFBbdX/p8KTO39TV228U2P/+wXXqh6S/30E2rGUQbMHAasehpYMFnfx1eAXyYCO6ZVnill9MQT++er5ab/qduQLwCMLCnpPWWUHBMRERFRyDEoRcEnTV9t8eaUN6ORrvFBIc3SZIQ8GX87+RAWDPJhK3elefrwOrPnSiBBqWDINIJSy10zwCQgNb2/6n2z5ePw7IvE2RKBDL3KdJuXz+PiwQc9z3vgAc/zzjsPyM4GLrrIPM/oKVWVXlUUWyQgav2/1jCYrYKM51rtjgrNoJHP7fUHQfZJQBO9tlVs/cRz23VTzHV5PEtwyuAoAfI3eQTapYxVsg9rRLKbjN9L7nfr58Ciq4Gd3wK/ngjs+cXc1lcmaKNj1HLPz8DP44F5F6rb2PqZa+leKMvbiYiIiMgFg1IUfPKG3ijhK9oHlBcDMvVPghHyLTR7SvlnZB45S4Nyc7aDbik/EpQ6vF6t1++IsJCyFnuiGrGer5f8SBDqj1vMbTa+g3CScinx88/eL7dmUImSEu/bNW4MbN0KvGPZ/V36cEODZMEQWVnLQ6UheI2Vl6gSNHm+NaZrtjg5sBI+I4gjU+rG/KZKdrXr/WQ+j697VfWO2mIJVEkASibaWe2bi5DYawk6id/PcD295UO1lEwtI3jlPhm0sRGUmqVekwy7vndtck5EREREYcOgFIVGRVBqt8qE+VWffJTWVurTanXXoiYoFaRMKdsBvVSlQT+zfK9wh+s0vXD8TkYJn9y/lM/MOcf1g+a+31RGXZiDUr5s3AjMmaPWp0/3nekhAac4vdWWwb30T/rp3H478MUXwG693z/FBumplJkJbN6s4iVSxpaTY06AvOEGIL2mFdWSOfRxEvBJPbO0LS4ZaHGi+Zjzx72ct7E+3GD/XLXTS+8AFl0FfNlMBZYT9bQuyS6SILdxf9p15iEkcld5P7/PY66Xy1AHo+F6akvXba1TQ632/u7Z5JyIiIiIwoLRAQoNGV8t5Ntoa+mY8WGHKi/fC1KmlF2yAET7S9SyvMAMHIZzvLjxgVA+IO9xazATX099kKysgXEQxet/Zn+GDgXmzwdOOAE4dMj1stNPV2V6Emzy1dzZ6qmn1HV6967BTlNU+fNPYMoUNeWxXTvAbgdGjQL6WmIjY8bU8E4OLVOTNQ2b3zf7KVkD0YEEpYxyt0YDAFuc6gMoWUcb33LdfsgH6nKZ8HdgoTqvzXlmICsUjJ6ETUeY53W5AcgaqdaPbNR/l61mxpMRKDPEJQGZvc0y8lP1jLIjG4ACPVDPoBQRERFRWDEoRaGR1s61wXZ6V2DAy0D/52p1t2ItUyrVsQc2mXgnHyDbXQhkWjopyzEJp4qg1F/A3tnm+UPeB5oMD/t0vk2urW98es7Lf1kp+fvsMxVsGDDA8/JHHgG+/RY49VTPy/btU9lSErBwOIDZsz17Tt18MzB5MhukR7s//vB+/ha9pVuNg1LyH0Sajksgxn3gQL22QEZ3cxKqZBB5I8HgkoOumVLxqebjVcr2rJqfAGSPM8vcjL6Bbc9Xy5xlKkC083ugVJ9mF8ygVJd/AiktgLgUoOMVZo9CuVxKFyv65fmYLCqvQ61OV887Wv8oPbiWu1xdnsSgFBEREVE4MShFoWF8UCjao5atTgM6XQUkcKpR4I3Oa54p1bh8mb4yGEhsABz7ERCXqs7reBXCyviQu+Nrszny+D+AtueZZYSbPwR+nqDKkcLsqqsCy6i65x5ghJ6sIZkv3iQnAyee6HuaWvPmwFFHqcbpw4e7Bq+kl5WUdr35JrB2bbV+FYoAchzvu8//Nv/6l2q6X215q/TG4tJNfAWQrZfrGf3iJAPRCB4d8RGFzdezpGTiXKLe/V80GaqWf+vlcQ37AwNeAo790PsUVXmOkUCQ9A78ugPwywRVohssRslxRg/gpNXAxHUq6CYZn/J7SmBJAlK+mpxX/F5DgGGfqf5SUkpuZPUa2WTsKUVEREQUVgxKUWjU0zOlDI0G1taexHSj8wzHJtdR6PIh7ux84NxyoJ2e2RAuUhKUYPnQK4xSGiMoJT2mpNxw0bXh3TcAL7zg/fwyt4S1Fi0Cv00jeOUvKCFmzTKzos46q+rZXBRZiouBVq08G967k21qJG+N+dhK76wCLgZjiIHxBYGUqEmgW6bOfZoJ7JzuVrrntjNdrnc93f4yoNPVZuDKCOYYAar4FJWBZLXzO6CwBk3UJMAlP5JxVZqn3282kJAGpLYwB2sYrzcSeDP+JoFOeZXbE0ZvLJbvEREREYUVg1IUGu5BqIZeapwo5OV79R3bzOwCq9poNi/9XSTLwshE6HkfYI/z3nD94JKw7toHHwAJCaoJ9T//qUrqvJVaiUaNAr/dtm0D31ayriQLa56lT/SGDYFfn6ouL09lqcnxDyZpbG/VtKnKiJKeYkENShmlasaUuTbnepbnpnVQy33zgI+TVZ+/0lxg9mlA0X6zB5N7uZsEdSQbSZby/C3lv1bWoJTx+O3zL6DJsWrappGRWd0+cTt/UI3bvz/KDJzFp3nPtjXKxfM3mj0MjcEKlbH+HoJBKSIiIqKwYlCKQkOm7PV9UpWitT4LSNW/jabQle95aUBU37HVe1CqtmSfAJy2GzjrCND7Yc+sDoOzXGVIhMmZZ6rlyJEqY0oanF9/vfe+QI31wZKBkObWN94InB9gUtr//Z/nBEAKHWk+P3WqOj7Lg1QxOmOGZ4Zbv35AYaHqQyb9xoIXlNrqGpSS4MzwqUCf/wOaj3PNGFrzrOtjqrxQDRwwyve8lbvJ4/LkDcC4BZ7BIG9BKelFNeZ3VV4nj3VtH6uR7ifBsrnnAeVFQM5fwNZP9Pv08TpSkQ22yexLlxngc577bTIoRURERBRWAcyfIqqm7rcBna9TE4+oGuV7VciU2jUT+P0MoO2FwID/qPOK9yEZuWo9wy11o7ZpPWAsjA/VBkexGtGe0iw8u+PlmVCyWiRAVVJS/aCUkP5QRnP0nXqv5kDt1afUU2isWmWuH3OMyoo7eBDIyQEGVrPi+OyzzfXMTHVb555r9h+7914gO1s1vO/oFoutsgIvTb1bTlI/vgK+HS5Xz8lr/6PKZSXwo92GnwiZlMi5S21prkvpoDvjMW0EzgJVfAD4rqvZfF3s+Ea/zxb+g1L7ftcbr9uA9G7VC0pJE3UiIiIiChtmSlFoSZ+R2igVi7VMqVVPq54r66ZUfAi05f6tLZ3Sb8U9CBRp7PFA15tdsxTyN1d+vRCOp/PVpLyqQSmDtSQwUAcOVO++KDBHLMPhCgqA6dOBvn2BQYPUdMTqaG2JD0kQUjKnLrjAdZvLLgPuuAPVJ//vpfG3e/meN81Gu56WiXVZo9T6lo+Bvb/5n1bni3V6Z6Y+xMAqSa9ztQaXAiETWyUwJYxeUUY5r69MqQb91HL/PDNIJVlbgbD+3vYk1TidiIiIiMKG0QKiupApZYwzF9u+0BY2KXuRmwk0Y6C2HfVv4NTdZlN2YwS8N2teAD5rCHxoB6b1Dnz0fHlJRa+upEoS+Bo08H5+VXpKWbVvDzRpUrXrMCgV+gl5VhdeqMrsxOuvV+82pWRTvPIKkJICjBkDxOmt04Klc+knSPi2nRms8ReUkjK7ZmPVugRcZApm8zEqcCMBI2mAbgxBqIpGg9S0P/nJ8tLRP7GhWpYcCuz2Fl8PzBqtel6JXg8B/Z91+138BKWsX35UpVy5oR7QEhLI8pYVRkREREQhw6AUUcQ2Og8wU6q8GCi0jPna/IHWO8a281vtpLOxPto9GsgHQmPUvK+pXdIXZ8kN5ofdnOXA9q8qv+3ig8BXrYHpRwFlBVrAoDLuPX86dao8mOWPt+s+9phKfDl82POyXL36kqpGSi5POgm46y7/2+3W/4udeKLnZX+pmG6VGUGt1AATdarM6UTX0o+9N/r2ZejHwMDXgONnqaxEyZwc9rnrNlUNSkkJ4Ihv1Y+3Eu3EBoEHpSRYvPZFYM8ss1RPAk3GdE6D+0AEg0zjswbfrVMIK2NtiB5oAI2IiIiIgoZBKaJoL98rsgRvbHHAwUXAb6fAtk+V5ThanYGoYvSRKtqjllKiVJZvXn54ved19v5a+e3KeHq5TQli7ZqulWhVZpveA1pIv6GV+mCv6kpOdj09eDBw551qPS3NPL9ePbOkjKruq6+A774DHn/cd4Wn/G2NTDTpJxWMfl67dqlyvaAHpf5+ClhwhRZMRcl+2GBpWF6vLZCQ7v/6iZlAx8uBBpYgj2RMWQVa7haoqgSlCt1S1kSDPup3s/a6yvRRUyuaWrK1sk+qWiB8xPfqebe3pQs9EREREYUFg1JE0V6+pzX21Rv0DtRrjnZ8o31wzbO1Vh/soklylhlsk343X7UFfhhoRhd2zzS3NUp29gXQsClvrbmesxxvvw1cfrnndD1fpDl1gn5oqstaEtiiBfDmm573YZSRRUtQSg7LggUqIBMpzjrLXPeWgSZ++UUt27QBBgzwvHz9ehVYsvadcif/dySmIT9yP2dY4r+BZOIF5NBSYOntwIbXgRUPw5a3RjvbKf2PpA+be8ZTVQz/WjUFP+oZBF1VglJGbyzrdSUYJX/YDv8wn98aHu37NnrcrSYO9rg38Ml7huzxwJk5QM97q3Y9IiIiIqoxBqWIor18r2ifWiY3ATpcCnS8suKivXFeGhBHOmv53rapal2ath9ep9Z36akofR8HTtPTWfJWq238sY6mz9+CZs2A114D+llaylR1Ql9VWXtKvfce0NXSK1pIcOeDD4Bbb9V305IgFql++kllGklAbdo0RJyFC72fv1xvwzZkCLT/C4YHH3QtxZs/3/v1338f6N/fPD1lCjB3rnk6aJlS6y3NrTa9B1ueGhnobHKc6sPW8Kjq33bLicBZ+UCXGxG6oFQAjc6PuA01kLI9o7eTBJuO/QgY87sqPfQlNRsYOR3oU81sp0gfBkFERERURzEoRRSp5XtVzZQypkZJCUrDo+FMbY3NCScg6ljL9w5aIgpGU+dDempT42PVhK+Wk9Tp1ZVkexxxDUoFQgIPkvHytSSUBIF1cl9DvQ+0VcuWwLnnAul6NVZREfDjjyEdMlhjf1tigd56M4Wb+9/qB71vtrXf1KuvmmWTPXoAPXsC48YBZ58NPPAA8I3e1khIo3IJuFkz6vbt85yot9aSiCe6V7FFk1er/g2se8k8XbgTtm2faqvO9C5BnJBqC11QSkpvpWeUP1JSW8EGdLvdPCmBqDZnA2lRlvFJRERERAFhUIoo2jOlivVMqaQmZsbU+EUoO3E98u3NEXWM8r2CrcCBxa5lTJIVViD9Z2yq54zodK1a7vzee/Rm62fAkpuAg5bbynfLzPDhvPOAvDxg4kQEhTVTyl95l9FTygiKWDNwIo3R2DtSFBf7bli+ejXQujVw1VXmeb16qel406cDH32kzpMm6RIcNEhpomRFLVumeotJ8NDdW2+Z6088ATRtWtNf5ACwVI+cZU8AskZpq/Z9et1h/SAFpUIlIVM9Tisr4SvaC2zV//CD3wMmbQFaTAjPPhIRERFRrQtCQQoRhT1TSoIvG99U06jcM6WiXUX5nluTIglKHfpTrdfvCCTUV+tNhwFxyVoWCaTfToalJi53NTDnXM+/pQS25G8YQIZIMMr2vGVK+QtKuV+2cSNw7LGISNaeSxkZtbknwObNwIcfup43cyZw++3AqFHA+PGul0mPsJEjvd+WZE+5k4y58nKVbeWLZFDJ/dXY/gXq/21qS+C4b4G/7lbT6XTOSA9K2eOApIYquCbPUSl6sNlKHoO/n60e62kdgFanBb/hOhERERFFNGZKEUVjptSWD4EF/wB+HGFOnjMypaJdSrYZmBPJesqJBKSMoJSMizdIQMpogHxggettbZ/qPbjnKKmV8e+NGgUWlJJYWX095iZKA0yaCweHQ023277dMygl0wRryyOPAO3aAXffrU4nJZkTDZ96yjMgJb2wJIhl/Ttb3XwzMHmy63kyWc/ac0ostiTgiUB7lFVKpmiKpiPVf4gmrlFJZ3o3RLxE/T98iT7mUPq+fZkNzD4d2PkDsO5lYO8vgDRtH/EdA1JEREREMYhBKaJoDEpVND92AvvmqNXUFqgT4hKBdEu2U4fL1ZQ9KVPcOc0zKCUaH6OW+926Uht/G6vEht4zscLACJIEMp2tuaXyMpIanksm0imnqACQ+3S72ux9df/9rqelZ5c0YPfV/FwypIxph94kJwNvvOF63mwvQx579zYb07uXXtaIPmUPDXqrZdMRbjtY0/rAMDCyN41sznWvqsfdti+AX8YDi/XS29ZnAMHqkUVEREREUYVBKaJoK98ryVHZBd4yjOqKzF7merNRZv+cvb95D0o10qMPB+a7Rkj2z3W9vP2lQIoe7ZFyvzAzGpgHEpSyToSLpKCUlMOJMv2/53493mBkUdWGefM8z5MMKOkJ5k4ypAYMCPy2r77a/+VSAlhQYJ4+7jgER+EOtUzRG1glpAGNVSraPrvl8RHJZBCBkBI+cUgfVuCu2ejw7RMRERERRRQGpYiiLVMqZ4X38+tKppRoe77KjmpwFNBkmOfY+4Y+MqVylqlpX0ajdBlHb08Ejp8BjPoJ6P+CJSgV/kwpabJtsNsDz5SyBj1qm/t+795d+5lSZ53leZ40L7/kEuCOO1zPHziwarf90kuq0bmV3KYcn3/+U52+Vk/4GToU6GpJ8quRgh2ej+uBr6G80w34K8nSqT0qglL7AUe56gvnjXsWGBERERHFDAaliCKNjEB3z5SSD3R/3Aosug44qGcbND9B9WKpi5lSLU5UU7jG/K7+Hu0vMS+r18azdEk+uEtDaKfDnNiXt1YtpYGyNEXPGqmyTVL1yNCRDQg3mfT25JPAu+9Wvu3Yseb6Pn3AYiQGpYzeUrUZlLKWEBpkaqK0Ynr8cfO866+vXnldlluP7tGjgR07gBdeUKe7dwcOHAB+1du71Zj8IQu9BKUye8LR9ynk26MkAF1RvncAKNhiBozluaphfyCtI9DxKiCtba3uJhERERHVHk7fI4o0Ni+ZUts+B1b/23U7+VBXmqtK1KRPktErqa6QIJMhaxRw1HPAxreA7m6pLwYp0Sv4TJXwZR0HHNaDUjKh0CpTH6uWuzI0+y0ZWFs/BdpdCCQ28Lj4ttsCuxnJ8nn7bdXHaImPqqfaDkrJvtVGUEoav0uDdQkwXXMNkJurzpeMJiPDzBqoyslRl3WpZtsiCW5Js3Tj2ElpoPvgRulhFTSlOUB5kVpPtqTMRRtro/P8rebjcaL+2CQiIiKimMdMKaKILd8rA3ZOB2aNBuac7bld9gRg0BtA8/FA/+c9PyXXJfK7db0BmLAUaHuu920qmp3rDYYOr1PL9M6u22X0NEv9QmHeRcCSG4DFN9Q4+COBELF3LyKG9b/Z8OGul4Wrp9QFFwBNm6rMs//+13sfLinfM2RkqLK6mjxErrzSXA/5Q80o3ZNAc3wlzceiIVOqaD9QsE2tp7aq1V0iIiIiosjCoBRRpJbvOYqA+ZcAe2Z5btNkqArCZHQDRn4PtLsg7LsZcRrp3aulvLGs0AxKuWdKSYaZ9KuSy/O3BHcfJJC4+0e1vvk9oPRIjW6ucWPPZuK1zV8vrFBnSknQS6bmffKJarS+dq1raZ41eGQt2wsGyY4ytG+P0PLWTyoaVZTv7TUzpepZGqsRERERUcxjUIoo0tiT1XL3T0DRHrN8bfwfQLMxQFwy0Oexup0ZVR0ZPdSyYDvwSSqwc5o6ne7WeTqpIdB4iFrfNSO4+2BkgxiMAFUNg1IyfS9SJvB5+293+eXhCUpJz6ZfvAyelH5Ozz2n1qXP09KlwD/+Efz7lz5Sa9aYxyVk8jeqpdH/LFoZvaKObLRkSkX570REREREQcWgFFGkidPLdcr0pjitzwZG/agmzo38AThtD9B0aK3uYsRO+pK+UlbSEL3RIM9tGw9Wy0N/Vf/+pPm8VXkxsO4l1/OMvlbVlJ5u9ir64w9EZKbUoEFmU/ZQB6UkKOROMqLkb2QEyxITgT59Kp9uWB3Z2UBnt2rQoCvJAZbcpNYlEzKaSSNzKUeW6Xsb9DpLlu8RERERkQWDUkSRxr2HjPWDqXzyTkgP+y5FjWM/UOV5hu53AXGWCYWGzF5qmbu8evez5gXg0zTV0Nyw8Apg1dOu2+VvRk3I4TYmv0n/JilZqy0rVgBTpngGnqwBoVD3lLrzTs/zbr0VdcvfTwCOYrXe7mJENZl22X6y6zRRBqWIiIiIyILT94giTVyq6+m0UDewqUPS2gFjFwDzLgTKC4GOel2Zr6BUznIVZalqKaQEpWQ62u9nAec5gbICYNO7rrcvty2T+Gpo1SpzfevWMPQz8kGaiosGbgMFGzUy/3zhypSSJuZSQicTCq0NzaNeySHgb70Z1pAPzUmR0Sz7BGD9K+bpaM/+IiIiIqKgYlCKKFLL9wwMSlWNPU5lTPmT3g2wxakgQOEOILVl1e7jyAbX09Jc3dBhMtD0ODWFr3A3gmnTptoLShkOHfLMlDJK5UIZlLLe9g8/AMcfX8faqklT/Kl6FpE9CWh5MuoEGcgggwWcDvW4Y6YUEREREVmwfI8o0sv3GJQKPinpq683B5KMppo4tAz4cbhab3UaMOgN1UtHFNU8U8oqJwcRx5opFYryvWeeAc47D/j9d7NnlJQy1qmAlNjyAVCmd7Pvcj0Q75YxGa2kr9uwL4C+TwDj5tfBA0dERERENcFMKaJILt+TSXvJzWpzb+oumcqXtwo4vF6l4UhTcq0xcyX1YJLxYWR+iDlnm5c1GqiWKc3VUjKlqlMe6MNhvfd9JLH2lAp2ptTGjcAtt5jZUaJLFyAhAXVH0X7glxOAg4vV6aOeAbrqjc7ripaTansPiIiIiChCMVOKKBKnyBlkfDozC0IjRQ/2Fe8DNr0DfNsVmHdB5dcrPmgGpETeanNdJiVab1saVpcGL70pEoNS0mMqmOV7X38NDBkCrF0LjBtnnn/woFq2qmvVXzKx0QhIiXYX1ebeEBERERGFFYNSRJEmsaFl3a2rNAVPUlO1LNoL7NLTcLZ8BORv8X89XyV5p2wD0tqaGW4JmWo9iH2l8vJQK8rL/V8ezEypSZOAefOAm28G1q/3vLxlFdt/Rbw9s8z1Hve6BqWJiIiIiOo4BqWIIo3dUlWb2bs296Ruk143RlCqYJt5/q4Z/q9XoI+As0rr4NksvaKEr2Z9pSZOrP1Mqdxc78Gj0aOBU08NXk8pa1Dr+++9b3Pxxag7ZILj/gVq/aQ1QJ9HanuPiIiIiIjCikEpokjU79+ql1Tna2p7T+p+UKp4rwpMGQ796f96Bds9z2s2yvO8tHZq+dfdgKOs2rv57rtA69bhz5SSANGzzwIzZwK73ZK9TjoJ+PJLdVlqavDK915/3Vw3Alwplr7/PXuq0r46Q6Y2Somn/F+s36m294aIiIiIKOwYlCKKRN1uBk7bBTToW9t7UnclZ6mlBKSK9pnnH1oKbHwb+ONWoDTPd1DK2oC+2WjP7RoOUMsDC4A1z1V7NzMzgeuvV+t79gS/mbgvixapErqxY4HbbzfPLykBvvnGtdVZMMr3duwArrzS8/xOnYCTT1brTz6JumXfHLVsPIS944iIiIgoJjEoRUSxnSklQSZrM/L984D5lwKr/w38eYfn9Qq2qmX7S9S0PZni19zSkdvQ6WrAro+J2/5VjXa1fn21/OILcxpdqEmQyPDdd+a6t8l3wQhKSWNzb5o0AT79FFizBjjhBNQt++eqZZNja3tPiIiIiIhqBYNSRBTbQanyQvM8aVButf1L10iLTN3b/aNabzwYGLcAOGkVkJDuefspWcBJ+mS+/fNV/6AaBqWElNSFw4YNnue9/LL3bYPRU0oys7yRYFRiItC5M+oW+X8l/y+M/0tERERERDGIQSkiik0yHc8W71rO16Cf6zZFe4DDlhFwe35RTdHlus3GVH4f9dqpaYrOMiB3ZbV3Nd1LzCuUpF/Ubbd5nt9WHy7oLhg9pe67z/v5Dz2EuiVvndlcX/5/yf/BBkfV9l4REREREdUKBqWIKDZJeo+RLSVSsoFGx1gu158et081z9v7i1q2PBmITwnsPhoNUus/jwOObKxxppQvBw4k4733bFrPp5o67TTv5zfXBwoGu3xv1y7Vq0pI8/S0NPOySy5B9Nv6KbD6OWDHt8B3XYHvegBbPlaXSd+4QP4vERERERHVQQxKEVHssgal0joAHS4D4lJVn6ijnlfnb/vcUm41T60bgaZA9LwPiE8Dig8AX3cA9um3UYOg1D33eG5z++3DMXlyPJ55BiHTzNLbPVhBqaIiIDvbPD18ONC1q2cWVtQ6+Afw+1nAHzcBv05UJaDF+4Glevf47LrWKIuIiIiIKHDR/nafiKj6kpu7TtDL7Amcvg+YsMwMFhz6EyjJBaa2NPtJSYPzQDUZDIz4zuw7NXMIkLvK/3UcpcDGdyu2cy/f+7//A+bOVc3B9+5V5x04oLJt7roLQdWokbneuLH3bYzAUVV6SuXlAW+/DbzxhnneuHGqf9Q77wA9ewIffYTotvMHYH4lqV7ZE8K1N0REREREEYdBKSKKXR0uVct6bYF2F6j1+FQ1NS+tPZDUGHCUAJvfBwp3qssluNSwij2Amg4HjrVEWHZOM9cLdqgpf9ZA1epngPkXA7+cqKUfeSvfO/ZYoEsXICsL2L7d9bL33nM9LcGiVasCy2SSzCUra9ZSXFzNMqXktv/1L+D334HHHgMuvRT45z/Ny6fqlZLduwPLlwNnn43otfN74JfxQM5ydTrreKDt+cCkzYA9yWys33BAre4mEREREVFtYlCKiGJX6zOBkzeozKj4el76QekZUZv/Z54vwSWj31RVSOaVkRUjTa4Ncy8AVj0JfNcd2KZHZbZ+ppb5m4DCHWjQwP9N33GHa7TooovM9T17VDBJAj1PPln5bubmup5+4AG17NPH93UqC0rJ+f/5D9CqlWpoftllwLffum7z7rtAstvww6j29xPmempLYOQPwJD/AfXaAMe8qXqY9X8BsPuI9BERERERxYCIDko9+OCDsNlsLj9dLV/bFxUV4dprr0WjRo2QlpaG008/HXvkE5jF1q1bceKJJyI1NRVNmzbFbbfdhrKyslr4bYgoIklGVIKPTuLGND6jl1T7y2rWA6j5OLU0sq72zjabp4vZpwIb3wEOLTXPK9iJhAT/N/vpp76fyp/XW2OJO+801xcvBv7+u/Kg1JgxwJIlwE8/VR6U8lW+9+uvKiNq/351et06c93QogVqz7YvgCU3AoW7g3N75UXA/rlqvce9wPGzALtl0mPb84BTdwAdLw/O/RERERERRSnLu+TI1KNHD/z444/mDsebu3zTTTfhu+++w6effoqMjAxcd911OO200zBnzhzt8vLyci0g1axZM8ydOxe7du3CRRddhISEBPyfNGUhIvInvYvr6fqdanZ7Kc3NoJSjTGVJuXPvQWQEsKqovFxlSFmDP0l61djOncAAvWqstFSeV9X6008Dt93meVtHVVKtaPSU8pUptc2SGGbY7Rb/GTYMtUP6hM0+Xa3nbwGGf1nz25SSPekLltQI6P2wGbUjIiIiIqLoyZQyglASVDJ+GuuddnNzc/Hf//4XzzzzDI4//nj0798fb731lhZ8mj9/vrbNjBkz8Pfff+N///sf+vbtixNOOAGPPPIIpkyZgpJgzE0norqtfrCDUvqYuYKdwNzzgYKtgD0ROGU7cGYukNbR8zqFO7SFv0wlbyTQ9MorwOuvuzYtl8bivXqZ5734ohnEcg9IBXqflZXv+WuA/tVXQHExKs0GC5k1L7j2+iorABzlNbvNg4vVsuHRDEgREREREUVzUGrdunXIzs5G+/btcf7552vleGLJkiUoLS3F6NGjK7aV0r7WrVtj3jxVaiPLXr16IUs6AevGjRuHvLw8rFy5shZ+GyKK7UypbLNX1NZP1HrP+4HUFqqBev9nzW2l95DRCB3AyJGB3UVqqrl+9dWul0mG1OWXAwcPmucZE+70p9YK0hg90Pv0F5RatAhYs8b79bp1A04+WU3cqxWyw0aZnZCm9ju/A77rBnzfDyjNq97tHlxiBqWIiIiIiCg6y/cGDRqEt99+G126dNFK7x566CEMGzYMK1aswO7du5GYmIjMzEyX60gASi4TsrQGpIzLjct8KS4u1n4MEsQSEgSTn2hm7H+0/x5UOR7rILClIj45G7YiVUJXmtxG1btVV3wjWBOCnJl9UNbpZvM2m4yBveM1sJUehrNeW8T9/QgchbtRXnGf/tOJBg0qx/btdhQUBJ6ds2SJEyUlZdixw+byktChgzzfBXYbDoe6rsPhRGmp2bPvr7+AgQPNfe7a1YmJEx146inV3LtZMwdKS2uYlVQTRXuQUHwATtjgzD4R9p3fAr+fVXFx+Yb34OhwRZVvNn7/IshfpCyjL5xBfvzxcR1beLxjB4917OCxjh081rGFx9tToH+LiA5KSbmdoXfv3lqQqk2bNvjkk0+QkpISsvt97LHHtACYOykHlIbpdcHMmTNrexcoTHisa6aNYxL64mVsjxuGJTMsTcmraQJSkYACbX11fnesnT7DbYux6n53/YC+Mj1v60os3DtNv2xSxVYZGUXo02cffvutVcV5//jHj3jkkcGS4uVyi506HUKHDjmYPr2dx/6Ul9tw+eVr0bLlYQDHaOc9+uhsTJtmSaeqxLp18uXAcSgoKMS0aeb/t++/bytz+ypO9+q1Fsceuxpr1vTAb7+1xKRJ8zBtWjWzkYKgcfkyHCuJa7YsLD9wFAbDdSRg7tIXMXtNyyrdpt1ZjBMLVmhBqVl/5qLoL+PYBRcf17GFxzt28FjHDh7r2MFjHVt4vE0FBeozT1QHpdxJVlTnzp2xfv16jBkzRusLlZOT45ItJdP3pPeUkOXChQtdbsOYzmds481dd92Fm2++2SVTqlWrVhg7dizS010/7EVjtFIeKPL3k4bvVHfxWAfLBJQW34esxAaYYFMZPjURP70VcFjVs3XqNw4d20zwup1tezEw72VkZcZhwvGe22zaFIe0tGYYO9aBX35RldinnjoMb72V7FGKd+GF6bjiijT4etp7990eFet9+jhx220qOBWoJUtUZlZycgomTDD3NSfHhldfNbcbNqwjJkxoD9lE+kzZ7UMRSrbdP2gZZx69wXT2dRuApUBq8wE4esg9KF96AHHrp2iZUzY40dCxBhOGdfB5fa/3eWAh7D854EzKwvEnXhj0nlJ8XMcWHu/YwWMdO3isYwePdWzh8fZkVJzVqaDUkSNHsGHDBlx44YVaY3M52LNmzcLpp6vJSWvWrNF6Tg0eLJkC0JaPPvoo9u7di6ZNm2rnyX8UCSx1797d5/0kJSVpP+7k/urKf7C69LuQfzzWQZCgT80LBpnApwel4jO7+O7wXU9FkOwl+2H3sk2DBuq8Bg3M8+rXT8Dq1Z6tAtu1i0NWVhyWLAEkTr9hAzB1qrpr6R1ltWKFrcr/X4zNnU7X67rH8Pv2jUNCQs0DewHZ+C4w/2IgqTEwaTMQX89zm8N/awt7w76wS2Orgf8But0IW3x9YOHlwI5vkLD2GeCYN33fz/av1cTEDpcD/Z4Acv/UzrY16o+EEDbL4uM6tvB4xw4e69jBYx07eKxjC4+3KdC/Q0Q3Or/11lvx66+/YvPmzdpUvVNPPRVxcXE499xzkZGRgcmTJ2sZTT///LPW+PzSSy/VAlHHHKO+5ZfMJgk+SRDrr7/+wg8//IB7770X1157rdegExFRyMVZnnsyfAfHkdRELYv3+725yZPNdUnKGTHCc5tzzlHLo44CrroKeOopKbkD5szx3FYfcFoldjvwj5GvY2Tn71zOt5aRp6VJphTCZ9tn5t9vj4+yywN6Jm1mb/O8+h2BlCyg2+3q9NbPgLJC79eXKX1LrgdKDgGrngQObwC2fKguazQweL8LEREREVEdFdGZUtu3b9cCUAcOHECTJk0wdOhQzJ8/X1sXzz77LOx2u5YpJY3JZbLeSy+9VHF9CWB9++23uPrqq7VgVb169XDxxRfj4YcfrsXfiohiWqszgF0/AA36qYl7vkiGj5CAh6MUsHv/pkFK4a6/vhzl5ctklB9efx1o2RK48kpAhozK5fE+nukly+q114ArLL28L7ig6r9SWsFsvP4P40bMEXxFReY23gJgIZVnGfm3eybQ4kTz9L55wLqXgJzlgJRkZnkZM9hkCCClf/mbgeUPAD3v9TxeWz8F8reYp5fdq6b52ZOADv8IxW9FRERERFSnRHRQ6iNjVrkPycnJmDJlivbjizRGnzYtNI1miYiqrMNlQHya90CIVWJDwJ4IOEqAgh1AWls0bAgcPAgMGOCaHfX00w5MmyaNpHpq2zz/vLrMT5Vyhcsvdw1KVSdmn57v/TnWGGI6caIMq0D4SBDvyEbztDVTauf3wK8TAac+9a/FSUBSI8/bsNmBXg8A8y8FVj2lfjpMBga9ARQfBJY/CKx9UW1brx2QvwnYor9mNRkKpLYI6a9IRERERFQXRHT5HhFRnSPBjrbnqBIxf+xxQFp7tZ63WlvMni0T9oBPPw3uLhnVzGefDVRnwGhK8XLXgJBbplRyMsLnwCLV58lZZp6Xs0wFkvK3Ar+fqQJSEhTs/zxwzFu+b6vdxUC328zTG/6rbuPPW8yAlPSqGuFatohmxwf7tyIiIiIiqpMiOlOKiCimNT5GBaSk3C97vJb5JOV5wTZvHvDGG8CDD1bv+vFle80T5YUVpYZGplTYglJ7fgVmjTRLCBv0BcqLgbxVwNZPVMZZWT7QaBAwYjoQV0kjcklD6/ck0PVmYOaxKvtqxzeqbM/Q/S4goxuQ3rUieIjsk0L4SxIRERER1R3MlCIiilQtJpo9kUKoXz9AqqD1dn01C0pZmoLPmuV9Cl9ISPBJSu0sPa20QJGU54nF1wEr/6XWu95UeUDKKqUZ0OY8tf7nrSqwldoaOHkj0ONudX6nq80G55m9gvM7ERERERHVcQxKERFFqkZqkqiWgeNrAlxtc5QjoXSHa6aUhIacwPTpYQxK7fxO9XWykql6Pe9Tf0ejh5T06mp5StVvv9kotSzXaxLbnA2ktVPZVKLzP4Hxi4HjZ5nnERERERGRXwxKERFFqpTmQFITFVCRSXGRqGgPbCjzCErt32+eddZZYdiPTf9TSynNswalEuoDQz8GUrLVedK8PE5volUVjQe7nm7t9ktJIKphfyAhreq3TUREREQUoxiUIiKKVBLoMErBjH5FkaZApv6ZDucWoqQE2KQnLTVrBvTtG+J9kCbmO79V6wOmAE2HAyktgCbHqvPqtQYmrgVOWgt0ub569yGBrOYnqPW0jioARURERERENcJG50REkax+R2DPT8CR9YhIMo3OYsyoEixYD/TSY2m9e4dhH2Qqnkz9kwCeBItG/wo4HWrSoUGm5KV3qtn9HP0CsPo5oMNklugREREREQUBg1JERJFMGmqLgm2ISDLZziIxvkRbLterDU89NUT3W7QPSMwE9s4G/tKbjXe+zrzcGpAKZoBwwH+Cf7tERERERDGKQSkiokiW2kItC3YiIh36y+VkUnyxy+mzzw7BfW79FPj9LCBrJFCwA3CWAS1OBtpdEoI7IyIiIiKiUGFQiogokklvJFFomXAXSXL+8popJYYPBxo0CPL9yVi/5Q+r9T0/q2VSI2Dwu0BcYpDvjIiIiIiIQomNzomIIpkxNU4ygiJNSS5wZKO2etjetSIoNXeuih39+msI7lOCYLkrXM876jkgMSMEd0ZERERERKHETCkiokhWr5ValuYAJYeAxGCnHlWDNBHf+T1QelidTm2N+vWbA3tWY+TwYgwYEML7lh5SInsC0O02wJ5gTtkjIiIiIqKowqAUEVEkS0gH0jqq6Xv7FwDZ42t7j4C1U4Al15unG/YDyou01euvLQntK8uBhWrZaBCQNSKEd0RERERERKHG8j0iokjXZIha7p+LiLDlI9fTDfoB9iS17nBtdB50BxepZaNQpmMREREREVE4MChFRBTpGhtBqfmICO5N1xv0Bex6k3GH2eg86EpygLw1ar0hg1JERERERNGO5XtERJEuvYtaFmyt/V5SUj6X77YfmX2AuE/VenkIMqW2fgoU7gbSVTN11GsHJDcO/v0QEREREVFYMShFRBTpkpupZeGu2t2Pxf8E1r1kOcOmAmb12oQuU+rgEuD3s9R6/U5q2WhgcO+DiIiIiIhqBYNSRESRLqW5WpbmAWUFQHxq+PfBUe4WkAJw6g4gIQOw2ULXU2rbF+b64XVqyX5SRERERER1AntKERFFwwS+uBS1XrS7dvahcKfr/nS7XQXLjABZsDOlnE613D/P87Imw4JzH0REREREVKsYlCIiinSSiVTbJXz5W8x+TqcfAPo94Xp5XFLwglKzTwe+bg8c2aR6WIkOl5tN3xsdXfP7ICIiIiKiWsfyPSKiaJDSDMjfBBTtqZ37N5qsa/2jvLx0GJlSNW10nrPSLNn781agLF9lZg18Bej1IJDUELDx+xQiIiIiorqAQSkiomiQ3FQtaysoVZEp1dr75cEq39v8nrluBKcaDVKBqNTsmt02ERERERFFFAaliIiiQXKWWhaGOSh1eD2QkAnkWzKlvKko36tBplTpEWDj257nS1CKiIiIiIjqHAaliIiiKShVvDd897l3NjBrJJDYEEhtqc5LrSRTqrwGmVISkJJMMMkKK7L8no0ZlCIiIiIiqovYmIOIKBok1UL53tbPAGc5ULwPOPSnOi+tnfdt7UHIlNo+VS1lsl/W8eb5jQdX/zaJiIiIiChiMVOKiCgaGP2UpJwuXHL+8jwvvVtoekoVHwD2/qrWW5wMZE8AFl0DtD0XSGpUvdskIiIiIqKIxqAUEVE0aHysWuYsU6VtRuPzUHE6gUNuQankZkBK80p6SlUzKLXhTcBZBjToC6R3UueN/rl6t0VERERERFGB5XtERNEgJQvI6KHWDywK/f0VbAVKcwBbHBCXqs5rOhyw2SrpKVWN8j1HObDuJbXe+brq7jEREREREUUZBqWIiKJF/c5qeWRDeJqci8zewLDPgHYXA33+z/f2NSnf2/opkL9ZNVRvc141d5iIiIiIiKINg1JERNGiXlu1LNjm9WL7mmeBzxurIE9NlBcBq55U683HA9knAIPfBup38H2d6jY6lzLBvx9T611uBOJTqrvXREREREQUZRiUIiKKFkY/p8JdwLL7gRlDgLy1QFkB4pzFsC+/VzUM//0soDSv+vez5WMgZzkQlwK0vziw68RVI1Nq94/AZ5mqT5aUCHZh6R4RERERUSxho3MiomgLSm3+QFKM1Pq3XRBvT0KHuNNgc5aa2279DOhwmXn64B+ALR5o0Lvy+zmw0OzvlN4lsH0zMqX89ZTaMQ2YfRqQ1hbo+6TqI2UEz7reCCQ2COy+iIiIiIioTmBQiogoWlRMvtMDUjqboxhdHB+7bntwiRmUOrAY+GGgalo+YRmQ0c3//Rz6Uy0zewW+b5X1lCo+qAJSUt6XtwaYcw5QXqguG/IB0OacwO+LiIiIiIjqBJbvERFFXVDKkx0OtVKvjWtgSWx6RwWynGXAhjfUeY5S4M/bgeWPqL5OBikHPLBArTcZFvi+xVXSU2rPT66XGQGp1FYqIOVrqh8REREREdVZDEoREUWLeu2AhHS1Pvh/wNlFwPjFrtu0PV8tD/0FOMrVz7bPzcu3fAiUHAL+vA1Y9RSw/H5gx7fm5aueBpwOIPskVWYXrEwpoySw09VAH72xuWg+jgEpIiIiIqIYxaAUEVG0kMl0o35RAam256nspMy+cBoBIdHyFNU0vLwAmHchsOMb1Rhdzouvp9Y/awised68zub/qWV5iTm5r9vNVdu3ip5SlQSlGg0E2l8CJDUC4tNUkIqIiIiIiGISe0oREUWThv3Uj8EeB2eT42DbMxPOpKawNegHZPZUQSDJipIf0eYs1ejcKN+z2j5V9Xw6sAgozQGSs4Amw6u2XxWZUl7K9yRb66Ce0dVwAJDSDDhpDeAoA1KyqnY/RERERERUZzAoRUQU5cr7PYd1sx5C++PuQoI9HkjrYGYmGVqdqRqX528G6ncBGh8DZI0Efj0JOLRUTfQr3Km2zT5RC3ZVibV8T3pUWUvycpcDZfkqMyq9qzpPMqWIiIiIiCimMShFRBTt6nfC6sTz0D6jhzrd5QaVmVSwQ5XxpbYGmo0G4hKB42e6Xrf9ZcCS64E/bwYyepoldlVlNDo3mqjLfRnWvaKWWcdXPdhFRERERER1FntKERHVNY0HARPXAqfvBQa+CoyZ7Rokcm+MHl9fBZKMiX1SAlhV1r5W1mbn5UX69D/pU3VL1W+XiIiIiIjqLAaliIjqKmls3vEKoF5r39skNQQGvOR6nQZ9q35fRqNz975SB5eowJTWp2pY1W+XiIiIiIjqLAaliIhiXavTgfQugC0O6P+876wqf6Qsz2b3zJTaP18tGw927TNFREREREQxjz2liIhiXXwKMG6x6j+V3LT6tyPZUuWFQLklU+rwerU0+lURERERERHpGJQiIiIgIU391IT0lZKglDVTKn+TWqa1rdltExERERFRncPyPSIiCg5jAp/0kDLkb1bLeu1qZ5+IiIiIiChiMShFRETBEa9nWpUdUUunE8jfotaZKUVERERERG4YlCIiouBISFfL0sNqWbRbZU1JA/TUVrW6a0REREREFHkYlCIiouAGpcry1DL3b7WUgJQ9ofb2i4iIiIiIIhKDUkREFBzx9dWyVA9K7fhWLZuOqL19IiIiIiKiiMWgFBERBbl8Lw/YPx/Y8qE63XJSre4WERERERFFJgaliIgoOBL0TKltXwAzBgNFe4CkJkDzsbW9Z0REREREFIEYlCIiouBmSu37XS0zegDHzwTi69XqbhERERERUWRiUIqIiIIjXg9KGY7+D9CgT23tDRERERERRbiYCkpNmTIFbdu2RXJyMgYNGoSFCxfW9i4REdW9TCmj6XmTY2tzb4iIiIiIKMLFTFDq448/xs0334wHHngAf/zxB/r06YNx48Zh7969tb1rRER1Q2q2ud58DGBPqM29ISIiIiKiCBczQalnnnkGl19+OS699FJ0794dr7zyClJTU/Hmm2/W9q4REdUN6V3N9eyTanNPiIiIiIgoCsREUKqkpARLlizB6NGjK86z2+3a6Xnz5tXqvhER1RkZPYHudwLtLgLanlvbe0NERERERBEuHjFg//79KC8vR1ZWlsv5cnr16tUe2xcXF2s/hry8PG1ZWlqq/UQzY/+j/fegyvFYx46IOtY9HlZLh/xEwP7UMRF1rCnkeLxjB4917OCxjh081rGFx9tToH8Lm9PpdKKO27lzJ1q0aIG5c+di8ODBFefffvvt+PXXX7FgwQKX7R988EE89NBDHrfzwQcfaCV/RERERERERETkXUFBAc477zzk5uYiPd1tSnesZUo1btwYcXFx2LNnj8v5crpZs2Ye2991111aU3RrplSrVq0wduxYv3/MaIlWzpw5E2PGjEFCApsQ12U81rGDxzp28FjHFh7v2MFjHTt4rGMHj3Vs4fH2ZFScVSYmglKJiYno378/Zs2ahVNOOUU7z+FwaKevu+46j+2TkpK0H3fyn6uu/AerS78L+cdjHTt4rGMHj3Vs4fGOHTzWsYPHOnbwWMcWHm9ToH+HmAhKCcl8uvjii3H00Udj4MCBeO6555Cfn69N4yMiIiIiIiIiovCKmaDU2WefjX379uH+++/H7t270bdvX0yfPt2j+TkREREREREREYVezASlhJTqeSvXIyIiIiIiIiKi8LKH+f6IiIiIiIiIiIgYlCIiIiIiIiIiovBjUIqIiIiIiIiIiMKOQSkiIiIiIiIiIgo7BqWIiIiIiIiIiCjsGJQiIiIiIiIiIqKwY1CKiIiIiIiIiIjCjkEpIiIiIiIiIiIKOwaliIiIiIiIiIgo7BiUIiIiIiIiIiKisGNQioiIiIiIiIiIwo5BKSIiIiIiIiIiCjsGpYiIiIiIiIiIKOwYlCIiIiIiIiIiorCLD/9dRh+n06kt8/LyEO1KS0tRUFCg/S4JCQm1vTsUQjzWsYPHOnbwWMcWHu/YwWMdO3isYwePdWzh8fZkxE+MeIovDEoF4PDhw9qyVatWtb0rRERERERERERRE0/JyMjwebnNWVnYiuBwOLBz507Ur18fNpsN0R6tlODatm3bkJ6eXtu7QyHEYx07eKxjB491bOHxjh081rGDxzp28FjHFh5vTxJqkoBUdnY27HbfnaOYKRUA+QO2bNkSdYk8UPhgiQ081rGDxzp28FjHFh7v2MFjHTt4rGMHj3Vs4fF25S9DysBG50REREREREREFHYMShERERERERERUdgxKBVjkpKS8MADD2hLqtt4rGMHj3Xs4LGOLTzesYPHOnbwWMcOHuvYwuNdfWx0TkREREREREREYcdMKSIiIiIiIiIiCjsGpYiIiIiIiIiIKOwYlCIiIiIiIiIiorBjUCqGTJkyBW3btkVycjIGDRqEhQsX1vYuURU9+OCDsNlsLj9du3atuLyoqAjXXnstGjVqhLS0NJx++unYs2ePy21s3boVJ554IlJTU9G0aVPcdtttKCsrq4Xfhqx+++03TJw4EdnZ2dpxnTp1qsvl0v7v/vvvR/PmzZGSkoLRo0dj3bp1LtscPHgQ559/PtLT05GZmYnJkyfjyJEjLtssW7YMw4YN054HWrVqhSeffDIsvx8FfqwvueQSj8f5+PHjXbbhsY4Ojz32GAYMGID69etrz7ennHIK1qxZ47JNsJ63f/nlFxx11FFag9WOHTvi7bffDsvvSIEf6xEjRng8tq+66iqXbXiso8PLL7+M3r17a8/B8jN48GB8//33FZfzcR07x5qP67rr8ccf147njTfeWHEeH9shIo3Oqe776KOPnImJic4333zTuXLlSufll1/uzMzMdO7Zs6e2d42q4IEHHnD26NHDuWvXroqfffv2VVx+1VVXOVu1auWcNWuWc/Hixc5jjjnGOWTIkIrLy8rKnD179nSOHj3a+eeffzqnTZvmbNy4sfOuu+6qpd+IDHIs7rnnHucXX3whwyecX375pcvljz/+uDMjI8M5depU519//eU8+eSTne3atXMWFhZWbDN+/Hhnnz59nPPnz3fOnj3b2bFjR+e5555bcXlubq4zKyvLef755ztXrFjh/PDDD50pKSnOV199Nay/a6yr7FhffPHF2rG0Ps4PHjzosg2PdXQYN26c86233tKOwdKlS50TJkxwtm7d2nnkyJGgPm9v3LjRmZqa6rz55pudf//9t/PFF190xsXFOadPnx723zlWBXKsjzvuOO39l/WxLY9VA4919Pj666+d3333nXPt2rXONWvWOO+++25nQkKCdvwFH9exc6z5uK6bFi5c6Gzbtq2zd+/ezhtuuKHifD62Q4NBqRgxcOBA57XXXltxury83Jmdne187LHHanW/qOpBKfkg6k1OTo72Ivnpp59WnLdq1SrtQ++8efO00/LEaLfbnbt3767Y5uWXX3amp6c7i4uLw/AbUCDcAxUOh8PZrFkz51NPPeVyvJOSkrRgg5AXNbneokWLKrb5/vvvnTabzbljxw7t9EsvveRs0KCBy7G+4447nF26dAnTb0bufAWlJk2a5PM6PNbRa+/evdqx+/XXX4P6vH377bdrX1hYnX322VqghCLjWBsfXq0fbtzxWEc3ec594403+LiOoWMt+Liuew4fPuzs1KmTc+bMmS7Hl4/t0GH5XgwoKSnBkiVLtHIfg91u107PmzevVveNqk5KtqTsp3379lr5jqSICjnGpaWlLsdZSvtat25dcZxl2atXL2RlZVVsM27cOOTl5WHlypW18NtQIDZt2oTdu3e7HNuMjAytDNd6bKWM6+ijj67YRraXx/qCBQsqthk+fDgSExNdjr+UmBw6dCisvxP5J2ndkvLdpUsXXH311Thw4EDFZTzW0Ss3N1dbNmzYMKjP27KN9TaMbfgaHznH2vD++++jcePG6NmzJ+666y4UFBRUXMZjHZ3Ky8vx0UcfIT8/Xyvt4uM6do61gY/rukXK86T8zv2Y8LEdOvEhvG2KEPv379eeRK0PDiGnV69eXWv7RVUnQQipOZYPqrt27cJDDz2k9YxZsWKFFrSQD6DyYdX9OMtlQpbe/h8Yl1FkMo6Nt2NnPbYSxLCKj4/XPhBZt2nXrp3HbRiXNWjQIKS/BwVG+keddtpp2rHasGED7r77bpxwwgnam5W4uDge6yjlcDi0vhTHHnus9sFFBOt529c28ia4sLBQ60NHtXusxXnnnYc2bdpoXyxJz7c77rhDCxR/8cUX2uU81tFl+fLlWmBCesxIb5kvv/wS3bt3x9KlS/m4jpFjLfi4rlsk6PjHH39g0aJFHpfxNTt0GJQiiiLywdQgTRclSCUvhJ988klMPoER1UXnnHNOxbp82yaP9Q4dOmjZU6NGjarVfaOaffMqXyD8/vvvtb0rVEvH+oorrnB5bMvgCnlMS/BZHuMUXeQLQglASVbcZ599hosvvhi//vprbe8WhfFYS2CKj+u6Y9u2bbjhhhswc+ZMbUgMhQ/L92KApJPKt+vukwHkdLNmzWptv6jmJFLfuXNnrF+/XjuWUqqZk5Pj8zjL0tv/A+MyikzGsfH3GJbl3r17XS6XSR8ypY3HP7pJqa48j8vjXPBYR5/rrrsO3377LX7++We0bNmy4vxgPW/72kYmRfELi8g41t7IF0vC+tjmsY4ekjEhU7P69++vTV/s06cPnn/+eT6uY+hYe8PHdfSS8jx5fyVT8SQDXX4k+PjCCy9o65LNxMd2aDAoFSNPpPIkOmvWLJfUcjltrYem6CMj4OWbGPlWRo5xQkKCy3GW9GHpOWUcZ1lKCrL1A618GyBPgkYaMkUeKcOSFzDrsZUUX+kfZD228iIpL6iGn376SXusG2+QZJvffvtNq4e3Hn/5BpDlXJFr+/btWk8peZwLHuvoIb3sJUghpR5yjNxLKoP1vC3bWG/D2Iav8ZFzrL2RzAthfWzzWEcveQ4uLi7m4zqGjrU3fFxHL8lwk2Mlx9D4kf6d0sPXWOdjO0RC2ESdIshHH32kTep6++23tclNV1xxhTMzM9NlMgBFvltuucX5yy+/ODdt2uScM2eONm5UxozKlB9jTKmMoP7pp5+0MaWDBw/WftzHlI4dO1YbWS2jR5s0aeIyppRqb9KHjI6VH3lqfuaZZ7T1LVu2aJc//vjj2mP2q6++ci5btkybztauXTtnYWFhxW2MHz/e2a9fP+eCBQucv//+uzY55Nxzz624XKaGZGVlOS+88EJtlLE8L8hI2ldffbVWfudY5e9Yy2W33nqrNsVFHuc//vij86ijjtKOZVFRUcVt8FhHh6uvvtqZkZGhPW9bx4UXFBRUbBOM521jvPRtt92mTQKaMmVKzI+XjrRjvX79eufDDz+sHWN5bMtzefv27Z3Dhw+vuA0e6+hx5513apMV5VjKa7KclgmoM2bM0C7n4zo2jjUf13Wf+3RFPrZDg0GpGPLiiy9qD6LExETnwIEDnfPnz6/tXaIqknGhzZs3145hixYttNPygmiQAMU111yjjaqVJ7tTTz1Ve1NstXnzZucJJ5zgTElJ0QJaEugqLS2thd+GrH7++WctQOH+c/HFF2uXOxwO53333acFGiTAPGrUKOeaNWtcbuPAgQNaYCItLU0bPXvppZdqQQ6rv/76yzl06FDtNuT/kAS7KHKOtXyAlTcy8gZGxg63adPGefnll3t8gcBjHR28HWf5eeutt4L+vC3/r/r27au9PsiHIut9UO0f661bt2ofVBs2bKg9Jjt27Kh9IMnNzXW5HR7r6HDZZZdpz89yDOT5Wl6TjYCU4OM6No41H9exF5TiYzs0bPJPqLKwiIiIiIiIiIiIvGFPKSIiIiIiIiIiCjsGpYiIiIiIiIiIKOwYlCIiIiIiIiIiorBjUIqIiIiIiIiIiMKOQSkiIiIiIiIiIgo7BqWIiIiIiIiIiCjsGJQiIiIiIiIiIqKwY1CKiIiIiIiIiIjCjkEpIiIiIiIiIiIKOwaliIiIiGrRJZdcApvNpv0kJCQgKysLY8aMwZtvvgmHw1Hbu0dEREQUMgxKEREREdWy8ePHY9euXdi8eTO+//57jBw5EjfccANOOukklJWV1fbuEREREYUEg1JEREREtSwpKQnNmjVDixYtcNRRR+Huu+/GV199pQWo3n77bW2bZ555Br169UK9evXQqlUrXHPNNThy5Ih2WX5+PtLT0/HZZ5+53O7UqVO17Q8fPoySkhJcd911aN68OZKTk9GmTRs89thjtfL7EhEREQkGpYiIiIgi0PHHH48+ffrgiy++0E7b7Xa88MILWLlyJd555x389NNPuP3227XLJPB0zjnn4K233nK5DTl9xhlnoH79+tp1v/76a3zyySdYs2YN3n//fbRt27ZWfjciIiIiEc8/AxEREVFk6tq1K5YtW6at33jjjRXnSzDpX//6F6666iq89NJL2nn/+Mc/MGTIEK0MULKh9u7di2nTpuHHH3/ULt+6dSs6deqEoUOHav2rJFOKiIiIqDYxU4qIiIgoQjmdTi2AJCS4NGrUKK3ETzKfLrzwQhw4cAAFBQXa5QMHDkSPHj20LCrxv//9Tws8DR8+vKKh+tKlS9GlSxdcf/31mDFjRi3+ZkREREQMShERERFFrFWrVqFdu3ZaA3Rpet67d298/vnnWLJkCaZMmaJtI72iDJItZfSgktK9Sy+9tCKoJb2qNm3ahEceeQSFhYU466yztNI+IiIiotrCoBQRERFRBJKeUcuXL8fpp5+uBaEcDgf+/e9/45hjjkHnzp2xc+dOj+tccMEF2LJli9Y/6u+//8bFF1/scrk0Qz/77LPx+uuv4+OPP9YCXAcPHgzjb0VERERkYk8pIiIiolpWXFyM3bt3o7y8HHv27MH06dO1yXiSHXXRRRdhxYoVKC0txYsvvoiJEydizpw5eOWVVzxup0GDBjjttNNw2223YezYsWjZsmXFZTK9T3pN9evXT2ua/umnn2oT/zIzM8P82xIREREpzJQiIiIiqmUShJKAkTQwHz9+PH7++Wct2+mrr75CXFycNoVPgkpPPPEEevbsqU3Ok6CVN5MnT9ZK+i677DKX86UP1ZNPPomjjz4aAwYM0EoCpRG6BKiIiIiIaoPNKR00iYiIiKhOeO+993DTTTdp5X2JiYm1vTtEREREPrF8j4iIiKgOkCl8u3btwuOPP44rr7ySASkiIiKKeMzXJiIiIqoDpDSva9euWp+ou+66q7Z3h4iIiKhSLN8jIiIiIiIiIqKwY6YUERERERERERGFHYNSREREREREREQUdgxKERERERERERFR2DEoRUREREREREREYcegFBERERERERERhR2DUkREREREREREFHYMShERERERERERUdgxKEVERERERERERGHHoBQRERERERERESHc/h+4wv2Yjsf8EgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "CSV_PATH = r\"D:/stock_prediction/data/TCS.csv\"\n",
    "MODEL_PATH = r\"D:/stock_prediction/notebooks/models/TCS_lstm_model.h5\"\n",
    "SCALER_MAX_PATH = r\"D:/stock_prediction/notebooks/models/TCS_scaler_max.npy\"\n",
    "SEQUENCE_LENGTH = 60\n",
    "\n",
    "# Step 1: Load the data\n",
    "df = pd.read_csv(CSV_PATH)[['Close']].dropna()\n",
    "\n",
    "# Step 2: Prepare the data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# Step 3: Load model and max scaler\n",
    "model = load_model(MODEL_PATH)\n",
    "scaler_max = float(np.load(SCALER_MAX_PATH))\n",
    "\n",
    "# Step 4: Create sequences and predictions\n",
    "X = []\n",
    "for i in range(SEQUENCE_LENGTH, len(scaled_data)):\n",
    "    X.append(scaled_data[i - SEQUENCE_LENGTH:i])\n",
    "\n",
    "X = np.array(X)\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "predictions_scaled = model.predict(X)\n",
    "predictions = predictions_scaled.flatten() * scaler_max\n",
    "\n",
    "# Actual prices to compare\n",
    "actual = df['Close'].values[SEQUENCE_LENGTH:]\n",
    "\n",
    "# Step 5: Plot the comparison graph\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(actual, label=\"Actual Price\", color='blue')\n",
    "plt.plot(predictions, label=\"Predicted Price\", color='orange')\n",
    "plt.title(\"TCS Stock Price Prediction vs Actual\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Price (â‚¹)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
